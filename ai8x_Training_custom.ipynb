{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone --recursive https://github.com/Jss-on/ai8x-training.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEQFGhlCoHlK",
        "outputId": "df4c9b67-c2ce-4a04-bcf6-dbe55e8f4127"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ai8x-training'...\n",
            "remote: Enumerating objects: 1760, done.\u001b[K\n",
            "remote: Counting objects: 100% (164/164), done.\u001b[K\n",
            "remote: Compressing objects: 100% (123/123), done.\u001b[K\n",
            "remote: Total 1760 (delta 78), reused 99 (delta 40), pack-reused 1596\u001b[K\n",
            "Receiving objects: 100% (1760/1760), 158.04 MiB | 28.11 MiB/s, done.\n",
            "Resolving deltas: 100% (1154/1154), done.\n",
            "Submodule 'datasets/face_id/facenet_pytorch' (https://github.com/MaximIntegratedAI/facenet-pytorch.git) registered for path 'datasets/face_id/facenet_pytorch'\n",
            "Submodule 'distiller' (https://github.com/MaximIntegratedAI/distiller.git) registered for path 'distiller'\n",
            "Cloning into '/content/ai8x-training/datasets/face_id/facenet_pytorch'...\n",
            "remote: Enumerating objects: 1220, done.        \n",
            "remote: Counting objects: 100% (5/5), done.        \n",
            "remote: Compressing objects: 100% (5/5), done.        \n",
            "remote: Total 1220 (delta 0), reused 2 (delta 0), pack-reused 1215        \n",
            "Receiving objects: 100% (1220/1220), 22.86 MiB | 22.66 MiB/s, done.\n",
            "Resolving deltas: 100% (589/589), done.\n",
            "Cloning into '/content/ai8x-training/distiller'...\n",
            "remote: Enumerating objects: 5504, done.        \n",
            "remote: Counting objects: 100% (5504/5504), done.        \n",
            "remote: Compressing objects: 100% (2043/2043), done.        \n",
            "remote: Total 5504 (delta 3969), reused 4338 (delta 3321), pack-reused 0        \n",
            "Receiving objects: 100% (5504/5504), 38.33 MiB | 14.43 MiB/s, done.\n",
            "Resolving deltas: 100% (3969/3969), done.\n",
            "Submodule path 'datasets/face_id/facenet_pytorch': checked out '932a69162cba16fbef0e452c515cb6cbb530e84c'\n",
            "Submodule 'dependencies/facenet' (https://github.com/davidsandberg/facenet.git) registered for path 'datasets/face_id/facenet_pytorch/dependencies/facenet'\n",
            "Cloning into '/content/ai8x-training/datasets/face_id/facenet_pytorch/dependencies/facenet'...\n",
            "remote: Enumerating objects: 3149, done.        \n",
            "remote: Counting objects: 100% (3/3), done.        \n",
            "remote: Compressing objects: 100% (3/3), done.        \n",
            "remote: Total 3149 (delta 0), reused 0 (delta 0), pack-reused 3146        \n",
            "Receiving objects: 100% (3149/3149), 2.92 MiB | 6.43 MiB/s, done.\n",
            "Resolving deltas: 100% (2233/2233), done.\n",
            "Submodule path 'datasets/face_id/facenet_pytorch/dependencies/facenet': checked out '096ed770f163957c1e56efa7feeb194773920f6e'\n",
            "Submodule path 'distiller': checked out 'dd15e335a722775a6bf2a61417ae02c671ebef57'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run below if your data comes from kaggle"
      ],
      "metadata": {
        "id": "vrc3KYkHrfEd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YeW5PsJsZfuD"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "gLSDU2pXMWcS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d tensordt/smarte2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZihqQWdMWid",
        "outputId": "7f795a43-ca85-4c81-fb79-77e8caafe853"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading smarte2.zip to /content\n",
            " 95% 28.0M/29.6M [00:02<00:00, 17.6MB/s]\n",
            "100% 29.6M/29.6M [00:02<00:00, 14.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create data folder and under that directory, create raw and processed folders"
      ],
      "metadata": {
        "id": "13YUY-UdrycU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the root directory\n",
        "root_directory = \"/content/ai8x-training\"\n",
        "\n",
        "# Define the folders to be created\n",
        "data_folder = os.path.join(root_directory, \"data\")\n",
        "raw_folder = os.path.join(data_folder, \"raw\")\n",
        "processed_folder = os.path.join(data_folder, \"processed\")\n",
        "\n",
        "# Create the folders if they don't already exist\n",
        "os.makedirs(raw_folder, exist_ok=True)\n",
        "os.makedirs(processed_folder, exist_ok=True)\n",
        "\n",
        "print(\"Folders created successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbz0jETksIFv",
        "outputId": "11edd714-4af1-43b3-ad45-485197cbab18"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folders created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/smarte2.zip -d /content/ai8x-training/data/raw"
      ],
      "metadata": {
        "id": "2CbJ8KOAMiZJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38836783-f220-4e5d-8bbc-83a5261444cd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/smarte2.zip\n",
            "  inflating: /content/ai8x-training/data/raw/Full_leak4/Full_leak1.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/Full_leak4/Full_leak10.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/Full_leak4/Full_leak11.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/Full_leak4/Full_leak12.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/Full_leak4/Full_leak13.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/Full_leak4/Full_leak14.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/Full_leak4/Full_leak15.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/Full_leak4/Full_leak16.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/Full_leak4/Full_leak17.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/Full_leak4/Full_leak18.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/Full_leak4/Full_leak19.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/Full_leak4/Full_leak2.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/Full_leak4/Full_leak20.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/Full_leak4/Full_leak3.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/Full_leak4/Full_leak4.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/Full_leak4/Full_leak5.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/Full_leak4/Full_leak6.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/Full_leak4/Full_leak7.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/Full_leak4/Full_leak8.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/Full_leak4/Full_leak9.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/leakage/1.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/leakage/10.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/leakage/11.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/leakage/12.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/leakage/2.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/leakage/3.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/leakage/4.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/leakage/5.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/leakage/6.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/leakage/7.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/leakage/8.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/leakage/9.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/normal/1.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/normal/10.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/normal/11.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/normal/12.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/normal/13.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/normal/14.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/normal/15.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/normal/16.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/normal/17.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/normal/18.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/normal/19.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/normal/2.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/normal/20.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/normal/3.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/normal/4.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/normal/5.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/normal/6.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/normal/7.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/normal/8.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/normal/9.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle abnormal/1.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle abnormal/10.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle abnormal/11.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle abnormal/12.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle abnormal/13.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle abnormal/14.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle abnormal/15.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle abnormal/16.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle abnormal/17.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle abnormal/18.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle abnormal/19.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle abnormal/2.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle abnormal/20.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle abnormal/21.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle abnormal/22.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle abnormal/23.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle abnormal/24.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle abnormal/25.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle abnormal/3.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle abnormal/4.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle abnormal/5.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle abnormal/6.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle abnormal/7.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle abnormal/8.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle abnormal/9.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle normal/1.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle normal/10.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle normal/11.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle normal/12.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle normal/13.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle normal/14.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle normal/15.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle normal/16.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle normal/17.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle normal/18.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle normal/19.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle normal/2.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle normal/20.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle normal/21.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle normal/22.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle normal/23.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle normal/24.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle normal/25.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle normal/26.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle normal/3.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle normal/4.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle normal/5.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle normal/6.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle normal/7.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle normal/8.wav  \n",
            "  inflating: /content/ai8x-training/data/raw/sort shuttle normal/9.wav  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyMgUVTkZwAw",
        "outputId": "8058d5f8-9ae7-4a1a-fae7-819fc46dc3bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ai8x-training\n"
          ]
        }
      ],
      "source": [
        "cd /content/ai8x-training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install -y build-essential libssl-dev zlib1g-dev libbz2-dev \\\n",
        "libreadline-dev libsqlite3-dev wget curl llvm libncurses5-dev libncursesw5-dev \\\n",
        "xz-utils tk-dev libffi-dev liblzma-dev python3-openssl git\n",
        "!curl https://pyenv.run | bash\n",
        "!echo 'export PATH=\"$HOME/.pyenv/bin:$PATH\"' >> ~/.bashrc\n",
        "!echo 'eval \"$(pyenv init --path)\"' >> ~/.bashrc\n",
        "!echo 'eval \"$(pyenv virtualenv-init -)\"' >> ~/.bashrc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_4zkIDb97xO",
        "outputId": "fa48d361-443f-483e-fe76-4db7bb7693c0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "\r0% [Waiting for headers] [1 InRelease 12.7 kB/110 kB 12%] [Connected to cloud.r\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [1 InRelease 110 kB/110 kB 100%] [Connected to cloud.r\r                                                                               \rGet:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "\r                                                                               \rGet:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\r0% [3 InRelease 46.0 kB/119 kB 39%] [Connected to ppa.launchpadcontent.net (185\r                                                                               \r0% [Waiting for headers] [Waiting for headers] [Waiting for headers]\r                                                                    \rHit:5 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Connecting to ppa.launchpadcontent.net] [Waiting for \r                                                                               \rGet:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\r0% [Waiting for headers] [Connecting to ppa.launchpadcontent.net (185.125.190.5\r0% [Waiting for headers] [Connecting to ppa.launchpadcontent.net (185.125.190.5\r                                                                               \rGet:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [897 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [980 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [860 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,136 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [923 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,241 kB]\n",
            "Get:17 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [458 kB]\n",
            "Fetched 6,838 kB in 1s (6,221 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.9ubuntu3).\n",
            "libbz2-dev is already the newest version (1.0.8-5build1).\n",
            "libbz2-dev set to manually installed.\n",
            "liblzma-dev is already the newest version (5.2.5-2ubuntu1).\n",
            "liblzma-dev set to manually installed.\n",
            "libreadline-dev is already the newest version (8.1.2-1).\n",
            "libreadline-dev set to manually installed.\n",
            "tk-dev is already the newest version (8.6.11+1build2).\n",
            "wget is already the newest version (1.21.2-2ubuntu1).\n",
            "xz-utils is already the newest version (5.2.5-2ubuntu1).\n",
            "xz-utils set to manually installed.\n",
            "curl is already the newest version (7.81.0-1ubuntu1.13).\n",
            "libncurses5-dev is already the newest version (6.3-2ubuntu0.1).\n",
            "libsqlite3-dev is already the newest version (3.37.2-2ubuntu0.1).\n",
            "libsqlite3-dev set to manually installed.\n",
            "libssl-dev is already the newest version (3.0.2-0ubuntu1.10).\n",
            "zlib1g-dev is already the newest version (1:1.2.11.dfsg-2ubuntu9.2).\n",
            "zlib1g-dev set to manually installed.\n",
            "The following additional packages will be installed:\n",
            "  binfmt-support libpfm4 libz3-4 libz3-dev llvm-14 llvm-14-dev llvm-14-runtime\n",
            "  llvm-14-tools llvm-runtime python3-pygments python3-yaml\n",
            "Suggested packages:\n",
            "  gettext-base git-daemon-run | git-daemon-sysvinit git-doc git-email git-gui\n",
            "  gitk gitweb git-cvs git-mediawiki git-svn llvm-14-doc python-openssl-doc\n",
            "  python3-openssl-dbg python-pygments-doc ttf-bitstream-vera\n",
            "The following NEW packages will be installed:\n",
            "  binfmt-support libffi-dev libncursesw5-dev libpfm4 libz3-4 libz3-dev llvm\n",
            "  llvm-14 llvm-14-dev llvm-14-runtime llvm-14-tools llvm-runtime\n",
            "  python3-openssl python3-pygments python3-yaml\n",
            "The following packages will be upgraded:\n",
            "  git\n",
            "1 upgraded, 15 newly installed, 0 to remove and 19 not upgraded.\n",
            "Need to get 61.8 MB of archives.\n",
            "After this operation, 355 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-yaml amd64 5.4.1-1ubuntu1 [129 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 binfmt-support amd64 2.2.1-2 [55.8 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 git amd64 1:2.34.1-1ubuntu1.10 [3,166 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libncursesw5-dev amd64 6.3-2ubuntu0.1 [790 B]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 llvm-14-runtime amd64 1:14.0.0-1ubuntu1.1 [484 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/universe amd64 llvm-runtime amd64 1:14.0-55~exp2 [3,204 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpfm4 amd64 4.11.1+git32-gd0b85fb-1ubuntu0.1 [345 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 llvm-14 amd64 1:14.0.0-1ubuntu1.1 [12.7 MB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/universe amd64 llvm amd64 1:14.0-55~exp2 [3,758 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libffi-dev amd64 3.4.2-4 [63.7 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-pygments all 2.11.2+dfsg-2 [750 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 llvm-14-tools amd64 1:14.0.0-1ubuntu1.1 [404 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libz3-4 amd64 4.8.12-1 [5,766 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libz3-dev amd64 4.8.12-1 [72.2 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 llvm-14-dev amd64 1:14.0.0-1ubuntu1.1 [37.8 MB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-openssl all 21.0.0-1 [45.2 kB]\n",
            "Fetched 61.8 MB in 1s (50.3 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 16.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python3-yaml.\n",
            "(Reading database ... 120831 files and directories currently installed.)\n",
            "Preparing to unpack .../00-python3-yaml_5.4.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking python3-yaml (5.4.1-1ubuntu1) ...\n",
            "Selecting previously unselected package binfmt-support.\n",
            "Preparing to unpack .../01-binfmt-support_2.2.1-2_amd64.deb ...\n",
            "Unpacking binfmt-support (2.2.1-2) ...\n",
            "Preparing to unpack .../02-git_1%3a2.34.1-1ubuntu1.10_amd64.deb ...\n",
            "Unpacking git (1:2.34.1-1ubuntu1.10) over (1:2.34.1-1ubuntu1.9) ...\n",
            "Selecting previously unselected package libncursesw5-dev:amd64.\n",
            "Preparing to unpack .../03-libncursesw5-dev_6.3-2ubuntu0.1_amd64.deb ...\n",
            "Unpacking libncursesw5-dev:amd64 (6.3-2ubuntu0.1) ...\n",
            "Selecting previously unselected package llvm-14-runtime.\n",
            "Preparing to unpack .../04-llvm-14-runtime_1%3a14.0.0-1ubuntu1.1_amd64.deb ...\n",
            "Unpacking llvm-14-runtime (1:14.0.0-1ubuntu1.1) ...\n",
            "Selecting previously unselected package llvm-runtime:amd64.\n",
            "Preparing to unpack .../05-llvm-runtime_1%3a14.0-55~exp2_amd64.deb ...\n",
            "Unpacking llvm-runtime:amd64 (1:14.0-55~exp2) ...\n",
            "Selecting previously unselected package libpfm4:amd64.\n",
            "Preparing to unpack .../06-libpfm4_4.11.1+git32-gd0b85fb-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libpfm4:amd64 (4.11.1+git32-gd0b85fb-1ubuntu0.1) ...\n",
            "Selecting previously unselected package llvm-14.\n",
            "Preparing to unpack .../07-llvm-14_1%3a14.0.0-1ubuntu1.1_amd64.deb ...\n",
            "Unpacking llvm-14 (1:14.0.0-1ubuntu1.1) ...\n",
            "Selecting previously unselected package llvm.\n",
            "Preparing to unpack .../08-llvm_1%3a14.0-55~exp2_amd64.deb ...\n",
            "Unpacking llvm (1:14.0-55~exp2) ...\n",
            "Selecting previously unselected package libffi-dev:amd64.\n",
            "Preparing to unpack .../09-libffi-dev_3.4.2-4_amd64.deb ...\n",
            "Unpacking libffi-dev:amd64 (3.4.2-4) ...\n",
            "Selecting previously unselected package python3-pygments.\n",
            "Preparing to unpack .../10-python3-pygments_2.11.2+dfsg-2_all.deb ...\n",
            "Unpacking python3-pygments (2.11.2+dfsg-2) ...\n",
            "Selecting previously unselected package llvm-14-tools.\n",
            "Preparing to unpack .../11-llvm-14-tools_1%3a14.0.0-1ubuntu1.1_amd64.deb ...\n",
            "Unpacking llvm-14-tools (1:14.0.0-1ubuntu1.1) ...\n",
            "Selecting previously unselected package libz3-4:amd64.\n",
            "Preparing to unpack .../12-libz3-4_4.8.12-1_amd64.deb ...\n",
            "Unpacking libz3-4:amd64 (4.8.12-1) ...\n",
            "Selecting previously unselected package libz3-dev:amd64.\n",
            "Preparing to unpack .../13-libz3-dev_4.8.12-1_amd64.deb ...\n",
            "Unpacking libz3-dev:amd64 (4.8.12-1) ...\n",
            "Selecting previously unselected package llvm-14-dev.\n",
            "Preparing to unpack .../14-llvm-14-dev_1%3a14.0.0-1ubuntu1.1_amd64.deb ...\n",
            "Unpacking llvm-14-dev (1:14.0.0-1ubuntu1.1) ...\n",
            "Selecting previously unselected package python3-openssl.\n",
            "Preparing to unpack .../15-python3-openssl_21.0.0-1_all.deb ...\n",
            "Unpacking python3-openssl (21.0.0-1) ...\n",
            "Setting up libncursesw5-dev:amd64 (6.3-2ubuntu0.1) ...\n",
            "Setting up python3-openssl (21.0.0-1) ...\n",
            "Setting up python3-yaml (5.4.1-1ubuntu1) ...\n",
            "Setting up libffi-dev:amd64 (3.4.2-4) ...\n",
            "Setting up python3-pygments (2.11.2+dfsg-2) ...\n",
            "Setting up libz3-4:amd64 (4.8.12-1) ...\n",
            "Setting up libpfm4:amd64 (4.11.1+git32-gd0b85fb-1ubuntu0.1) ...\n",
            "Setting up llvm-14-runtime (1:14.0.0-1ubuntu1.1) ...\n",
            "Setting up llvm-runtime:amd64 (1:14.0-55~exp2) ...\n",
            "Setting up binfmt-support (2.2.1-2) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of restart.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/binfmt-support.service → /lib/systemd/system/binfmt-support.service.\n",
            "Setting up git (1:2.34.1-1ubuntu1.10) ...\n",
            "Setting up llvm-14 (1:14.0.0-1ubuntu1.1) ...\n",
            "Setting up llvm-14-tools (1:14.0.0-1ubuntu1.1) ...\n",
            "Setting up libz3-dev:amd64 (4.8.12-1) ...\n",
            "Setting up llvm (1:14.0-55~exp2) ...\n",
            "Setting up llvm-14-dev (1:14.0.0-1ubuntu1.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   270  100   270    0     0    373      0 --:--:-- --:--:-- --:--:--   373\n",
            "Cloning into '/root/.pyenv'...\n",
            "remote: Enumerating objects: 1158, done.\u001b[K\n",
            "remote: Counting objects: 100% (1158/1158), done.\u001b[K\n",
            "remote: Compressing objects: 100% (663/663), done.\u001b[K\n",
            "remote: Total 1158 (delta 672), reused 632 (delta 362), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (1158/1158), 575.74 KiB | 14.76 MiB/s, done.\n",
            "Resolving deltas: 100% (672/672), done.\n",
            "Cloning into '/root/.pyenv/plugins/pyenv-doctor'...\n",
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 11 (delta 1), reused 5 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (11/11), 38.72 KiB | 4.30 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n",
            "Cloning into '/root/.pyenv/plugins/pyenv-update'...\n",
            "remote: Enumerating objects: 10, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 10 (delta 1), reused 5 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (10/10), done.\n",
            "Resolving deltas: 100% (1/1), done.\n",
            "Cloning into '/root/.pyenv/plugins/pyenv-virtualenv'...\n",
            "remote: Enumerating objects: 63, done.\u001b[K\n",
            "remote: Counting objects: 100% (63/63), done.\u001b[K\n",
            "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
            "remote: Total 63 (delta 11), reused 29 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (63/63), 40.54 KiB | 2.90 MiB/s, done.\n",
            "Resolving deltas: 100% (11/11), done.\n",
            "\n",
            "\u001b[1mWARNING\u001b[m: seems you still have not added 'pyenv' to the load path.\n",
            "\n",
            "# Load pyenv automatically by appending\n",
            "# the following to \n",
            "~/.bash_profile if it exists, otherwise ~/.profile (for login shells)\n",
            "and ~/.bashrc (for interactive shells) :\n",
            "\n",
            "export PYENV_ROOT=\"$HOME/.pyenv\"\n",
            "command -v pyenv >/dev/null || export PATH=\"$PYENV_ROOT/bin:$PATH\"\n",
            "eval \"$(pyenv init -)\"\n",
            "\n",
            "# Restart your shell for the changes to take effect.\n",
            "\n",
            "# Load pyenv-virtualenv automatically by adding\n",
            "# the following to ~/.bashrc:\n",
            "\n",
            "eval \"$(pyenv virtualenv-init -)\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step by step process on SHELL below\n",
        "1. pyenv install 3.8.11\n",
        "2. pyenv local 3.8.11\n",
        "3. python -m venv venv --prompt ai8x-training\n",
        "4. source venv/bin/activate\n",
        "5. pip3 install -U pip wheel setuptools\n",
        "6. pip3 install -r requirements-cu11.txt\n",
        "7. pip3 install -r requirements.txt\n",
        "8. chmod +x /content/ai8x-training/scripts/train_smart_echo_net.sh\n",
        "9. scripts/train_smart_echo_net.sh\n"
      ],
      "metadata": {
        "id": "2fCSvb-n8a5y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2Xpi2FdbMJx",
        "outputId": "e1c1c822-354a-407a-eb22-0365c567d4dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "==> Confusion:\n",
            "[[117  41  16   0   0   0]\n",
            " [ 45  57   4   0   0   0]\n",
            " [ 14  12 124  15   0   0]\n",
            " [  0   1  13 171  18   0]\n",
            " [  0   0   2  38 173   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 75.842   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 56]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [69][   10/   31]    Overall Loss 0.000295    Objective Loss 0.000295                                        LR 0.001000    Time 0.112776    \n",
            "Epoch: [69][   20/   31]    Overall Loss 0.000301    Objective Loss 0.000301                                        LR 0.001000    Time 0.084415    \n",
            "Epoch: [69][   30/   31]    Overall Loss 0.000315    Objective Loss 0.000315    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.069139    \n",
            "Epoch: [69][   31/   31]    Overall Loss 0.000312    Objective Loss 0.000312    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.068121    \n",
            "--- validate (epoch=69)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [69][    4/    4]    Loss 1.540524    Top1 75.145180    Top5 100.000000    \n",
            "==> Top1: 75.145    Top5: 100.000    Loss: 1.541\n",
            "\n",
            "==> Confusion:\n",
            "[[116  44  14   0   0   0]\n",
            " [ 43  58   5   0   0   0]\n",
            " [ 15  10 126  14   0   0]\n",
            " [  1   1   9 177  15   0]\n",
            " [  0   0   2  41 170   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 75.842   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 56]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [70][   10/   31]    Overall Loss 0.000311    Objective Loss 0.000311                                        LR 0.001000    Time 0.205703    \n",
            "Epoch: [70][   20/   31]    Overall Loss 0.000331    Objective Loss 0.000331                                        LR 0.001000    Time 0.148061    \n",
            "Epoch: [70][   30/   31]    Overall Loss 0.000334    Objective Loss 0.000334    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.117903    \n",
            "Epoch: [70][   31/   31]    Overall Loss 0.000337    Objective Loss 0.000337    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.115507    \n",
            "--- validate (epoch=70)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [70][    4/    4]    Loss 1.626930    Top1 75.609756    Top5 100.000000    \n",
            "==> Top1: 75.610    Top5: 100.000    Loss: 1.627\n",
            "\n",
            "==> Confusion:\n",
            "[[117  43  14   0   0   0]\n",
            " [ 43  59   4   0   0   0]\n",
            " [ 15  10 127  13   0   0]\n",
            " [  1   1  11 179  11   0]\n",
            " [  0   0   2  42 169   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 75.842   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 56]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [71][   10/   31]    Overall Loss 0.000308    Objective Loss 0.000308                                        LR 0.001000    Time 0.170327    \n",
            "Epoch: [71][   20/   31]    Overall Loss 0.000315    Objective Loss 0.000315                                        LR 0.001000    Time 0.129693    \n",
            "Epoch: [71][   30/   31]    Overall Loss 0.000308    Objective Loss 0.000308    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.105165    \n",
            "Epoch: [71][   31/   31]    Overall Loss 0.000311    Objective Loss 0.000311    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.103094    \n",
            "--- validate (epoch=71)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [71][    4/    4]    Loss 1.614687    Top1 75.145180    Top5 100.000000    \n",
            "==> Top1: 75.145    Top5: 100.000    Loss: 1.615\n",
            "\n",
            "==> Confusion:\n",
            "[[117  44  13   0   0   0]\n",
            " [ 43  58   5   0   0   0]\n",
            " [ 15  10 127  13   0   0]\n",
            " [  1   1  11 174  16   0]\n",
            " [  0   0   2  40 171   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 75.842   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 56]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [72][   10/   31]    Overall Loss 0.000303    Objective Loss 0.000303                                        LR 0.001000    Time 0.178085    \n",
            "Epoch: [72][   20/   31]    Overall Loss 0.000302    Objective Loss 0.000302                                        LR 0.001000    Time 0.136577    \n",
            "Epoch: [72][   30/   31]    Overall Loss 0.000299    Objective Loss 0.000299    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.109255    \n",
            "Epoch: [72][   31/   31]    Overall Loss 0.000297    Objective Loss 0.000297    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.106739    \n",
            "--- validate (epoch=72)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [72][    4/    4]    Loss 1.577352    Top1 75.029036    Top5 100.000000    \n",
            "==> Top1: 75.029    Top5: 100.000    Loss: 1.577\n",
            "\n",
            "==> Confusion:\n",
            "[[117  40  17   0   0   0]\n",
            " [ 41  57   8   0   0   0]\n",
            " [ 14   9 126  16   0   0]\n",
            " [  0   1  13 172  17   0]\n",
            " [  0   0   1  38 174   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 75.842   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 56]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [73][   10/   31]    Overall Loss 0.000286    Objective Loss 0.000286                                        LR 0.001000    Time 0.111827    \n",
            "Epoch: [73][   20/   31]    Overall Loss 0.000290    Objective Loss 0.000290                                        LR 0.001000    Time 0.083376    \n",
            "Epoch: [73][   30/   31]    Overall Loss 0.000285    Objective Loss 0.000285    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.068617    \n",
            "Epoch: [73][   31/   31]    Overall Loss 0.000282    Objective Loss 0.000282    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.067347    \n",
            "--- validate (epoch=73)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [73][    4/    4]    Loss 1.601091    Top1 75.842044    Top5 100.000000    \n",
            "==> Top1: 75.842    Top5: 100.000    Loss: 1.601\n",
            "\n",
            "==> Confusion:\n",
            "[[122  40  12   0   0   0]\n",
            " [ 45  58   3   0   0   0]\n",
            " [ 15  10 126  14   0   0]\n",
            " [  0   1  13 173  16   0]\n",
            " [  0   0   2  37 174   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 75.842   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 73]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [74][   10/   31]    Overall Loss 0.000274    Objective Loss 0.000274                                        LR 0.001000    Time 0.113959    \n",
            "Epoch: [74][   20/   31]    Overall Loss 0.000280    Objective Loss 0.000280                                        LR 0.001000    Time 0.084783    \n",
            "Epoch: [74][   30/   31]    Overall Loss 0.000281    Objective Loss 0.000281    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.069154    \n",
            "Epoch: [74][   31/   31]    Overall Loss 0.000282    Objective Loss 0.000282    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.067896    \n",
            "--- validate (epoch=74)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [74][    4/    4]    Loss 1.559822    Top1 75.493612    Top5 100.000000    \n",
            "==> Top1: 75.494    Top5: 100.000    Loss: 1.560\n",
            "\n",
            "==> Confusion:\n",
            "[[119  41  14   0   0   0]\n",
            " [ 43  58   5   0   0   0]\n",
            " [ 14  10 127  14   0   0]\n",
            " [  0   1  13 174  15   0]\n",
            " [  0   0   1  40 172   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 75.842   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 73]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [75][   10/   31]    Overall Loss 0.000266    Objective Loss 0.000266                                        LR 0.001000    Time 0.111249    \n",
            "Epoch: [75][   20/   31]    Overall Loss 0.000273    Objective Loss 0.000273                                        LR 0.001000    Time 0.083914    \n",
            "Epoch: [75][   30/   31]    Overall Loss 0.000268    Objective Loss 0.000268    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.068968    \n",
            "Epoch: [75][   31/   31]    Overall Loss 0.000266    Objective Loss 0.000266    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.067682    \n",
            "--- validate (epoch=75)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [75][    4/    4]    Loss 1.518761    Top1 75.145180    Top5 100.000000    \n",
            "==> Top1: 75.145    Top5: 100.000    Loss: 1.519\n",
            "\n",
            "==> Confusion:\n",
            "[[113  45  16   0   0   0]\n",
            " [ 44  57   5   0   0   0]\n",
            " [ 16   9 124  16   0   0]\n",
            " [  0   1  10 178  14   0]\n",
            " [  0   0   1  37 175   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 75.842   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 73]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [76][   10/   31]    Overall Loss 0.000261    Objective Loss 0.000261                                        LR 0.001000    Time 0.158173    \n",
            "Epoch: [76][   20/   31]    Overall Loss 0.000257    Objective Loss 0.000257                                        LR 0.001000    Time 0.124599    \n",
            "Epoch: [76][   30/   31]    Overall Loss 0.000253    Objective Loss 0.000253    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.100676    \n",
            "Epoch: [76][   31/   31]    Overall Loss 0.000256    Objective Loss 0.000256    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.098649    \n",
            "--- validate (epoch=76)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [76][    4/    4]    Loss 1.605748    Top1 75.842044    Top5 100.000000    \n",
            "==> Top1: 75.842    Top5: 100.000    Loss: 1.606\n",
            "\n",
            "==> Confusion:\n",
            "[[119  42  13   0   0   0]\n",
            " [ 44  58   4   0   0   0]\n",
            " [ 15  10 127  13   0   0]\n",
            " [  0   1  11 175  16   0]\n",
            " [  0   0   1  38 174   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 75.842   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 76]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [77][   10/   31]    Overall Loss 0.000262    Objective Loss 0.000262                                        LR 0.001000    Time 0.170542    \n",
            "Epoch: [77][   20/   31]    Overall Loss 0.000261    Objective Loss 0.000261                                        LR 0.001000    Time 0.129313    \n",
            "Epoch: [77][   30/   31]    Overall Loss 0.000259    Objective Loss 0.000259    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.106218    \n",
            "Epoch: [77][   31/   31]    Overall Loss 0.000259    Objective Loss 0.000259    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.104062    \n",
            "--- validate (epoch=77)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [77][    4/    4]    Loss 1.604321    Top1 75.842044    Top5 100.000000    \n",
            "==> Top1: 75.842    Top5: 100.000    Loss: 1.604\n",
            "\n",
            "==> Confusion:\n",
            "[[120  41  13   0   0   0]\n",
            " [ 43  58   5   0   0   0]\n",
            " [ 15  10 127  13   0   0]\n",
            " [  0   1  11 175  16   0]\n",
            " [  0   0   2  38 173   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 75.842   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 77]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [78][   10/   31]    Overall Loss 0.000230    Objective Loss 0.000230                                        LR 0.001000    Time 0.178664    \n",
            "Epoch: [78][   20/   31]    Overall Loss 0.000234    Objective Loss 0.000234                                        LR 0.001000    Time 0.134511    \n",
            "Epoch: [78][   30/   31]    Overall Loss 0.000239    Objective Loss 0.000239    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.110433    \n",
            "Epoch: [78][   31/   31]    Overall Loss 0.000248    Objective Loss 0.000248    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.108154    \n",
            "--- validate (epoch=78)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [78][    4/    4]    Loss 1.711363    Top1 75.261324    Top5 100.000000    \n",
            "==> Top1: 75.261    Top5: 100.000    Loss: 1.711\n",
            "\n",
            "==> Confusion:\n",
            "[[114  42  18   0   0   0]\n",
            " [ 41  58   7   0   0   0]\n",
            " [ 14   9 127  15   0   0]\n",
            " [  0   1  11 175  16   0]\n",
            " [  0   0   2  37 174   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 75.842   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 77]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [79][   10/   31]    Overall Loss 0.000258    Objective Loss 0.000258                                        LR 0.001000    Time 0.140860    \n",
            "Epoch: [79][   20/   31]    Overall Loss 0.000259    Objective Loss 0.000259                                        LR 0.001000    Time 0.098496    \n",
            "Epoch: [79][   30/   31]    Overall Loss 0.000258    Objective Loss 0.000258    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.078912    \n",
            "Epoch: [79][   31/   31]    Overall Loss 0.000260    Objective Loss 0.000260    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.077319    \n",
            "--- validate (epoch=79)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [79][    4/    4]    Loss 1.564113    Top1 76.074332    Top5 100.000000    \n",
            "==> Top1: 76.074    Top5: 100.000    Loss: 1.564\n",
            "\n",
            "==> Confusion:\n",
            "[[121  38  15   0   0   0]\n",
            " [ 41  58   7   0   0   0]\n",
            " [ 15   9 128  13   0   0]\n",
            " [  0   1  11 177  14   0]\n",
            " [  0   0   2  40 171   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.074   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 79]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [80][   10/   31]    Overall Loss 0.000247    Objective Loss 0.000247                                        LR 0.001000    Time 0.112345    \n",
            "Epoch: [80][   20/   31]    Overall Loss 0.000238    Objective Loss 0.000238                                        LR 0.001000    Time 0.084416    \n",
            "Epoch: [80][   30/   31]    Overall Loss 0.000240    Objective Loss 0.000240    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.069690    \n",
            "Epoch: [80][   31/   31]    Overall Loss 0.000240    Objective Loss 0.000240    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.068423    \n",
            "--- validate (epoch=80)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [80][    4/    4]    Loss 1.689117    Top1 76.306620    Top5 100.000000    \n",
            "==> Top1: 76.307    Top5: 100.000    Loss: 1.689\n",
            "\n",
            "==> Confusion:\n",
            "[[121  39  14   0   0   0]\n",
            " [ 40  60   6   0   0   0]\n",
            " [ 13  11 129  12   0   0]\n",
            " [  0   1  12 174  16   0]\n",
            " [  0   0   2  38 173   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [81][   10/   31]    Overall Loss 0.000230    Objective Loss 0.000230                                        LR 0.001000    Time 0.117209    \n",
            "Epoch: [81][   20/   31]    Overall Loss 0.000226    Objective Loss 0.000226                                        LR 0.001000    Time 0.086373    \n",
            "Epoch: [81][   30/   31]    Overall Loss 0.000228    Objective Loss 0.000228    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.071052    \n",
            "Epoch: [81][   31/   31]    Overall Loss 0.000225    Objective Loss 0.000225    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.069775    \n",
            "--- validate (epoch=81)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [81][    4/    4]    Loss 1.537247    Top1 75.725900    Top5 100.000000    \n",
            "==> Top1: 75.726    Top5: 100.000    Loss: 1.537\n",
            "\n",
            "==> Confusion:\n",
            "[[120  40  14   0   0   0]\n",
            " [ 43  57   6   0   0   0]\n",
            " [ 14  11 126  14   0   0]\n",
            " [  1   1  10 175  16   0]\n",
            " [  0   0   3  36 174   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [82][   10/   31]    Overall Loss 0.000221    Objective Loss 0.000221                                        LR 0.001000    Time 0.114889    \n",
            "Epoch: [82][   20/   31]    Overall Loss 0.000224    Objective Loss 0.000224                                        LR 0.001000    Time 0.086069    \n",
            "Epoch: [82][   30/   31]    Overall Loss 0.000230    Objective Loss 0.000230    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.073708    \n",
            "Epoch: [82][   31/   31]    Overall Loss 0.000229    Objective Loss 0.000229    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.072563    \n",
            "--- validate (epoch=82)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [82][    4/    4]    Loss 1.589762    Top1 74.912892    Top5 100.000000    \n",
            "==> Top1: 74.913    Top5: 100.000    Loss: 1.590\n",
            "\n",
            "==> Confusion:\n",
            "[[117  42  15   0   0   0]\n",
            " [ 44  56   6   0   0   0]\n",
            " [ 14  11 124  16   0   0]\n",
            " [  0   1  11 175  16   0]\n",
            " [  0   0   2  38 173   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [83][   10/   31]    Overall Loss 0.000230    Objective Loss 0.000230                                        LR 0.001000    Time 0.179444    \n",
            "Epoch: [83][   20/   31]    Overall Loss 0.000228    Objective Loss 0.000228                                        LR 0.001000    Time 0.137421    \n",
            "Epoch: [83][   30/   31]    Overall Loss 0.000225    Objective Loss 0.000225    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.110882    \n",
            "Epoch: [83][   31/   31]    Overall Loss 0.000222    Objective Loss 0.000222    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.108696    \n",
            "--- validate (epoch=83)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [83][    4/    4]    Loss 1.602254    Top1 74.912892    Top5 100.000000    \n",
            "==> Top1: 74.913    Top5: 100.000    Loss: 1.602\n",
            "\n",
            "==> Confusion:\n",
            "[[119  41  14   0   0   0]\n",
            " [ 43  58   5   0   0   0]\n",
            " [ 15  10 125  15   0   0]\n",
            " [  1   1  12 169  20   0]\n",
            " [  0   0   2  37 174   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [84][   10/   31]    Overall Loss 0.000235    Objective Loss 0.000235                                        LR 0.001000    Time 0.174232    \n",
            "Epoch: [84][   20/   31]    Overall Loss 0.000223    Objective Loss 0.000223                                        LR 0.001000    Time 0.133755    \n",
            "Epoch: [84][   30/   31]    Overall Loss 0.000220    Objective Loss 0.000220    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.109958    \n",
            "Epoch: [84][   31/   31]    Overall Loss 0.000219    Objective Loss 0.000219    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.107704    \n",
            "--- validate (epoch=84)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [84][    4/    4]    Loss 1.563072    Top1 75.029036    Top5 100.000000    \n",
            "==> Top1: 75.029    Top5: 100.000    Loss: 1.563\n",
            "\n",
            "==> Confusion:\n",
            "[[118  39  17   0   0   0]\n",
            " [ 43  58   5   0   0   0]\n",
            " [ 15  10 123  17   0   0]\n",
            " [  0   1  12 173  17   0]\n",
            " [  0   0   2  37 174   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [85][   10/   31]    Overall Loss 0.000204    Objective Loss 0.000204                                        LR 0.001000    Time 0.176468    \n",
            "Epoch: [85][   20/   31]    Overall Loss 0.000208    Objective Loss 0.000208                                        LR 0.001000    Time 0.132842    \n",
            "Epoch: [85][   30/   31]    Overall Loss 0.000210    Objective Loss 0.000210    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.104487    \n",
            "Epoch: [85][   31/   31]    Overall Loss 0.000207    Objective Loss 0.000207    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.102074    \n",
            "--- validate (epoch=85)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [85][    4/    4]    Loss 1.516156    Top1 74.564460    Top5 100.000000    \n",
            "==> Top1: 74.564    Top5: 100.000    Loss: 1.516\n",
            "\n",
            "==> Confusion:\n",
            "[[115  43  16   0   0   0]\n",
            " [ 42  58   6   0   0   0]\n",
            " [ 14  11 125  15   0   0]\n",
            " [  0   1  12 170  20   0]\n",
            " [  0   0   2  37 174   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [86][   10/   31]    Overall Loss 0.000201    Objective Loss 0.000201                                        LR 0.001000    Time 0.112401    \n",
            "Epoch: [86][   20/   31]    Overall Loss 0.000205    Objective Loss 0.000205                                        LR 0.001000    Time 0.084035    \n",
            "Epoch: [86][   30/   31]    Overall Loss 0.000210    Objective Loss 0.000210    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.069601    \n",
            "Epoch: [86][   31/   31]    Overall Loss 0.000206    Objective Loss 0.000206    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.068385    \n",
            "--- validate (epoch=86)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [86][    4/    4]    Loss 1.588152    Top1 74.912892    Top5 100.000000    \n",
            "==> Top1: 74.913    Top5: 100.000    Loss: 1.588\n",
            "\n",
            "==> Confusion:\n",
            "[[117  42  15   0   0   0]\n",
            " [ 44  57   5   0   0   0]\n",
            " [ 14  11 126  14   0   0]\n",
            " [  0   1  13 172  17   0]\n",
            " [  0   0   2  38 173   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [87][   10/   31]    Overall Loss 0.000198    Objective Loss 0.000198                                        LR 0.001000    Time 0.112820    \n",
            "Epoch: [87][   20/   31]    Overall Loss 0.000202    Objective Loss 0.000202                                        LR 0.001000    Time 0.083450    \n",
            "Epoch: [87][   30/   31]    Overall Loss 0.000201    Objective Loss 0.000201    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.069030    \n",
            "Epoch: [87][   31/   31]    Overall Loss 0.000205    Objective Loss 0.000205    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.067788    \n",
            "--- validate (epoch=87)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [87][    4/    4]    Loss 1.614862    Top1 75.725900    Top5 100.000000    \n",
            "==> Top1: 75.726    Top5: 100.000    Loss: 1.615\n",
            "\n",
            "==> Confusion:\n",
            "[[120  40  14   0   0   0]\n",
            " [ 43  58   5   0   0   0]\n",
            " [ 13  11 127  14   0   0]\n",
            " [  0   0  13 174  16   0]\n",
            " [  0   0   1  39 173   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [88][   10/   31]    Overall Loss 0.000199    Objective Loss 0.000199                                        LR 0.001000    Time 0.111884    \n",
            "Epoch: [88][   20/   31]    Overall Loss 0.000195    Objective Loss 0.000195                                        LR 0.001000    Time 0.082787    \n",
            "Epoch: [88][   30/   31]    Overall Loss 0.000197    Objective Loss 0.000197    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.068439    \n",
            "Epoch: [88][   31/   31]    Overall Loss 0.000199    Objective Loss 0.000199    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.067196    \n",
            "--- validate (epoch=88)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [88][    4/    4]    Loss 1.623195    Top1 75.145180    Top5 100.000000    \n",
            "==> Top1: 75.145    Top5: 100.000    Loss: 1.623\n",
            "\n",
            "==> Confusion:\n",
            "[[114  44  16   0   0   0]\n",
            " [ 42  59   5   0   0   0]\n",
            " [ 16  10 126  13   0   0]\n",
            " [  0   0  13 176  14   0]\n",
            " [  0   0   3  38 172   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [89][   10/   31]    Overall Loss 0.000194    Objective Loss 0.000194                                        LR 0.001000    Time 0.201107    \n",
            "Epoch: [89][   20/   31]    Overall Loss 0.000194    Objective Loss 0.000194                                        LR 0.001000    Time 0.147657    \n",
            "Epoch: [89][   30/   31]    Overall Loss 0.000192    Objective Loss 0.000192    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.116748    \n",
            "Epoch: [89][   31/   31]    Overall Loss 0.000189    Objective Loss 0.000189    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.114261    \n",
            "--- validate (epoch=89)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [89][    4/    4]    Loss 1.621525    Top1 75.261324    Top5 100.000000    \n",
            "==> Top1: 75.261    Top5: 100.000    Loss: 1.622\n",
            "\n",
            "==> Confusion:\n",
            "[[118  42  14   0   0   0]\n",
            " [ 44  57   5   0   0   0]\n",
            " [ 15  10 125  15   0   0]\n",
            " [  0   1  12 175  15   0]\n",
            " [  0   0   2  38 173   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [90][   10/   31]    Overall Loss 0.000189    Objective Loss 0.000189                                        LR 0.001000    Time 0.169314    \n",
            "Epoch: [90][   20/   31]    Overall Loss 0.000187    Objective Loss 0.000187                                        LR 0.001000    Time 0.130715    \n",
            "Epoch: [90][   30/   31]    Overall Loss 0.000186    Objective Loss 0.000186    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.106251    \n",
            "Epoch: [90][   31/   31]    Overall Loss 0.000184    Objective Loss 0.000184    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.104144    \n",
            "--- validate (epoch=90)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [90][    4/    4]    Loss 1.563269    Top1 75.842044    Top5 100.000000    \n",
            "==> Top1: 75.842    Top5: 100.000    Loss: 1.563\n",
            "\n",
            "==> Confusion:\n",
            "[[120  41  13   0   0   0]\n",
            " [ 44  57   5   0   0   0]\n",
            " [ 15  10 126  14   0   0]\n",
            " [  0   1  12 176  14   0]\n",
            " [  0   0   2  37 174   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [91][   10/   31]    Overall Loss 0.000164    Objective Loss 0.000164                                        LR 0.001000    Time 0.167394    \n",
            "Epoch: [91][   20/   31]    Overall Loss 0.000169    Objective Loss 0.000169                                        LR 0.001000    Time 0.128669    \n",
            "Epoch: [91][   30/   31]    Overall Loss 0.000174    Objective Loss 0.000174    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.106393    \n",
            "Epoch: [91][   31/   31]    Overall Loss 0.000172    Objective Loss 0.000172    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.104241    \n",
            "--- validate (epoch=91)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [91][    4/    4]    Loss 1.686656    Top1 75.493612    Top5 100.000000    \n",
            "==> Top1: 75.494    Top5: 100.000    Loss: 1.687\n",
            "\n",
            "==> Confusion:\n",
            "[[116  44  14   0   0   0]\n",
            " [ 42  58   6   0   0   0]\n",
            " [ 15  10 127  13   0   0]\n",
            " [  0   1  12 174  16   0]\n",
            " [  0   0   1  37 175   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [92][   10/   31]    Overall Loss 0.000172    Objective Loss 0.000172                                        LR 0.001000    Time 0.114782    \n",
            "Epoch: [92][   20/   31]    Overall Loss 0.000169    Objective Loss 0.000169                                        LR 0.001000    Time 0.085792    \n",
            "Epoch: [92][   30/   31]    Overall Loss 0.000173    Objective Loss 0.000173    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.070439    \n",
            "Epoch: [92][   31/   31]    Overall Loss 0.000171    Objective Loss 0.000171    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.069114    \n",
            "--- validate (epoch=92)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [92][    4/    4]    Loss 1.587512    Top1 75.261324    Top5 100.000000    \n",
            "==> Top1: 75.261    Top5: 100.000    Loss: 1.588\n",
            "\n",
            "==> Confusion:\n",
            "[[116  43  15   0   0   0]\n",
            " [ 42  59   5   0   0   0]\n",
            " [ 15  10 126  14   0   0]\n",
            " [  1   1  10 177  14   0]\n",
            " [  0   0   2  41 170   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [93][   10/   31]    Overall Loss 0.000167    Objective Loss 0.000167                                        LR 0.001000    Time 0.110928    \n",
            "Epoch: [93][   20/   31]    Overall Loss 0.000170    Objective Loss 0.000170                                        LR 0.001000    Time 0.084211    \n",
            "Epoch: [93][   30/   31]    Overall Loss 0.000167    Objective Loss 0.000167    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.069636    \n",
            "Epoch: [93][   31/   31]    Overall Loss 0.000167    Objective Loss 0.000167    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.068369    \n",
            "--- validate (epoch=93)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [93][    4/    4]    Loss 1.646722    Top1 75.029036    Top5 100.000000    \n",
            "==> Top1: 75.029    Top5: 100.000    Loss: 1.647\n",
            "\n",
            "==> Confusion:\n",
            "[[116  42  16   0   0   0]\n",
            " [ 44  57   5   0   0   0]\n",
            " [ 15  10 126  14   0   0]\n",
            " [  0   1  13 173  16   0]\n",
            " [  0   0   2  37 174   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [94][   10/   31]    Overall Loss 0.000164    Objective Loss 0.000164                                        LR 0.001000    Time 0.114427    \n",
            "Epoch: [94][   20/   31]    Overall Loss 0.000164    Objective Loss 0.000164                                        LR 0.001000    Time 0.085359    \n",
            "Epoch: [94][   30/   31]    Overall Loss 0.000163    Objective Loss 0.000163    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.069758    \n",
            "Epoch: [94][   31/   31]    Overall Loss 0.000163    Objective Loss 0.000163    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.068367    \n",
            "--- validate (epoch=94)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [94][    4/    4]    Loss 1.717350    Top1 75.029036    Top5 100.000000    \n",
            "==> Top1: 75.029    Top5: 100.000    Loss: 1.717\n",
            "\n",
            "==> Confusion:\n",
            "[[116  43  15   0   0   0]\n",
            " [ 42  59   5   0   0   0]\n",
            " [ 14  10 125  16   0   0]\n",
            " [  0   1  12 176  14   0]\n",
            " [  0   0   2  41 170   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [95][   10/   31]    Overall Loss 0.000162    Objective Loss 0.000162                                        LR 0.001000    Time 0.192031    \n",
            "Epoch: [95][   20/   31]    Overall Loss 0.000160    Objective Loss 0.000160                                        LR 0.001000    Time 0.147456    \n",
            "Epoch: [95][   30/   31]    Overall Loss 0.000160    Objective Loss 0.000160    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.121280    \n",
            "Epoch: [95][   31/   31]    Overall Loss 0.000157    Objective Loss 0.000157    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.119313    \n",
            "--- validate (epoch=95)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [95][    4/    4]    Loss 1.590802    Top1 74.796748    Top5 100.000000    \n",
            "==> Top1: 74.797    Top5: 100.000    Loss: 1.591\n",
            "\n",
            "==> Confusion:\n",
            "[[116  41  17   0   0   0]\n",
            " [ 42  58   6   0   0   0]\n",
            " [ 14  10 125  16   0   0]\n",
            " [  0   1  12 172  18   0]\n",
            " [  0   0   2  38 173   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [96][   10/   31]    Overall Loss 0.000155    Objective Loss 0.000155                                        LR 0.001000    Time 0.209102    \n",
            "Epoch: [96][   20/   31]    Overall Loss 0.000157    Objective Loss 0.000157                                        LR 0.001000    Time 0.160745    \n",
            "Epoch: [96][   30/   31]    Overall Loss 0.000155    Objective Loss 0.000155    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.132045    \n",
            "Epoch: [96][   31/   31]    Overall Loss 0.000153    Objective Loss 0.000153    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.129893    \n",
            "--- validate (epoch=96)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [96][    4/    4]    Loss 1.678795    Top1 74.912892    Top5 100.000000    \n",
            "==> Top1: 74.913    Top5: 100.000    Loss: 1.679\n",
            "\n",
            "==> Confusion:\n",
            "[[117  42  15   0   0   0]\n",
            " [ 43  58   5   0   0   0]\n",
            " [ 16  10 123  16   0   0]\n",
            " [  0   1  12 175  15   0]\n",
            " [  0   0   2  39 172   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [97][   10/   31]    Overall Loss 0.000152    Objective Loss 0.000152                                        LR 0.001000    Time 0.220315    \n",
            "Epoch: [97][   20/   31]    Overall Loss 0.000155    Objective Loss 0.000155                                        LR 0.001000    Time 0.165317    \n",
            "Epoch: [97][   30/   31]    Overall Loss 0.000158    Objective Loss 0.000158    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.132147    \n",
            "Epoch: [97][   31/   31]    Overall Loss 0.000157    Objective Loss 0.000157    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.129265    \n",
            "--- validate (epoch=97)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [97][    4/    4]    Loss 1.655263    Top1 74.680604    Top5 100.000000    \n",
            "==> Top1: 74.681    Top5: 100.000    Loss: 1.655\n",
            "\n",
            "==> Confusion:\n",
            "[[113  47  14   0   0   0]\n",
            " [ 43  58   5   0   0   0]\n",
            " [ 14  10 125  16   0   0]\n",
            " [  1   1  11 174  16   0]\n",
            " [  0   0   2  38 173   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [98][   10/   31]    Overall Loss 0.000141    Objective Loss 0.000141                                        LR 0.001000    Time 0.144225    \n",
            "Epoch: [98][   20/   31]    Overall Loss 0.000150    Objective Loss 0.000150                                        LR 0.001000    Time 0.101150    \n",
            "Epoch: [98][   30/   31]    Overall Loss 0.000155    Objective Loss 0.000155    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.080376    \n",
            "Epoch: [98][   31/   31]    Overall Loss 0.000154    Objective Loss 0.000154    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.078778    \n",
            "--- validate (epoch=98)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [98][    4/    4]    Loss 1.652377    Top1 74.912892    Top5 100.000000    \n",
            "==> Top1: 74.913    Top5: 100.000    Loss: 1.652\n",
            "\n",
            "==> Confusion:\n",
            "[[113  44  17   0   0   0]\n",
            " [ 42  58   6   0   0   0]\n",
            " [ 15  10 126  14   0   0]\n",
            " [  1   1  10 173  18   0]\n",
            " [  0   0   1  37 175   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [99][   10/   31]    Overall Loss 0.000142    Objective Loss 0.000142                                        LR 0.001000    Time 0.115062    \n",
            "Epoch: [99][   20/   31]    Overall Loss 0.000139    Objective Loss 0.000139                                        LR 0.001000    Time 0.085975    \n",
            "Epoch: [99][   30/   31]    Overall Loss 0.000142    Objective Loss 0.000142    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.070409    \n",
            "Epoch: [99][   31/   31]    Overall Loss 0.000144    Objective Loss 0.000144    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.069098    \n",
            "--- validate (epoch=99)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [99][    4/    4]    Loss 1.508590    Top1 75.609756    Top5 100.000000    \n",
            "==> Top1: 75.610    Top5: 100.000    Loss: 1.509\n",
            "\n",
            "==> Confusion:\n",
            "[[118  42  14   0   0   0]\n",
            " [ 42  58   6   0   0   0]\n",
            " [ 14  10 125  16   0   0]\n",
            " [  0   1  13 175  14   0]\n",
            " [  0   0   2  36 175   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [100][   10/   31]    Overall Loss 0.000142    Objective Loss 0.000142                                        LR 0.000500    Time 0.114163    \n",
            "Epoch: [100][   20/   31]    Overall Loss 0.000139    Objective Loss 0.000139                                        LR 0.000500    Time 0.085452    \n",
            "Epoch: [100][   30/   31]    Overall Loss 0.000138    Objective Loss 0.000138    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.070536    \n",
            "Epoch: [100][   31/   31]    Overall Loss 0.000138    Objective Loss 0.000138    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.069213    \n",
            "--- validate (epoch=100)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [100][    4/    4]    Loss 1.684181    Top1 74.332172    Top5 100.000000    \n",
            "==> Top1: 74.332    Top5: 100.000    Loss: 1.684\n",
            "\n",
            "==> Confusion:\n",
            "[[115  46  13   0   0   0]\n",
            " [ 43  57   6   0   0   0]\n",
            " [ 14  11 125  15   0   0]\n",
            " [  0   1  12 173  17   0]\n",
            " [  0   0   2  41 170   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [101][   10/   31]    Overall Loss 0.000138    Objective Loss 0.000138                                        LR 0.000500    Time 0.113273    \n",
            "Epoch: [101][   20/   31]    Overall Loss 0.000143    Objective Loss 0.000143                                        LR 0.000500    Time 0.084239    \n",
            "Epoch: [101][   30/   31]    Overall Loss 0.000139    Objective Loss 0.000139    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.072589    \n",
            "Epoch: [101][   31/   31]    Overall Loss 0.000141    Objective Loss 0.000141    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.071427    \n",
            "--- validate (epoch=101)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [101][    4/    4]    Loss 1.588723    Top1 75.145180    Top5 100.000000    \n",
            "==> Top1: 75.145    Top5: 100.000    Loss: 1.589\n",
            "\n",
            "==> Confusion:\n",
            "[[117  41  16   0   0   0]\n",
            " [ 43  56   7   0   0   0]\n",
            " [ 13  11 126  15   0   0]\n",
            " [  0   1  12 174  16   0]\n",
            " [  0   0   2  37 174   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [102][   10/   31]    Overall Loss 0.000148    Objective Loss 0.000148                                        LR 0.000500    Time 0.185653    \n",
            "Epoch: [102][   20/   31]    Overall Loss 0.000141    Objective Loss 0.000141                                        LR 0.000500    Time 0.136181    \n",
            "Epoch: [102][   30/   31]    Overall Loss 0.000140    Objective Loss 0.000140    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.111743    \n",
            "Epoch: [102][   31/   31]    Overall Loss 0.000141    Objective Loss 0.000141    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.109547    \n",
            "--- validate (epoch=102)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [102][    4/    4]    Loss 1.584526    Top1 75.609756    Top5 100.000000    \n",
            "==> Top1: 75.610    Top5: 100.000    Loss: 1.585\n",
            "\n",
            "==> Confusion:\n",
            "[[119  41  14   0   0   0]\n",
            " [ 43  59   4   0   0   0]\n",
            " [ 15  11 124  15   0   0]\n",
            " [  0   1  13 175  14   0]\n",
            " [  0   0   2  37 174   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [103][   10/   31]    Overall Loss 0.000128    Objective Loss 0.000128                                        LR 0.000500    Time 0.212078    \n",
            "Epoch: [103][   20/   31]    Overall Loss 0.000133    Objective Loss 0.000133                                        LR 0.000500    Time 0.158408    \n",
            "Epoch: [103][   30/   31]    Overall Loss 0.000135    Objective Loss 0.000135    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.130805    \n",
            "Epoch: [103][   31/   31]    Overall Loss 0.000135    Objective Loss 0.000135    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.128418    \n",
            "--- validate (epoch=103)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [103][    4/    4]    Loss 1.548036    Top1 75.261324    Top5 100.000000    \n",
            "==> Top1: 75.261    Top5: 100.000    Loss: 1.548\n",
            "\n",
            "==> Confusion:\n",
            "[[120  39  15   0   0   0]\n",
            " [ 40  59   7   0   0   0]\n",
            " [ 13  11 125  16   0   0]\n",
            " [  1   1  11 173  17   0]\n",
            " [  0   0   2  40 171   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [104][   10/   31]    Overall Loss 0.000134    Objective Loss 0.000134                                        LR 0.000500    Time 0.199695    \n",
            "Epoch: [104][   20/   31]    Overall Loss 0.000134    Objective Loss 0.000134                                        LR 0.000500    Time 0.146926    \n",
            "Epoch: [104][   30/   31]    Overall Loss 0.000133    Objective Loss 0.000133    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.116621    \n",
            "Epoch: [104][   31/   31]    Overall Loss 0.000134    Objective Loss 0.000134    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.114114    \n",
            "--- validate (epoch=104)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [104][    4/    4]    Loss 1.591437    Top1 75.029036    Top5 100.000000    \n",
            "==> Top1: 75.029    Top5: 100.000    Loss: 1.591\n",
            "\n",
            "==> Confusion:\n",
            "[[117  41  16   0   0   0]\n",
            " [ 42  58   6   0   0   0]\n",
            " [ 14  12 124  15   0   0]\n",
            " [  0   1  13 174  15   0]\n",
            " [  0   0   2  38 173   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [105][   10/   31]    Overall Loss 0.000127    Objective Loss 0.000127                                        LR 0.000500    Time 0.172488    \n",
            "Epoch: [105][   20/   31]    Overall Loss 0.000128    Objective Loss 0.000128                                        LR 0.000500    Time 0.133790    \n",
            "Epoch: [105][   30/   31]    Overall Loss 0.000130    Objective Loss 0.000130    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.108540    \n",
            "Epoch: [105][   31/   31]    Overall Loss 0.000130    Objective Loss 0.000130    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.106454    \n",
            "--- validate (epoch=105)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [105][    4/    4]    Loss 1.581276    Top1 75.609756    Top5 100.000000    \n",
            "==> Top1: 75.610    Top5: 100.000    Loss: 1.581\n",
            "\n",
            "==> Confusion:\n",
            "[[118  42  14   0   0   0]\n",
            " [ 42  60   4   0   0   0]\n",
            " [ 15  11 125  14   0   0]\n",
            " [  0   1  13 176  13   0]\n",
            " [  0   0   1  40 172   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [106][   10/   31]    Overall Loss 0.000144    Objective Loss 0.000144                                        LR 0.000500    Time 0.126091    \n",
            "Epoch: [106][   20/   31]    Overall Loss 0.000137    Objective Loss 0.000137                                        LR 0.000500    Time 0.091860    \n",
            "Epoch: [106][   30/   31]    Overall Loss 0.000137    Objective Loss 0.000137    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.074130    \n",
            "Epoch: [106][   31/   31]    Overall Loss 0.000136    Objective Loss 0.000136    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.072663    \n",
            "--- validate (epoch=106)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [106][    4/    4]    Loss 1.650036    Top1 75.029036    Top5 100.000000    \n",
            "==> Top1: 75.029    Top5: 100.000    Loss: 1.650\n",
            "\n",
            "==> Confusion:\n",
            "[[115  44  15   0   0   0]\n",
            " [ 43  57   6   0   0   0]\n",
            " [ 13  11 127  14   0   0]\n",
            " [  0   1  13 173  16   0]\n",
            " [  0   0   2  37 174   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [107][   10/   31]    Overall Loss 0.000125    Objective Loss 0.000125                                        LR 0.000500    Time 0.179302    \n",
            "Epoch: [107][   20/   31]    Overall Loss 0.000124    Objective Loss 0.000124                                        LR 0.000500    Time 0.137287    \n",
            "Epoch: [107][   30/   31]    Overall Loss 0.000126    Objective Loss 0.000126    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.111516    \n",
            "Epoch: [107][   31/   31]    Overall Loss 0.000128    Objective Loss 0.000128    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.109222    \n",
            "--- validate (epoch=107)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [107][    4/    4]    Loss 1.645198    Top1 74.796748    Top5 100.000000    \n",
            "==> Top1: 74.797    Top5: 100.000    Loss: 1.645\n",
            "\n",
            "==> Confusion:\n",
            "[[117  41  16   0   0   0]\n",
            " [ 43  59   4   0   0   0]\n",
            " [ 12  13 124  16   0   0]\n",
            " [  1   1  12 171  18   0]\n",
            " [  0   0   1  39 173   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [108][   10/   31]    Overall Loss 0.000124    Objective Loss 0.000124                                        LR 0.000500    Time 0.168810    \n",
            "Epoch: [108][   20/   31]    Overall Loss 0.000126    Objective Loss 0.000126                                        LR 0.000500    Time 0.131563    \n",
            "Epoch: [108][   30/   31]    Overall Loss 0.000131    Objective Loss 0.000131    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.106556    \n",
            "Epoch: [108][   31/   31]    Overall Loss 0.000131    Objective Loss 0.000131    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.104400    \n",
            "--- validate (epoch=108)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [108][    4/    4]    Loss 1.755412    Top1 75.261324    Top5 100.000000    \n",
            "==> Top1: 75.261    Top5: 100.000    Loss: 1.755\n",
            "\n",
            "==> Confusion:\n",
            "[[118  42  14   0   0   0]\n",
            " [ 40  58   8   0   0   0]\n",
            " [ 13  12 126  14   0   0]\n",
            " [  0   1  12 173  17   0]\n",
            " [  0   0   2  38 173   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [109][   10/   31]    Overall Loss 0.000126    Objective Loss 0.000126                                        LR 0.000500    Time 0.175810    \n",
            "Epoch: [109][   20/   31]    Overall Loss 0.000126    Objective Loss 0.000126                                        LR 0.000500    Time 0.135962    \n",
            "Epoch: [109][   30/   31]    Overall Loss 0.000126    Objective Loss 0.000126    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.110362    \n",
            "Epoch: [109][   31/   31]    Overall Loss 0.000126    Objective Loss 0.000126    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.108115    \n",
            "--- validate (epoch=109)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [109][    4/    4]    Loss 1.680980    Top1 75.725900    Top5 100.000000    \n",
            "==> Top1: 75.726    Top5: 100.000    Loss: 1.681\n",
            "\n",
            "==> Confusion:\n",
            "[[119  42  13   0   0   0]\n",
            " [ 43  58   5   0   0   0]\n",
            " [ 15  10 125  15   0   0]\n",
            " [  0   0  12 175  16   0]\n",
            " [  0   0   2  36 175   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [110][   10/   31]    Overall Loss 0.000123    Objective Loss 0.000123                                        LR 0.000500    Time 0.110975    \n",
            "Epoch: [110][   20/   31]    Overall Loss 0.000131    Objective Loss 0.000131                                        LR 0.000500    Time 0.083258    \n",
            "Epoch: [110][   30/   31]    Overall Loss 0.000126    Objective Loss 0.000126    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.068425    \n",
            "Epoch: [110][   31/   31]    Overall Loss 0.000127    Objective Loss 0.000127    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.067169    \n",
            "--- validate (epoch=110)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [110][    4/    4]    Loss 1.703345    Top1 75.377468    Top5 100.000000    \n",
            "==> Top1: 75.377    Top5: 100.000    Loss: 1.703\n",
            "\n",
            "==> Confusion:\n",
            "[[117  43  14   0   0   0]\n",
            " [ 43  59   4   0   0   0]\n",
            " [ 14  10 125  16   0   0]\n",
            " [  0   1  12 173  17   0]\n",
            " [  0   0   2  36 175   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [111][   10/   31]    Overall Loss 0.000123    Objective Loss 0.000123                                        LR 0.000500    Time 0.136281    \n",
            "Epoch: [111][   20/   31]    Overall Loss 0.000123    Objective Loss 0.000123                                        LR 0.000500    Time 0.096256    \n",
            "Epoch: [111][   30/   31]    Overall Loss 0.000124    Objective Loss 0.000124    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.077631    \n",
            "Epoch: [111][   31/   31]    Overall Loss 0.000127    Objective Loss 0.000127    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.076113    \n",
            "--- validate (epoch=111)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [111][    4/    4]    Loss 1.724303    Top1 75.029036    Top5 100.000000    \n",
            "==> Top1: 75.029    Top5: 100.000    Loss: 1.724\n",
            "\n",
            "==> Confusion:\n",
            "[[115  43  16   0   0   0]\n",
            " [ 43  58   5   0   0   0]\n",
            " [ 13  11 126  15   0   0]\n",
            " [  0   0  14 173  16   0]\n",
            " [  0   0   2  37 174   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [112][   10/   31]    Overall Loss 0.000121    Objective Loss 0.000121                                        LR 0.000500    Time 0.114265    \n",
            "Epoch: [112][   20/   31]    Overall Loss 0.000129    Objective Loss 0.000129                                        LR 0.000500    Time 0.085742    \n",
            "Epoch: [112][   30/   31]    Overall Loss 0.000125    Objective Loss 0.000125    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.070408    \n",
            "Epoch: [112][   31/   31]    Overall Loss 0.000123    Objective Loss 0.000123    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.069107    \n",
            "--- validate (epoch=112)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [112][    4/    4]    Loss 1.640458    Top1 75.609756    Top5 100.000000    \n",
            "==> Top1: 75.610    Top5: 100.000    Loss: 1.640\n",
            "\n",
            "==> Confusion:\n",
            "[[118  42  14   0   0   0]\n",
            " [ 43  59   4   0   0   0]\n",
            " [ 16  10 126  13   0   0]\n",
            " [  1   1  11 174  16   0]\n",
            " [  0   0   2  37 174   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [113][   10/   31]    Overall Loss 0.000113    Objective Loss 0.000113                                        LR 0.000500    Time 0.153716    \n",
            "Epoch: [113][   20/   31]    Overall Loss 0.000117    Objective Loss 0.000117                                        LR 0.000500    Time 0.125426    \n",
            "Epoch: [113][   30/   31]    Overall Loss 0.000120    Objective Loss 0.000120    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.100797    \n",
            "Epoch: [113][   31/   31]    Overall Loss 0.000119    Objective Loss 0.000119    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.098819    \n",
            "--- validate (epoch=113)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [113][    4/    4]    Loss 1.562651    Top1 75.493612    Top5 100.000000    \n",
            "==> Top1: 75.494    Top5: 100.000    Loss: 1.563\n",
            "\n",
            "==> Confusion:\n",
            "[[118  41  15   0   0   0]\n",
            " [ 43  57   6   0   0   0]\n",
            " [ 14  11 125  15   0   0]\n",
            " [  1   0  11 176  15   0]\n",
            " [  0   0   1  38 174   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [114][   10/   31]    Overall Loss 0.000115    Objective Loss 0.000115                                        LR 0.000500    Time 0.175072    \n",
            "Epoch: [114][   20/   31]    Overall Loss 0.000115    Objective Loss 0.000115                                        LR 0.000500    Time 0.132293    \n",
            "Epoch: [114][   30/   31]    Overall Loss 0.000116    Objective Loss 0.000116    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.110976    \n",
            "Epoch: [114][   31/   31]    Overall Loss 0.000114    Objective Loss 0.000114    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.108708    \n",
            "--- validate (epoch=114)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [114][    4/    4]    Loss 1.724576    Top1 75.261324    Top5 100.000000    \n",
            "==> Top1: 75.261    Top5: 100.000    Loss: 1.725\n",
            "\n",
            "==> Confusion:\n",
            "[[116  43  15   0   0   0]\n",
            " [ 42  59   5   0   0   0]\n",
            " [ 14  11 125  15   0   0]\n",
            " [  0   1  12 175  15   0]\n",
            " [  0   0   1  39 173   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [115][   10/   31]    Overall Loss 0.000121    Objective Loss 0.000121                                        LR 0.000500    Time 0.169681    \n",
            "Epoch: [115][   20/   31]    Overall Loss 0.000118    Objective Loss 0.000118                                        LR 0.000500    Time 0.129960    \n",
            "Epoch: [115][   30/   31]    Overall Loss 0.000117    Objective Loss 0.000117    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.106361    \n",
            "Epoch: [115][   31/   31]    Overall Loss 0.000117    Objective Loss 0.000117    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.104210    \n",
            "--- validate (epoch=115)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [115][    4/    4]    Loss 1.725914    Top1 75.493612    Top5 100.000000    \n",
            "==> Top1: 75.494    Top5: 100.000    Loss: 1.726\n",
            "\n",
            "==> Confusion:\n",
            "[[117  41  16   0   0   0]\n",
            " [ 43  58   5   0   0   0]\n",
            " [ 14  11 126  14   0   0]\n",
            " [  0   1  11 175  16   0]\n",
            " [  0   0   1  38 174   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [116][   10/   31]    Overall Loss 0.000114    Objective Loss 0.000114                                        LR 0.000500    Time 0.137499    \n",
            "Epoch: [116][   20/   31]    Overall Loss 0.000112    Objective Loss 0.000112                                        LR 0.000500    Time 0.097171    \n",
            "Epoch: [116][   30/   31]    Overall Loss 0.000113    Objective Loss 0.000113    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.077865    \n",
            "Epoch: [116][   31/   31]    Overall Loss 0.000112    Objective Loss 0.000112    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.076298    \n",
            "--- validate (epoch=116)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [116][    4/    4]    Loss 1.632583    Top1 75.725900    Top5 100.000000    \n",
            "==> Top1: 75.726    Top5: 100.000    Loss: 1.633\n",
            "\n",
            "==> Confusion:\n",
            "[[118  40  16   0   0   0]\n",
            " [ 43  58   5   0   0   0]\n",
            " [ 14  10 127  14   0   0]\n",
            " [  0   0  12 176  15   0]\n",
            " [  0   0   2  38 173   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [117][   10/   31]    Overall Loss 0.000115    Objective Loss 0.000115                                        LR 0.000500    Time 0.113618    \n",
            "Epoch: [117][   20/   31]    Overall Loss 0.000111    Objective Loss 0.000111                                        LR 0.000500    Time 0.085442    \n",
            "Epoch: [117][   30/   31]    Overall Loss 0.000110    Objective Loss 0.000110    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.069522    \n",
            "Epoch: [117][   31/   31]    Overall Loss 0.000109    Objective Loss 0.000109    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.068258    \n",
            "--- validate (epoch=117)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [117][    4/    4]    Loss 1.630534    Top1 75.029036    Top5 100.000000    \n",
            "==> Top1: 75.029    Top5: 100.000    Loss: 1.631\n",
            "\n",
            "==> Confusion:\n",
            "[[117  43  14   0   0   0]\n",
            " [ 43  57   6   0   0   0]\n",
            " [ 15  10 125  15   0   0]\n",
            " [  1   1  10 174  17   0]\n",
            " [  0   0   2  38 173   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [118][   10/   31]    Overall Loss 0.000109    Objective Loss 0.000109                                        LR 0.000500    Time 0.120280    \n",
            "Epoch: [118][   20/   31]    Overall Loss 0.000112    Objective Loss 0.000112                                        LR 0.000500    Time 0.091041    \n",
            "Epoch: [118][   30/   31]    Overall Loss 0.000110    Objective Loss 0.000110    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.073527    \n",
            "Epoch: [118][   31/   31]    Overall Loss 0.000111    Objective Loss 0.000111    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.072104    \n",
            "--- validate (epoch=118)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [118][    4/    4]    Loss 1.718122    Top1 75.261324    Top5 100.000000    \n",
            "==> Top1: 75.261    Top5: 100.000    Loss: 1.718\n",
            "\n",
            "==> Confusion:\n",
            "[[116  42  16   0   0   0]\n",
            " [ 44  58   4   0   0   0]\n",
            " [ 14  11 126  14   0   0]\n",
            " [  0   1  11 175  16   0]\n",
            " [  0   0   2  38 173   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [119][   10/   31]    Overall Loss 0.000110    Objective Loss 0.000110                                        LR 0.000500    Time 0.116826    \n",
            "Epoch: [119][   20/   31]    Overall Loss 0.000109    Objective Loss 0.000109                                        LR 0.000500    Time 0.089136    \n",
            "Epoch: [119][   30/   31]    Overall Loss 0.000109    Objective Loss 0.000109    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.077342    \n",
            "Epoch: [119][   31/   31]    Overall Loss 0.000109    Objective Loss 0.000109    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.076066    \n",
            "--- validate (epoch=119)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [119][    4/    4]    Loss 1.689352    Top1 75.958188    Top5 100.000000    \n",
            "==> Top1: 75.958    Top5: 100.000    Loss: 1.689\n",
            "\n",
            "==> Confusion:\n",
            "[[117  41  16   0   0   0]\n",
            " [ 44  58   4   0   0   0]\n",
            " [ 16  10 126  13   0   0]\n",
            " [  0   1  10 177  15   0]\n",
            " [  0   0   1  36 176   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [120][   10/   31]    Overall Loss 0.000111    Objective Loss 0.000111                                        LR 0.000500    Time 0.175955    \n",
            "Epoch: [120][   20/   31]    Overall Loss 0.000111    Objective Loss 0.000111                                        LR 0.000500    Time 0.135313    \n",
            "Epoch: [120][   30/   31]    Overall Loss 0.000111    Objective Loss 0.000111    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.109095    \n",
            "Epoch: [120][   31/   31]    Overall Loss 0.000109    Objective Loss 0.000109    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.106822    \n",
            "--- validate (epoch=120)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [120][    4/    4]    Loss 1.586102    Top1 74.796748    Top5 100.000000    \n",
            "==> Top1: 74.797    Top5: 100.000    Loss: 1.586\n",
            "\n",
            "==> Confusion:\n",
            "[[114  44  16   0   0   0]\n",
            " [ 44  55   7   0   0   0]\n",
            " [ 13  11 127  14   0   0]\n",
            " [  0   1  12 173  17   0]\n",
            " [  0   0   2  36 175   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [121][   10/   31]    Overall Loss 0.000109    Objective Loss 0.000109                                        LR 0.000500    Time 0.179133    \n",
            "Epoch: [121][   20/   31]    Overall Loss 0.000107    Objective Loss 0.000107                                        LR 0.000500    Time 0.134589    \n",
            "Epoch: [121][   30/   31]    Overall Loss 0.000106    Objective Loss 0.000106    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.110232    \n",
            "Epoch: [121][   31/   31]    Overall Loss 0.000107    Objective Loss 0.000107    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.107973    \n",
            "--- validate (epoch=121)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [121][    4/    4]    Loss 1.583159    Top1 75.493612    Top5 100.000000    \n",
            "==> Top1: 75.494    Top5: 100.000    Loss: 1.583\n",
            "\n",
            "==> Confusion:\n",
            "[[117  40  17   0   0   0]\n",
            " [ 43  56   7   0   0   0]\n",
            " [ 11  13 126  15   0   0]\n",
            " [  1   1  11 175  15   0]\n",
            " [  0   0   1  36 176   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [122][   10/   31]    Overall Loss 0.000103    Objective Loss 0.000103                                        LR 0.000500    Time 0.174570    \n",
            "Epoch: [122][   20/   31]    Overall Loss 0.000104    Objective Loss 0.000104                                        LR 0.000500    Time 0.126352    \n",
            "Epoch: [122][   30/   31]    Overall Loss 0.000107    Objective Loss 0.000107    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.097504    \n",
            "Epoch: [122][   31/   31]    Overall Loss 0.000106    Objective Loss 0.000106    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.095328    \n",
            "--- validate (epoch=122)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [122][    4/    4]    Loss 1.703875    Top1 75.842044    Top5 100.000000    \n",
            "==> Top1: 75.842    Top5: 100.000    Loss: 1.704\n",
            "\n",
            "==> Confusion:\n",
            "[[117  42  15   0   0   0]\n",
            " [ 41  59   6   0   0   0]\n",
            " [ 14  11 125  15   0   0]\n",
            " [  0   1  12 176  14   0]\n",
            " [  0   0   1  36 176   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [123][   10/   31]    Overall Loss 0.000102    Objective Loss 0.000102                                        LR 0.000500    Time 0.113284    \n",
            "Epoch: [123][   20/   31]    Overall Loss 0.000110    Objective Loss 0.000110                                        LR 0.000500    Time 0.085201    \n",
            "Epoch: [123][   30/   31]    Overall Loss 0.000108    Objective Loss 0.000108    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.069902    \n",
            "Epoch: [123][   31/   31]    Overall Loss 0.000108    Objective Loss 0.000108    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.068589    \n",
            "--- validate (epoch=123)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [123][    4/    4]    Loss 1.573100    Top1 75.493612    Top5 100.000000    \n",
            "==> Top1: 75.494    Top5: 100.000    Loss: 1.573\n",
            "\n",
            "==> Confusion:\n",
            "[[120  39  15   0   0   0]\n",
            " [ 43  57   6   0   0   0]\n",
            " [ 14  12 124  15   0   0]\n",
            " [  1   1  11 173  17   0]\n",
            " [  0   0   1  36 176   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [124][   10/   31]    Overall Loss 0.000101    Objective Loss 0.000101                                        LR 0.000500    Time 0.113532    \n",
            "Epoch: [124][   20/   31]    Overall Loss 0.000102    Objective Loss 0.000102                                        LR 0.000500    Time 0.085477    \n",
            "Epoch: [124][   30/   31]    Overall Loss 0.000101    Objective Loss 0.000101    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.069983    \n",
            "Epoch: [124][   31/   31]    Overall Loss 0.000101    Objective Loss 0.000101    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.068661    \n",
            "--- validate (epoch=124)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [124][    4/    4]    Loss 1.649104    Top1 75.261324    Top5 100.000000    \n",
            "==> Top1: 75.261    Top5: 100.000    Loss: 1.649\n",
            "\n",
            "==> Confusion:\n",
            "[[118  42  14   0   0   0]\n",
            " [ 44  57   5   0   0   0]\n",
            " [ 15  10 126  14   0   0]\n",
            " [  0   1  13 172  17   0]\n",
            " [  0   0   1  37 175   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [125][   10/   31]    Overall Loss 0.000096    Objective Loss 0.000096                                        LR 0.000500    Time 0.117573    \n",
            "Epoch: [125][   20/   31]    Overall Loss 0.000103    Objective Loss 0.000103                                        LR 0.000500    Time 0.086963    \n",
            "Epoch: [125][   30/   31]    Overall Loss 0.000102    Objective Loss 0.000102    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.071047    \n",
            "Epoch: [125][   31/   31]    Overall Loss 0.000102    Objective Loss 0.000102    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.069730    \n",
            "--- validate (epoch=125)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [125][    4/    4]    Loss 1.619120    Top1 75.261324    Top5 100.000000    \n",
            "==> Top1: 75.261    Top5: 100.000    Loss: 1.619\n",
            "\n",
            "==> Confusion:\n",
            "[[116  46  12   0   0   0]\n",
            " [ 44  58   4   0   0   0]\n",
            " [ 15  10 127  13   0   0]\n",
            " [  1   1  12 174  15   0]\n",
            " [  0   0   2  38 173   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [126][   10/   31]    Overall Loss 0.000096    Objective Loss 0.000096                                        LR 0.000500    Time 0.183953    \n",
            "Epoch: [126][   20/   31]    Overall Loss 0.000095    Objective Loss 0.000095                                        LR 0.000500    Time 0.142677    \n",
            "Epoch: [126][   30/   31]    Overall Loss 0.000098    Objective Loss 0.000098    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.115207    \n",
            "Epoch: [126][   31/   31]    Overall Loss 0.000097    Objective Loss 0.000097    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.112826    \n",
            "--- validate (epoch=126)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [126][    4/    4]    Loss 1.737614    Top1 75.377468    Top5 100.000000    \n",
            "==> Top1: 75.377    Top5: 100.000    Loss: 1.738\n",
            "\n",
            "==> Confusion:\n",
            "[[117  42  15   0   0   0]\n",
            " [ 43  59   4   0   0   0]\n",
            " [ 14  11 125  15   0   0]\n",
            " [  0   1  12 174  16   0]\n",
            " [  0   0   2  37 174   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [127][   10/   31]    Overall Loss 0.000109    Objective Loss 0.000109                                        LR 0.000500    Time 0.173749    \n",
            "Epoch: [127][   20/   31]    Overall Loss 0.000105    Objective Loss 0.000105                                        LR 0.000500    Time 0.132631    \n",
            "Epoch: [127][   30/   31]    Overall Loss 0.000101    Objective Loss 0.000101    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.107393    \n",
            "Epoch: [127][   31/   31]    Overall Loss 0.000101    Objective Loss 0.000101    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.105269    \n",
            "--- validate (epoch=127)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [127][    4/    4]    Loss 1.602479    Top1 75.609756    Top5 100.000000    \n",
            "==> Top1: 75.610    Top5: 100.000    Loss: 1.602\n",
            "\n",
            "==> Confusion:\n",
            "[[116  43  15   0   0   0]\n",
            " [ 43  57   6   0   0   0]\n",
            " [ 15  10 126  14   0   0]\n",
            " [  0   1  11 178  13   0]\n",
            " [  0   0   2  37 174   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [128][   10/   31]    Overall Loss 0.000102    Objective Loss 0.000102                                        LR 0.000500    Time 0.170094    \n",
            "Epoch: [128][   20/   31]    Overall Loss 0.000102    Objective Loss 0.000102                                        LR 0.000500    Time 0.133049    \n",
            "Epoch: [128][   30/   31]    Overall Loss 0.000101    Objective Loss 0.000101    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.108488    \n",
            "Epoch: [128][   31/   31]    Overall Loss 0.000100    Objective Loss 0.000100    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.106315    \n",
            "--- validate (epoch=128)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [128][    4/    4]    Loss 1.634241    Top1 75.377468    Top5 100.000000    \n",
            "==> Top1: 75.377    Top5: 100.000    Loss: 1.634\n",
            "\n",
            "==> Confusion:\n",
            "[[116  43  15   0   0   0]\n",
            " [ 43  58   5   0   0   0]\n",
            " [ 13  11 126  15   0   0]\n",
            " [  0   1  13 173  16   0]\n",
            " [  0   0   1  36 176   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [129][   10/   31]    Overall Loss 0.000094    Objective Loss 0.000094                                        LR 0.000500    Time 0.116376    \n",
            "Epoch: [129][   20/   31]    Overall Loss 0.000099    Objective Loss 0.000099                                        LR 0.000500    Time 0.086620    \n",
            "Epoch: [129][   30/   31]    Overall Loss 0.000097    Objective Loss 0.000097    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.070393    \n",
            "Epoch: [129][   31/   31]    Overall Loss 0.000098    Objective Loss 0.000098    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.069092    \n",
            "--- validate (epoch=129)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [129][    4/    4]    Loss 1.645635    Top1 75.725900    Top5 100.000000    \n",
            "==> Top1: 75.726    Top5: 100.000    Loss: 1.646\n",
            "\n",
            "==> Confusion:\n",
            "[[119  41  14   0   0   0]\n",
            " [ 43  56   7   0   0   0]\n",
            " [ 14  11 127  13   0   0]\n",
            " [  0   1  12 175  15   0]\n",
            " [  0   0   1  37 175   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [130][   10/   31]    Overall Loss 0.000099    Objective Loss 0.000099                                        LR 0.000500    Time 0.114338    \n",
            "Epoch: [130][   20/   31]    Overall Loss 0.000100    Objective Loss 0.000100                                        LR 0.000500    Time 0.084988    \n",
            "Epoch: [130][   30/   31]    Overall Loss 0.000098    Objective Loss 0.000098    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.070202    \n",
            "Epoch: [130][   31/   31]    Overall Loss 0.000097    Objective Loss 0.000097    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.068940    \n",
            "--- validate (epoch=130)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [130][    4/    4]    Loss 1.667971    Top1 75.493612    Top5 100.000000    \n",
            "==> Top1: 75.494    Top5: 100.000    Loss: 1.668\n",
            "\n",
            "==> Confusion:\n",
            "[[117  42  15   0   0   0]\n",
            " [ 43  58   5   0   0   0]\n",
            " [ 13  12 125  15   0   0]\n",
            " [  0   1  12 175  15   0]\n",
            " [  0   0   1  37 175   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [131][   10/   31]    Overall Loss 0.000097    Objective Loss 0.000097                                        LR 0.000500    Time 0.112620    \n",
            "Epoch: [131][   20/   31]    Overall Loss 0.000094    Objective Loss 0.000094                                        LR 0.000500    Time 0.084301    \n",
            "Epoch: [131][   30/   31]    Overall Loss 0.000095    Objective Loss 0.000095    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.069682    \n",
            "Epoch: [131][   31/   31]    Overall Loss 0.000095    Objective Loss 0.000095    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.068394    \n",
            "--- validate (epoch=131)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [131][    4/    4]    Loss 1.688281    Top1 74.680604    Top5 100.000000    \n",
            "==> Top1: 74.681    Top5: 100.000    Loss: 1.688\n",
            "\n",
            "==> Confusion:\n",
            "[[116  44  14   0   0   0]\n",
            " [ 43  57   6   0   0   0]\n",
            " [ 15  11 122  17   0   0]\n",
            " [  0   1  12 175  15   0]\n",
            " [  0   0   1  39 173   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [132][   10/   31]    Overall Loss 0.000091    Objective Loss 0.000091                                        LR 0.000500    Time 0.129491    \n",
            "Epoch: [132][   20/   31]    Overall Loss 0.000096    Objective Loss 0.000096                                        LR 0.000500    Time 0.110758    \n",
            "Epoch: [132][   30/   31]    Overall Loss 0.000095    Objective Loss 0.000095    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.092621    \n",
            "Epoch: [132][   31/   31]    Overall Loss 0.000094    Objective Loss 0.000094    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.090919    \n",
            "--- validate (epoch=132)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [132][    4/    4]    Loss 1.742436    Top1 75.145180    Top5 100.000000    \n",
            "==> Top1: 75.145    Top5: 100.000    Loss: 1.742\n",
            "\n",
            "==> Confusion:\n",
            "[[113  45  16   0   0   0]\n",
            " [ 43  59   4   0   0   0]\n",
            " [ 15  10 125  15   0   0]\n",
            " [  1   1  11 175  15   0]\n",
            " [  0   0   1  37 175   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [133][   10/   31]    Overall Loss 0.000093    Objective Loss 0.000093                                        LR 0.000500    Time 0.177954    \n",
            "Epoch: [133][   20/   31]    Overall Loss 0.000092    Objective Loss 0.000092                                        LR 0.000500    Time 0.133712    \n",
            "Epoch: [133][   30/   31]    Overall Loss 0.000093    Objective Loss 0.000093    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.109867    \n",
            "Epoch: [133][   31/   31]    Overall Loss 0.000092    Objective Loss 0.000092    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.107683    \n",
            "--- validate (epoch=133)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [133][    4/    4]    Loss 1.753307    Top1 75.029036    Top5 100.000000    \n",
            "==> Top1: 75.029    Top5: 100.000    Loss: 1.753\n",
            "\n",
            "==> Confusion:\n",
            "[[117  44  13   0   0   0]\n",
            " [ 44  58   4   0   0   0]\n",
            " [ 16  10 124  15   0   0]\n",
            " [  0   1  12 172  18   0]\n",
            " [  0   0   1  37 175   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [134][   10/   31]    Overall Loss 0.000092    Objective Loss 0.000092                                        LR 0.000500    Time 0.201840    \n",
            "Epoch: [134][   20/   31]    Overall Loss 0.000090    Objective Loss 0.000090                                        LR 0.000500    Time 0.154360    \n",
            "Epoch: [134][   30/   31]    Overall Loss 0.000090    Objective Loss 0.000090    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.128136    \n",
            "Epoch: [134][   31/   31]    Overall Loss 0.000091    Objective Loss 0.000091    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.126111    \n",
            "--- validate (epoch=134)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [134][    4/    4]    Loss 1.697633    Top1 75.958188    Top5 100.000000    \n",
            "==> Top1: 75.958    Top5: 100.000    Loss: 1.698\n",
            "\n",
            "==> Confusion:\n",
            "[[118  42  14   0   0   0]\n",
            " [ 43  58   5   0   0   0]\n",
            " [ 12  13 127  13   0   0]\n",
            " [  0   0  13 176  14   0]\n",
            " [  0   0   1  37 175   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [135][   10/   31]    Overall Loss 0.000086    Objective Loss 0.000086                                        LR 0.000500    Time 0.163310    \n",
            "Epoch: [135][   20/   31]    Overall Loss 0.000088    Objective Loss 0.000088                                        LR 0.000500    Time 0.109952    \n",
            "Epoch: [135][   30/   31]    Overall Loss 0.000089    Objective Loss 0.000089    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.086580    \n",
            "Epoch: [135][   31/   31]    Overall Loss 0.000089    Objective Loss 0.000089    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.084748    \n",
            "--- validate (epoch=135)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [135][    4/    4]    Loss 1.658199    Top1 75.377468    Top5 100.000000    \n",
            "==> Top1: 75.377    Top5: 100.000    Loss: 1.658\n",
            "\n",
            "==> Confusion:\n",
            "[[118  44  12   0   0   0]\n",
            " [ 44  58   4   0   0   0]\n",
            " [ 13  12 126  14   0   0]\n",
            " [  1   1  10 171  20   0]\n",
            " [  0   0   1  36 176   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [136][   10/   31]    Overall Loss 0.000085    Objective Loss 0.000085                                        LR 0.000500    Time 0.122009    \n",
            "Epoch: [136][   20/   31]    Overall Loss 0.000088    Objective Loss 0.000088                                        LR 0.000500    Time 0.089502    \n",
            "Epoch: [136][   30/   31]    Overall Loss 0.000089    Objective Loss 0.000089    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.072691    \n",
            "Epoch: [136][   31/   31]    Overall Loss 0.000090    Objective Loss 0.000090    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.071310    \n",
            "--- validate (epoch=136)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [136][    4/    4]    Loss 1.712228    Top1 75.145180    Top5 100.000000    \n",
            "==> Top1: 75.145    Top5: 100.000    Loss: 1.712\n",
            "\n",
            "==> Confusion:\n",
            "[[115  45  14   0   0   0]\n",
            " [ 43  58   5   0   0   0]\n",
            " [ 14  11 124  16   0   0]\n",
            " [  1   1  10 177  14   0]\n",
            " [  0   0   2  38 173   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [137][   10/   31]    Overall Loss 0.000088    Objective Loss 0.000088                                        LR 0.000500    Time 0.212026    \n",
            "Epoch: [137][   20/   31]    Overall Loss 0.000085    Objective Loss 0.000085                                        LR 0.000500    Time 0.149894    \n",
            "Epoch: [137][   30/   31]    Overall Loss 0.000086    Objective Loss 0.000086    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.119967    \n",
            "Epoch: [137][   31/   31]    Overall Loss 0.000085    Objective Loss 0.000085    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.117395    \n",
            "--- validate (epoch=137)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [137][    4/    4]    Loss 1.651143    Top1 75.145180    Top5 100.000000    \n",
            "==> Top1: 75.145    Top5: 100.000    Loss: 1.651\n",
            "\n",
            "==> Confusion:\n",
            "[[119  41  14   0   0   0]\n",
            " [ 43  57   6   0   0   0]\n",
            " [ 16  10 125  14   0   0]\n",
            " [  1   1  12 172  17   0]\n",
            " [  0   0   2  37 174   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [138][   10/   31]    Overall Loss 0.000082    Objective Loss 0.000082                                        LR 0.000500    Time 0.217819    \n",
            "Epoch: [138][   20/   31]    Overall Loss 0.000082    Objective Loss 0.000082                                        LR 0.000500    Time 0.161427    \n",
            "Epoch: [138][   30/   31]    Overall Loss 0.000086    Objective Loss 0.000086    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.133001    \n",
            "Epoch: [138][   31/   31]    Overall Loss 0.000087    Objective Loss 0.000087    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.130335    \n",
            "--- validate (epoch=138)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [138][    4/    4]    Loss 1.716212    Top1 75.145180    Top5 100.000000    \n",
            "==> Top1: 75.145    Top5: 100.000    Loss: 1.716\n",
            "\n",
            "==> Confusion:\n",
            "[[117  40  17   0   0   0]\n",
            " [ 43  57   6   0   0   0]\n",
            " [ 14  10 125  16   0   0]\n",
            " [  0   1  13 176  13   0]\n",
            " [  0   0   2  39 172   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [139][   10/   31]    Overall Loss 0.000080    Objective Loss 0.000080                                        LR 0.000500    Time 0.205627    \n",
            "Epoch: [139][   20/   31]    Overall Loss 0.000085    Objective Loss 0.000085                                        LR 0.000500    Time 0.150793    \n",
            "Epoch: [139][   30/   31]    Overall Loss 0.000085    Objective Loss 0.000085    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.121775    \n",
            "Epoch: [139][   31/   31]    Overall Loss 0.000085    Objective Loss 0.000085    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.119240    \n",
            "--- validate (epoch=139)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [139][    4/    4]    Loss 1.684017    Top1 75.145180    Top5 100.000000    \n",
            "==> Top1: 75.145    Top5: 100.000    Loss: 1.684\n",
            "\n",
            "==> Confusion:\n",
            "[[117  42  15   0   0   0]\n",
            " [ 42  58   6   0   0   0]\n",
            " [ 15  10 126  14   0   0]\n",
            " [  0   1  11 173  18   0]\n",
            " [  0   0   2  38 173   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [140][   10/   31]    Overall Loss 0.000086    Objective Loss 0.000086                                        LR 0.000250    Time 0.176204    \n",
            "Epoch: [140][   20/   31]    Overall Loss 0.000082    Objective Loss 0.000082                                        LR 0.000250    Time 0.132516    \n",
            "Epoch: [140][   30/   31]    Overall Loss 0.000083    Objective Loss 0.000083    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.108796    \n",
            "Epoch: [140][   31/   31]    Overall Loss 0.000082    Objective Loss 0.000082    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.106608    \n",
            "--- validate (epoch=140)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [140][    4/    4]    Loss 1.668038    Top1 75.145180    Top5 100.000000    \n",
            "==> Top1: 75.145    Top5: 100.000    Loss: 1.668\n",
            "\n",
            "==> Confusion:\n",
            "[[116  43  15   0   0   0]\n",
            " [ 43  57   6   0   0   0]\n",
            " [ 14  10 125  16   0   0]\n",
            " [  1   0  12 175  15   0]\n",
            " [  0   0   2  37 174   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [141][   10/   31]    Overall Loss 0.000084    Objective Loss 0.000084                                        LR 0.000250    Time 0.111782    \n",
            "Epoch: [141][   20/   31]    Overall Loss 0.000083    Objective Loss 0.000083                                        LR 0.000250    Time 0.085572    \n",
            "Epoch: [141][   30/   31]    Overall Loss 0.000085    Objective Loss 0.000085    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.070346    \n",
            "Epoch: [141][   31/   31]    Overall Loss 0.000083    Objective Loss 0.000083    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.069041    \n",
            "--- validate (epoch=141)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [141][    4/    4]    Loss 1.570340    Top1 75.261324    Top5 100.000000    \n",
            "==> Top1: 75.261    Top5: 100.000    Loss: 1.570\n",
            "\n",
            "==> Confusion:\n",
            "[[116  42  16   0   0   0]\n",
            " [ 41  60   5   0   0   0]\n",
            " [ 15  10 126  14   0   0]\n",
            " [  1   1  12 173  16   0]\n",
            " [  0   0   2  38 173   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [142][   10/   31]    Overall Loss 0.000074    Objective Loss 0.000074                                        LR 0.000250    Time 0.113089    \n",
            "Epoch: [142][   20/   31]    Overall Loss 0.000080    Objective Loss 0.000080                                        LR 0.000250    Time 0.084911    \n",
            "Epoch: [142][   30/   31]    Overall Loss 0.000080    Objective Loss 0.000080    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.070528    \n",
            "Epoch: [142][   31/   31]    Overall Loss 0.000079    Objective Loss 0.000079    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.069254    \n",
            "--- validate (epoch=142)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [142][    4/    4]    Loss 1.734268    Top1 75.842044    Top5 100.000000    \n",
            "==> Top1: 75.842    Top5: 100.000    Loss: 1.734\n",
            "\n",
            "==> Confusion:\n",
            "[[119  43  12   0   0   0]\n",
            " [ 42  59   5   0   0   0]\n",
            " [ 14  11 128  12   0   0]\n",
            " [  0   1  13 175  14   0]\n",
            " [  0   0   2  39 172   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [143][   10/   31]    Overall Loss 0.000073    Objective Loss 0.000073                                        LR 0.000250    Time 0.112593    \n",
            "Epoch: [143][   20/   31]    Overall Loss 0.000078    Objective Loss 0.000078                                        LR 0.000250    Time 0.084618    \n",
            "Epoch: [143][   30/   31]    Overall Loss 0.000081    Objective Loss 0.000081    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.070125    \n",
            "Epoch: [143][   31/   31]    Overall Loss 0.000080    Objective Loss 0.000080    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.068831    \n",
            "--- validate (epoch=143)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [143][    4/    4]    Loss 1.655285    Top1 75.261324    Top5 100.000000    \n",
            "==> Top1: 75.261    Top5: 100.000    Loss: 1.655\n",
            "\n",
            "==> Confusion:\n",
            "[[116  43  15   0   0   0]\n",
            " [ 43  58   5   0   0   0]\n",
            " [ 13  11 127  14   0   0]\n",
            " [  0   1  12 173  17   0]\n",
            " [  0   0   2  37 174   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [144][   10/   31]    Overall Loss 0.000073    Objective Loss 0.000073                                        LR 0.000250    Time 0.117875    \n",
            "Epoch: [144][   20/   31]    Overall Loss 0.000076    Objective Loss 0.000076                                        LR 0.000250    Time 0.106032    \n",
            "Epoch: [144][   30/   31]    Overall Loss 0.000078    Objective Loss 0.000078    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.088307    \n",
            "Epoch: [144][   31/   31]    Overall Loss 0.000078    Objective Loss 0.000078    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.086734    \n",
            "--- validate (epoch=144)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [144][    4/    4]    Loss 1.670364    Top1 75.493612    Top5 100.000000    \n",
            "==> Top1: 75.494    Top5: 100.000    Loss: 1.670\n",
            "\n",
            "==> Confusion:\n",
            "[[117  42  15   0   0   0]\n",
            " [ 42  58   6   0   0   0]\n",
            " [ 14  11 125  15   0   0]\n",
            " [  0   1  12 176  14   0]\n",
            " [  0   0   2  37 174   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [145][   10/   31]    Overall Loss 0.000078    Objective Loss 0.000078                                        LR 0.000250    Time 0.168059    \n",
            "Epoch: [145][   20/   31]    Overall Loss 0.000076    Objective Loss 0.000076                                        LR 0.000250    Time 0.128228    \n",
            "Epoch: [145][   30/   31]    Overall Loss 0.000079    Objective Loss 0.000079    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.105543    \n",
            "Epoch: [145][   31/   31]    Overall Loss 0.000078    Objective Loss 0.000078    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.103411    \n",
            "--- validate (epoch=145)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [145][    4/    4]    Loss 1.639774    Top1 75.145180    Top5 100.000000    \n",
            "==> Top1: 75.145    Top5: 100.000    Loss: 1.640\n",
            "\n",
            "==> Confusion:\n",
            "[[117  44  13   0   0   0]\n",
            " [ 43  57   6   0   0   0]\n",
            " [ 14  11 125  15   0   0]\n",
            " [  1   1  11 173  17   0]\n",
            " [  0   0   2  36 175   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [146][   10/   31]    Overall Loss 0.000077    Objective Loss 0.000077                                        LR 0.000250    Time 0.176413    \n",
            "Epoch: [146][   20/   31]    Overall Loss 0.000076    Objective Loss 0.000076                                        LR 0.000250    Time 0.135378    \n",
            "Epoch: [146][   30/   31]    Overall Loss 0.000079    Objective Loss 0.000079    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.109299    \n",
            "Epoch: [146][   31/   31]    Overall Loss 0.000079    Objective Loss 0.000079    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.107077    \n",
            "--- validate (epoch=146)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [146][    4/    4]    Loss 1.650166    Top1 74.912892    Top5 100.000000    \n",
            "==> Top1: 74.913    Top5: 100.000    Loss: 1.650\n",
            "\n",
            "==> Confusion:\n",
            "[[115  43  16   0   0   0]\n",
            " [ 42  58   6   0   0   0]\n",
            " [ 15   9 124  17   0   0]\n",
            " [  1   1  12 173  16   0]\n",
            " [  0   0   2  36 175   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [147][   10/   31]    Overall Loss 0.000078    Objective Loss 0.000078                                        LR 0.000250    Time 0.203008    \n",
            "Epoch: [147][   20/   31]    Overall Loss 0.000080    Objective Loss 0.000080                                        LR 0.000250    Time 0.148103    \n",
            "Epoch: [147][   30/   31]    Overall Loss 0.000079    Objective Loss 0.000079    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.117805    \n",
            "Epoch: [147][   31/   31]    Overall Loss 0.000078    Objective Loss 0.000078    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.115196    \n",
            "--- validate (epoch=147)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [147][    4/    4]    Loss 1.731924    Top1 74.680604    Top5 100.000000    \n",
            "==> Top1: 74.681    Top5: 100.000    Loss: 1.732\n",
            "\n",
            "==> Confusion:\n",
            "[[115  42  17   0   0   0]\n",
            " [ 45  56   5   0   0   0]\n",
            " [ 14  11 126  14   0   0]\n",
            " [  0   0  14 173  16   0]\n",
            " [  0   0   2  38 173   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [148][   10/   31]    Overall Loss 0.000079    Objective Loss 0.000079                                        LR 0.000250    Time 0.165706    \n",
            "Epoch: [148][   20/   31]    Overall Loss 0.000076    Objective Loss 0.000076                                        LR 0.000250    Time 0.129960    \n",
            "Epoch: [148][   30/   31]    Overall Loss 0.000077    Objective Loss 0.000077    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.106536    \n",
            "Epoch: [148][   31/   31]    Overall Loss 0.000077    Objective Loss 0.000077    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.104489    \n",
            "--- validate (epoch=148)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [148][    4/    4]    Loss 1.712704    Top1 75.609756    Top5 100.000000    \n",
            "==> Top1: 75.610    Top5: 100.000    Loss: 1.713\n",
            "\n",
            "==> Confusion:\n",
            "[[118  41  15   0   0   0]\n",
            " [ 43  59   4   0   0   0]\n",
            " [ 12  12 125  16   0   0]\n",
            " [  1   1  11 176  14   0]\n",
            " [  0   0   2  38 173   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [149][   10/   31]    Overall Loss 0.000071    Objective Loss 0.000071                                        LR 0.000250    Time 0.172863    \n",
            "Epoch: [149][   20/   31]    Overall Loss 0.000075    Objective Loss 0.000075                                        LR 0.000250    Time 0.136120    \n",
            "Epoch: [149][   30/   31]    Overall Loss 0.000076    Objective Loss 0.000076    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.113795    \n",
            "Epoch: [149][   31/   31]    Overall Loss 0.000077    Objective Loss 0.000077    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.111965    \n",
            "--- validate (epoch=149)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [149][    4/    4]    Loss 1.707850    Top1 75.609756    Top5 100.000000    \n",
            "==> Top1: 75.610    Top5: 100.000    Loss: 1.708\n",
            "\n",
            "==> Confusion:\n",
            "[[115  44  15   0   0   0]\n",
            " [ 44  58   4   0   0   0]\n",
            " [ 13  12 126  14   0   0]\n",
            " [  1   1  10 177  14   0]\n",
            " [  0   0   1  37 175   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [150][   10/   31]    Overall Loss 0.000076    Objective Loss 0.000076                                        LR 0.000250    Time 0.179127    \n",
            "Epoch: [150][   20/   31]    Overall Loss 0.000079    Objective Loss 0.000079                                        LR 0.000250    Time 0.135016    \n",
            "Epoch: [150][   30/   31]    Overall Loss 0.000077    Objective Loss 0.000077    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.109899    \n",
            "Epoch: [150][   31/   31]    Overall Loss 0.000078    Objective Loss 0.000078    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.107671    \n",
            "--- validate (epoch=150)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [150][    4/    4]    Loss 1.657639    Top1 75.493612    Top5 100.000000    \n",
            "==> Top1: 75.494    Top5: 100.000    Loss: 1.658\n",
            "\n",
            "==> Confusion:\n",
            "[[118  42  14   0   0   0]\n",
            " [ 43  58   5   0   0   0]\n",
            " [ 16  11 123  15   0   0]\n",
            " [  1   1  11 178  12   0]\n",
            " [  0   0   2  38 173   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [151][   10/   31]    Overall Loss 0.000076    Objective Loss 0.000076                                        LR 0.000250    Time 0.174047    \n",
            "Epoch: [151][   20/   31]    Overall Loss 0.000077    Objective Loss 0.000077                                        LR 0.000250    Time 0.134251    \n",
            "Epoch: [151][   30/   31]    Overall Loss 0.000078    Objective Loss 0.000078    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.109729    \n",
            "Epoch: [151][   31/   31]    Overall Loss 0.000078    Objective Loss 0.000078    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.107549    \n",
            "--- validate (epoch=151)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [151][    4/    4]    Loss 1.649817    Top1 75.029036    Top5 100.000000    \n",
            "==> Top1: 75.029    Top5: 100.000    Loss: 1.650\n",
            "\n",
            "==> Confusion:\n",
            "[[115  44  15   0   0   0]\n",
            " [ 45  57   4   0   0   0]\n",
            " [ 13  12 124  16   0   0]\n",
            " [  1   1  12 174  15   0]\n",
            " [  0   0   2  35 176   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [152][   10/   31]    Overall Loss 0.000083    Objective Loss 0.000083                                        LR 0.000250    Time 0.179146    \n",
            "Epoch: [152][   20/   31]    Overall Loss 0.000076    Objective Loss 0.000076                                        LR 0.000250    Time 0.134244    \n",
            "Epoch: [152][   30/   31]    Overall Loss 0.000075    Objective Loss 0.000075    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.106173    \n",
            "Epoch: [152][   31/   31]    Overall Loss 0.000076    Objective Loss 0.000076    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.103789    \n",
            "--- validate (epoch=152)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [152][    4/    4]    Loss 1.660354    Top1 75.261324    Top5 100.000000    \n",
            "==> Top1: 75.261    Top5: 100.000    Loss: 1.660\n",
            "\n",
            "==> Confusion:\n",
            "[[117  44  13   0   0   0]\n",
            " [ 43  56   7   0   0   0]\n",
            " [ 15  10 124  16   0   0]\n",
            " [  0   1  12 176  14   0]\n",
            " [  0   0   2  36 175   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [153][   10/   31]    Overall Loss 0.000073    Objective Loss 0.000073                                        LR 0.000250    Time 0.112252    \n",
            "Epoch: [153][   20/   31]    Overall Loss 0.000073    Objective Loss 0.000073                                        LR 0.000250    Time 0.084215    \n",
            "Epoch: [153][   30/   31]    Overall Loss 0.000074    Objective Loss 0.000074    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.069556    \n",
            "Epoch: [153][   31/   31]    Overall Loss 0.000074    Objective Loss 0.000074    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.068284    \n",
            "--- validate (epoch=153)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [153][    4/    4]    Loss 1.654315    Top1 75.493612    Top5 100.000000    \n",
            "==> Top1: 75.494    Top5: 100.000    Loss: 1.654\n",
            "\n",
            "==> Confusion:\n",
            "[[117  44  13   0   0   0]\n",
            " [ 43  59   4   0   0   0]\n",
            " [ 15  10 126  14   0   0]\n",
            " [  1   0  11 176  15   0]\n",
            " [  0   0   2  39 172   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [154][   10/   31]    Overall Loss 0.000076    Objective Loss 0.000076                                        LR 0.000250    Time 0.110916    \n",
            "Epoch: [154][   20/   31]    Overall Loss 0.000076    Objective Loss 0.000076                                        LR 0.000250    Time 0.083756    \n",
            "Epoch: [154][   30/   31]    Overall Loss 0.000075    Objective Loss 0.000075    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.068802    \n",
            "Epoch: [154][   31/   31]    Overall Loss 0.000075    Objective Loss 0.000075    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.067549    \n",
            "--- validate (epoch=154)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [154][    4/    4]    Loss 1.631922    Top1 75.029036    Top5 100.000000    \n",
            "==> Top1: 75.029    Top5: 100.000    Loss: 1.632\n",
            "\n",
            "==> Confusion:\n",
            "[[116  41  17   0   0   0]\n",
            " [ 44  56   6   0   0   0]\n",
            " [ 13  11 126  15   0   0]\n",
            " [  0   0  14 175  14   0]\n",
            " [  0   0   2  38 173   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [155][   10/   31]    Overall Loss 0.000073    Objective Loss 0.000073                                        LR 0.000250    Time 0.115560    \n",
            "Epoch: [155][   20/   31]    Overall Loss 0.000075    Objective Loss 0.000075                                        LR 0.000250    Time 0.085937    \n",
            "Epoch: [155][   30/   31]    Overall Loss 0.000074    Objective Loss 0.000074    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.070224    \n",
            "Epoch: [155][   31/   31]    Overall Loss 0.000074    Objective Loss 0.000074    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.068936    \n",
            "--- validate (epoch=155)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [155][    4/    4]    Loss 1.691923    Top1 75.377468    Top5 100.000000    \n",
            "==> Top1: 75.377    Top5: 100.000    Loss: 1.692\n",
            "\n",
            "==> Confusion:\n",
            "[[114  47  13   0   0   0]\n",
            " [ 44  58   4   0   0   0]\n",
            " [ 13  11 126  15   0   0]\n",
            " [  1   1  11 178  12   0]\n",
            " [  0   0   1  39 173   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [156][   10/   31]    Overall Loss 0.000075    Objective Loss 0.000075                                        LR 0.000250    Time 0.173978    \n",
            "Epoch: [156][   20/   31]    Overall Loss 0.000073    Objective Loss 0.000073                                        LR 0.000250    Time 0.130333    \n",
            "Epoch: [156][   30/   31]    Overall Loss 0.000073    Objective Loss 0.000073    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.107510    \n",
            "Epoch: [156][   31/   31]    Overall Loss 0.000074    Objective Loss 0.000074    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.105309    \n",
            "--- validate (epoch=156)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [156][    4/    4]    Loss 1.624851    Top1 75.493612    Top5 100.000000    \n",
            "==> Top1: 75.494    Top5: 100.000    Loss: 1.625\n",
            "\n",
            "==> Confusion:\n",
            "[[118  42  14   0   0   0]\n",
            " [ 43  58   5   0   0   0]\n",
            " [ 13  11 125  16   0   0]\n",
            " [  1   1  12 176  13   0]\n",
            " [  0   0   1  39 173   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [157][   10/   31]    Overall Loss 0.000067    Objective Loss 0.000067                                        LR 0.000250    Time 0.177780    \n",
            "Epoch: [157][   20/   31]    Overall Loss 0.000069    Objective Loss 0.000069                                        LR 0.000250    Time 0.131554    \n",
            "Epoch: [157][   30/   31]    Overall Loss 0.000072    Objective Loss 0.000072    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.107577    \n",
            "Epoch: [157][   31/   31]    Overall Loss 0.000071    Objective Loss 0.000071    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.105456    \n",
            "--- validate (epoch=157)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [157][    4/    4]    Loss 1.682073    Top1 74.564460    Top5 100.000000    \n",
            "==> Top1: 74.564    Top5: 100.000    Loss: 1.682\n",
            "\n",
            "==> Confusion:\n",
            "[[114  45  15   0   0   0]\n",
            " [ 44  57   5   0   0   0]\n",
            " [ 13  11 126  15   0   0]\n",
            " [  0   1  13 173  16   0]\n",
            " [  0   0   2  39 172   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [158][   10/   31]    Overall Loss 0.000075    Objective Loss 0.000075                                        LR 0.000250    Time 0.177735    \n",
            "Epoch: [158][   20/   31]    Overall Loss 0.000074    Objective Loss 0.000074                                        LR 0.000250    Time 0.134417    \n",
            "Epoch: [158][   30/   31]    Overall Loss 0.000072    Objective Loss 0.000072    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.107819    \n",
            "Epoch: [158][   31/   31]    Overall Loss 0.000073    Objective Loss 0.000073    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.105614    \n",
            "--- validate (epoch=158)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [158][    4/    4]    Loss 1.677766    Top1 75.145180    Top5 100.000000    \n",
            "==> Top1: 75.145    Top5: 100.000    Loss: 1.678\n",
            "\n",
            "==> Confusion:\n",
            "[[113  46  15   0   0   0]\n",
            " [ 41  58   7   0   0   0]\n",
            " [ 11  10 129  15   0   0]\n",
            " [  1   1  11 175  15   0]\n",
            " [  0   0   2  39 172   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [159][   10/   31]    Overall Loss 0.000076    Objective Loss 0.000076                                        LR 0.000250    Time 0.120979    \n",
            "Epoch: [159][   20/   31]    Overall Loss 0.000072    Objective Loss 0.000072                                        LR 0.000250    Time 0.089709    \n",
            "Epoch: [159][   30/   31]    Overall Loss 0.000072    Objective Loss 0.000072    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.072760    \n",
            "Epoch: [159][   31/   31]    Overall Loss 0.000072    Objective Loss 0.000072    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.071373    \n",
            "--- validate (epoch=159)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [159][    4/    4]    Loss 1.637484    Top1 75.609756    Top5 100.000000    \n",
            "==> Top1: 75.610    Top5: 100.000    Loss: 1.637\n",
            "\n",
            "==> Confusion:\n",
            "[[119  41  14   0   0   0]\n",
            " [ 42  59   5   0   0   0]\n",
            " [ 14  11 125  15   0   0]\n",
            " [  0   0  12 177  14   0]\n",
            " [  0   0   2  40 171   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [160][   10/   31]    Overall Loss 0.000070    Objective Loss 0.000070                                        LR 0.000250    Time 0.114798    \n",
            "Epoch: [160][   20/   31]    Overall Loss 0.000070    Objective Loss 0.000070                                        LR 0.000250    Time 0.086046    \n",
            "Epoch: [160][   30/   31]    Overall Loss 0.000070    Objective Loss 0.000070    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.070853    \n",
            "Epoch: [160][   31/   31]    Overall Loss 0.000071    Objective Loss 0.000071    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.069569    \n",
            "--- validate (epoch=160)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [160][    4/    4]    Loss 1.658583    Top1 75.377468    Top5 100.000000    \n",
            "==> Top1: 75.377    Top5: 100.000    Loss: 1.659\n",
            "\n",
            "==> Confusion:\n",
            "[[115  46  13   0   0   0]\n",
            " [ 44  58   4   0   0   0]\n",
            " [ 14  11 125  15   0   0]\n",
            " [  1   1  10 178  13   0]\n",
            " [  0   0   2  38 173   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [161][   10/   31]    Overall Loss 0.000072    Objective Loss 0.000072                                        LR 0.000250    Time 0.109486    \n",
            "Epoch: [161][   20/   31]    Overall Loss 0.000072    Objective Loss 0.000072                                        LR 0.000250    Time 0.083066    \n",
            "Epoch: [161][   30/   31]    Overall Loss 0.000072    Objective Loss 0.000072    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.068333    \n",
            "Epoch: [161][   31/   31]    Overall Loss 0.000072    Objective Loss 0.000072    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.067065    \n",
            "--- validate (epoch=161)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [161][    4/    4]    Loss 1.671847    Top1 74.912892    Top5 100.000000    \n",
            "==> Top1: 74.913    Top5: 100.000    Loss: 1.672\n",
            "\n",
            "==> Confusion:\n",
            "[[114  46  14   0   0   0]\n",
            " [ 43  57   6   0   0   0]\n",
            " [ 14  11 125  15   0   0]\n",
            " [  1   1  10 177  14   0]\n",
            " [  0   0   1  40 172   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [162][   10/   31]    Overall Loss 0.000072    Objective Loss 0.000072                                        LR 0.000250    Time 0.113026    \n",
            "Epoch: [162][   20/   31]    Overall Loss 0.000070    Objective Loss 0.000070                                        LR 0.000250    Time 0.093158    \n",
            "Epoch: [162][   30/   31]    Overall Loss 0.000070    Objective Loss 0.000070    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.080457    \n",
            "Epoch: [162][   31/   31]    Overall Loss 0.000069    Objective Loss 0.000069    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.079039    \n",
            "--- validate (epoch=162)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [162][    4/    4]    Loss 1.641131    Top1 75.261324    Top5 100.000000    \n",
            "==> Top1: 75.261    Top5: 100.000    Loss: 1.641\n",
            "\n",
            "==> Confusion:\n",
            "[[115  46  13   0   0   0]\n",
            " [ 43  57   6   0   0   0]\n",
            " [ 13  11 124  17   0   0]\n",
            " [  1   1  11 176  14   0]\n",
            " [  0   0   1  36 176   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [163][   10/   31]    Overall Loss 0.000076    Objective Loss 0.000076                                        LR 0.000250    Time 0.206067    \n",
            "Epoch: [163][   20/   31]    Overall Loss 0.000073    Objective Loss 0.000073                                        LR 0.000250    Time 0.151270    \n",
            "Epoch: [163][   30/   31]    Overall Loss 0.000071    Objective Loss 0.000071    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.119909    \n",
            "Epoch: [163][   31/   31]    Overall Loss 0.000071    Objective Loss 0.000071    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.117316    \n",
            "--- validate (epoch=163)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [163][    4/    4]    Loss 1.627790    Top1 75.609756    Top5 100.000000    \n",
            "==> Top1: 75.610    Top5: 100.000    Loss: 1.628\n",
            "\n",
            "==> Confusion:\n",
            "[[117  42  15   0   0   0]\n",
            " [ 43  56   7   0   0   0]\n",
            " [ 14  10 127  14   0   0]\n",
            " [  0   0  12 177  14   0]\n",
            " [  0   0   1  38 174   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [164][   10/   31]    Overall Loss 0.000067    Objective Loss 0.000067                                        LR 0.000250    Time 0.183306    \n",
            "Epoch: [164][   20/   31]    Overall Loss 0.000070    Objective Loss 0.000070                                        LR 0.000250    Time 0.137908    \n",
            "Epoch: [164][   30/   31]    Overall Loss 0.000070    Objective Loss 0.000070    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.110463    \n",
            "Epoch: [164][   31/   31]    Overall Loss 0.000069    Objective Loss 0.000069    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.108343    \n",
            "--- validate (epoch=164)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [164][    4/    4]    Loss 1.710463    Top1 74.796748    Top5 100.000000    \n",
            "==> Top1: 74.797    Top5: 100.000    Loss: 1.710\n",
            "\n",
            "==> Confusion:\n",
            "[[113  44  17   0   0   0]\n",
            " [ 43  58   5   0   0   0]\n",
            " [ 14  10 125  16   0   0]\n",
            " [  0   1  12 176  14   0]\n",
            " [  0   0   1  40 172   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [165][   10/   31]    Overall Loss 0.000069    Objective Loss 0.000069                                        LR 0.000250    Time 0.182120    \n",
            "Epoch: [165][   20/   31]    Overall Loss 0.000072    Objective Loss 0.000072                                        LR 0.000250    Time 0.121511    \n",
            "Epoch: [165][   30/   31]    Overall Loss 0.000068    Objective Loss 0.000068    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.094703    \n",
            "Epoch: [165][   31/   31]    Overall Loss 0.000068    Objective Loss 0.000068    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.092644    \n",
            "--- validate (epoch=165)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [165][    4/    4]    Loss 1.713299    Top1 75.377468    Top5 100.000000    \n",
            "==> Top1: 75.377    Top5: 100.000    Loss: 1.713\n",
            "\n",
            "==> Confusion:\n",
            "[[117  41  16   0   0   0]\n",
            " [ 44  56   6   0   0   0]\n",
            " [ 13  11 128  13   0   0]\n",
            " [  1   0  12 173  17   0]\n",
            " [  0   0   2  36 175   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [166][   10/   31]    Overall Loss 0.000070    Objective Loss 0.000070                                        LR 0.000250    Time 0.113220    \n",
            "Epoch: [166][   20/   31]    Overall Loss 0.000068    Objective Loss 0.000068                                        LR 0.000250    Time 0.084723    \n",
            "Epoch: [166][   30/   31]    Overall Loss 0.000068    Objective Loss 0.000068    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.070135    \n",
            "Epoch: [166][   31/   31]    Overall Loss 0.000068    Objective Loss 0.000068    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.068852    \n",
            "--- validate (epoch=166)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [166][    4/    4]    Loss 1.750655    Top1 74.796748    Top5 100.000000    \n",
            "==> Top1: 74.797    Top5: 100.000    Loss: 1.751\n",
            "\n",
            "==> Confusion:\n",
            "[[116  41  17   0   0   0]\n",
            " [ 44  55   7   0   0   0]\n",
            " [ 15   9 125  16   0   0]\n",
            " [  0   1  12 174  16   0]\n",
            " [  0   0   2  37 174   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [167][   10/   31]    Overall Loss 0.000066    Objective Loss 0.000066                                        LR 0.000250    Time 0.115168    \n",
            "Epoch: [167][   20/   31]    Overall Loss 0.000065    Objective Loss 0.000065                                        LR 0.000250    Time 0.085542    \n",
            "Epoch: [167][   30/   31]    Overall Loss 0.000067    Objective Loss 0.000067    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.070093    \n",
            "Epoch: [167][   31/   31]    Overall Loss 0.000068    Objective Loss 0.000068    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.068826    \n",
            "--- validate (epoch=167)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [167][    4/    4]    Loss 1.752928    Top1 75.145180    Top5 100.000000    \n",
            "==> Top1: 75.145    Top5: 100.000    Loss: 1.753\n",
            "\n",
            "==> Confusion:\n",
            "[[116  43  15   0   0   0]\n",
            " [ 43  56   7   0   0   0]\n",
            " [ 15  10 124  16   0   0]\n",
            " [  0   0  13 178  12   0]\n",
            " [  0   0   2  38 173   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [168][   10/   31]    Overall Loss 0.000066    Objective Loss 0.000066                                        LR 0.000250    Time 0.113663    \n",
            "Epoch: [168][   20/   31]    Overall Loss 0.000066    Objective Loss 0.000066                                        LR 0.000250    Time 0.085406    \n",
            "Epoch: [168][   30/   31]    Overall Loss 0.000068    Objective Loss 0.000068    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.069970    \n",
            "Epoch: [168][   31/   31]    Overall Loss 0.000067    Objective Loss 0.000067    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.068669    \n",
            "--- validate (epoch=168)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [168][    4/    4]    Loss 1.669404    Top1 75.609756    Top5 100.000000    \n",
            "==> Top1: 75.610    Top5: 100.000    Loss: 1.669\n",
            "\n",
            "==> Confusion:\n",
            "[[117  43  14   0   0   0]\n",
            " [ 43  58   5   0   0   0]\n",
            " [ 12  12 128  13   0   0]\n",
            " [  0   0  15 173  15   0]\n",
            " [  0   0   2  36 175   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [169][   10/   31]    Overall Loss 0.000067    Objective Loss 0.000067                                        LR 0.000250    Time 0.190369    \n",
            "Epoch: [169][   20/   31]    Overall Loss 0.000068    Objective Loss 0.000068                                        LR 0.000250    Time 0.154985    \n",
            "Epoch: [169][   30/   31]    Overall Loss 0.000066    Objective Loss 0.000066    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.129315    \n",
            "Epoch: [169][   31/   31]    Overall Loss 0.000067    Objective Loss 0.000067    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.126938    \n",
            "--- validate (epoch=169)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [169][    4/    4]    Loss 1.696527    Top1 75.145180    Top5 100.000000    \n",
            "==> Top1: 75.145    Top5: 100.000    Loss: 1.697\n",
            "\n",
            "==> Confusion:\n",
            "[[117  43  14   0   0   0]\n",
            " [ 45  56   5   0   0   0]\n",
            " [ 14  11 124  16   0   0]\n",
            " [  0   0  13 175  15   0]\n",
            " [  0   0   1  37 175   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [170][   10/   31]    Overall Loss 0.000065    Objective Loss 0.000065                                        LR 0.000250    Time 0.195251    \n",
            "Epoch: [170][   20/   31]    Overall Loss 0.000064    Objective Loss 0.000064                                        LR 0.000250    Time 0.143924    \n",
            "Epoch: [170][   30/   31]    Overall Loss 0.000064    Objective Loss 0.000064    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.115929    \n",
            "Epoch: [170][   31/   31]    Overall Loss 0.000064    Objective Loss 0.000064    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.113482    \n",
            "--- validate (epoch=170)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [170][    4/    4]    Loss 1.756294    Top1 75.377468    Top5 100.000000    \n",
            "==> Top1: 75.377    Top5: 100.000    Loss: 1.756\n",
            "\n",
            "==> Confusion:\n",
            "[[118  42  14   0   0   0]\n",
            " [ 43  59   4   0   0   0]\n",
            " [ 14  10 125  16   0   0]\n",
            " [  0   0  14 171  18   0]\n",
            " [  0   0   2  35 176   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [171][   10/   31]    Overall Loss 0.000060    Objective Loss 0.000060                                        LR 0.000250    Time 0.174693    \n",
            "Epoch: [171][   20/   31]    Overall Loss 0.000064    Objective Loss 0.000064                                        LR 0.000250    Time 0.132143    \n",
            "Epoch: [171][   30/   31]    Overall Loss 0.000066    Objective Loss 0.000066    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.108063    \n",
            "Epoch: [171][   31/   31]    Overall Loss 0.000066    Objective Loss 0.000066    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.105902    \n",
            "--- validate (epoch=171)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [171][    4/    4]    Loss 1.645521    Top1 75.377468    Top5 100.000000    \n",
            "==> Top1: 75.377    Top5: 100.000    Loss: 1.646\n",
            "\n",
            "==> Confusion:\n",
            "[[115  44  15   0   0   0]\n",
            " [ 43  57   6   0   0   0]\n",
            " [ 12  11 125  17   0   0]\n",
            " [  0   0  13 177  13   0]\n",
            " [  0   0   2  36 175   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [172][   10/   31]    Overall Loss 0.000066    Objective Loss 0.000066                                        LR 0.000250    Time 0.113345    \n",
            "Epoch: [172][   20/   31]    Overall Loss 0.000066    Objective Loss 0.000066                                        LR 0.000250    Time 0.084935    \n",
            "Epoch: [172][   30/   31]    Overall Loss 0.000066    Objective Loss 0.000066    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.070151    \n",
            "Epoch: [172][   31/   31]    Overall Loss 0.000066    Objective Loss 0.000066    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.068833    \n",
            "--- validate (epoch=172)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [172][    4/    4]    Loss 1.757691    Top1 75.725900    Top5 100.000000    \n",
            "==> Top1: 75.726    Top5: 100.000    Loss: 1.758\n",
            "\n",
            "==> Confusion:\n",
            "[[118  44  12   0   0   0]\n",
            " [ 44  59   3   0   0   0]\n",
            " [ 15  10 124  16   0   0]\n",
            " [  0   1  12 177  13   0]\n",
            " [  0   0   1  38 174   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [173][   10/   31]    Overall Loss 0.000062    Objective Loss 0.000062                                        LR 0.000250    Time 0.113127    \n",
            "Epoch: [173][   20/   31]    Overall Loss 0.000060    Objective Loss 0.000060                                        LR 0.000250    Time 0.083788    \n",
            "Epoch: [173][   30/   31]    Overall Loss 0.000063    Objective Loss 0.000063    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.068940    \n",
            "Epoch: [173][   31/   31]    Overall Loss 0.000065    Objective Loss 0.000065    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.067754    \n",
            "--- validate (epoch=173)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [173][    4/    4]    Loss 1.760193    Top1 75.145180    Top5 100.000000    \n",
            "==> Top1: 75.145    Top5: 100.000    Loss: 1.760\n",
            "\n",
            "==> Confusion:\n",
            "[[117  45  12   0   0   0]\n",
            " [ 45  56   5   0   0   0]\n",
            " [ 14  11 125  15   0   0]\n",
            " [  0   1  12 175  15   0]\n",
            " [  0   0   1  38 174   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [174][   10/   31]    Overall Loss 0.000057    Objective Loss 0.000057                                        LR 0.000250    Time 0.117622    \n",
            "Epoch: [174][   20/   31]    Overall Loss 0.000060    Objective Loss 0.000060                                        LR 0.000250    Time 0.087048    \n",
            "Epoch: [174][   30/   31]    Overall Loss 0.000062    Objective Loss 0.000062    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.071164    \n",
            "Epoch: [174][   31/   31]    Overall Loss 0.000061    Objective Loss 0.000061    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.069833    \n",
            "--- validate (epoch=174)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [174][    4/    4]    Loss 1.769950    Top1 75.493612    Top5 100.000000    \n",
            "==> Top1: 75.494    Top5: 100.000    Loss: 1.770\n",
            "\n",
            "==> Confusion:\n",
            "[[119  41  14   0   0   0]\n",
            " [ 41  58   7   0   0   0]\n",
            " [ 15  10 124  16   0   0]\n",
            " [  0   0  13 173  17   0]\n",
            " [  0   0   2  35 176   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [175][   10/   31]    Overall Loss 0.000063    Objective Loss 0.000063                                        LR 0.000250    Time 0.137215    \n",
            "Epoch: [175][   20/   31]    Overall Loss 0.000061    Objective Loss 0.000061                                        LR 0.000250    Time 0.115789    \n",
            "Epoch: [175][   30/   31]    Overall Loss 0.000063    Objective Loss 0.000063    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.096427    \n",
            "Epoch: [175][   31/   31]    Overall Loss 0.000063    Objective Loss 0.000063    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.094518    \n",
            "--- validate (epoch=175)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [175][    4/    4]    Loss 1.662017    Top1 75.377468    Top5 100.000000    \n",
            "==> Top1: 75.377    Top5: 100.000    Loss: 1.662\n",
            "\n",
            "==> Confusion:\n",
            "[[116  43  15   0   0   0]\n",
            " [ 43  57   6   0   0   0]\n",
            " [ 14  11 124  16   0   0]\n",
            " [  0   1  12 176  14   0]\n",
            " [  0   0   2  35 176   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [176][   10/   31]    Overall Loss 0.000061    Objective Loss 0.000061                                        LR 0.000250    Time 0.178700    \n",
            "Epoch: [176][   20/   31]    Overall Loss 0.000061    Objective Loss 0.000061                                        LR 0.000250    Time 0.143523    \n",
            "Epoch: [176][   30/   31]    Overall Loss 0.000061    Objective Loss 0.000061    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.124214    \n",
            "Epoch: [176][   31/   31]    Overall Loss 0.000060    Objective Loss 0.000060    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.122045    \n",
            "--- validate (epoch=176)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [176][    4/    4]    Loss 1.643028    Top1 75.609756    Top5 100.000000    \n",
            "==> Top1: 75.610    Top5: 100.000    Loss: 1.643\n",
            "\n",
            "==> Confusion:\n",
            "[[119  43  12   0   0   0]\n",
            " [ 43  58   5   0   0   0]\n",
            " [ 14  11 124  16   0   0]\n",
            " [  1   1  11 173  17   0]\n",
            " [  0   0   2  34 177   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [177][   10/   31]    Overall Loss 0.000063    Objective Loss 0.000063                                        LR 0.000250    Time 0.212186    \n",
            "Epoch: [177][   20/   31]    Overall Loss 0.000062    Objective Loss 0.000062                                        LR 0.000250    Time 0.155703    \n",
            "Epoch: [177][   30/   31]    Overall Loss 0.000060    Objective Loss 0.000060    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.126494    \n",
            "Epoch: [177][   31/   31]    Overall Loss 0.000060    Objective Loss 0.000060    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.123885    \n",
            "--- validate (epoch=177)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [177][    4/    4]    Loss 1.709237    Top1 75.725900    Top5 100.000000    \n",
            "==> Top1: 75.726    Top5: 100.000    Loss: 1.709\n",
            "\n",
            "==> Confusion:\n",
            "[[119  42  13   0   0   0]\n",
            " [ 41  58   7   0   0   0]\n",
            " [ 13  12 125  15   0   0]\n",
            " [  1   1  11 175  15   0]\n",
            " [  0   0   2  36 175   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [178][   10/   31]    Overall Loss 0.000059    Objective Loss 0.000059                                        LR 0.000250    Time 0.176884    \n",
            "Epoch: [178][   20/   31]    Overall Loss 0.000058    Objective Loss 0.000058                                        LR 0.000250    Time 0.136627    \n",
            "Epoch: [178][   30/   31]    Overall Loss 0.000060    Objective Loss 0.000060    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.110643    \n",
            "Epoch: [178][   31/   31]    Overall Loss 0.000060    Objective Loss 0.000060    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.108344    \n",
            "--- validate (epoch=178)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [178][    4/    4]    Loss 1.679806    Top1 75.493612    Top5 100.000000    \n",
            "==> Top1: 75.494    Top5: 100.000    Loss: 1.680\n",
            "\n",
            "==> Confusion:\n",
            "[[118  43  13   0   0   0]\n",
            " [ 41  58   7   0   0   0]\n",
            " [ 14  11 123  17   0   0]\n",
            " [  0   1  11 176  15   0]\n",
            " [  0   0   2  36 175   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [179][   10/   31]    Overall Loss 0.000058    Objective Loss 0.000058                                        LR 0.000250    Time 0.176999    \n",
            "Epoch: [179][   20/   31]    Overall Loss 0.000057    Objective Loss 0.000057                                        LR 0.000250    Time 0.120565    \n",
            "Epoch: [179][   30/   31]    Overall Loss 0.000059    Objective Loss 0.000059    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.094022    \n",
            "Epoch: [179][   31/   31]    Overall Loss 0.000060    Objective Loss 0.000060    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.091928    \n",
            "--- validate (epoch=179)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [179][    4/    4]    Loss 1.709287    Top1 75.609756    Top5 100.000000    \n",
            "==> Top1: 75.610    Top5: 100.000    Loss: 1.709\n",
            "\n",
            "==> Confusion:\n",
            "[[118  44  12   0   0   0]\n",
            " [ 43  58   5   0   0   0]\n",
            " [ 15  10 126  14   0   0]\n",
            " [  0   1  12 174  16   0]\n",
            " [  0   0   1  37 175   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [180][   10/   31]    Overall Loss 0.000062    Objective Loss 0.000062                                        LR 0.000125    Time 0.112306    \n",
            "Epoch: [180][   20/   31]    Overall Loss 0.000061    Objective Loss 0.000061                                        LR 0.000125    Time 0.090315    \n",
            "Epoch: [180][   30/   31]    Overall Loss 0.000059    Objective Loss 0.000059    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.078611    \n",
            "Epoch: [180][   31/   31]    Overall Loss 0.000058    Objective Loss 0.000058    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.077289    \n",
            "--- validate (epoch=180)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [180][    4/    4]    Loss 1.710338    Top1 74.912892    Top5 100.000000    \n",
            "==> Top1: 74.913    Top5: 100.000    Loss: 1.710\n",
            "\n",
            "==> Confusion:\n",
            "[[116  43  15   0   0   0]\n",
            " [ 44  56   6   0   0   0]\n",
            " [ 14  11 123  17   0   0]\n",
            " [  0   1  13 175  14   0]\n",
            " [  0   0   2  36 175   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [181][   10/   31]    Overall Loss 0.000060    Objective Loss 0.000060                                        LR 0.000125    Time 0.184747    \n",
            "Epoch: [181][   20/   31]    Overall Loss 0.000060    Objective Loss 0.000060                                        LR 0.000125    Time 0.136959    \n",
            "Epoch: [181][   30/   31]    Overall Loss 0.000060    Objective Loss 0.000060    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.111600    \n",
            "Epoch: [181][   31/   31]    Overall Loss 0.000059    Objective Loss 0.000059    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.109415    \n",
            "--- validate (epoch=181)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [181][    4/    4]    Loss 1.714838    Top1 75.958188    Top5 100.000000    \n",
            "==> Top1: 75.958    Top5: 100.000    Loss: 1.715\n",
            "\n",
            "==> Confusion:\n",
            "[[120  40  14   0   0   0]\n",
            " [ 41  61   4   0   0   0]\n",
            " [ 14  12 125  14   0   0]\n",
            " [  0   0  14 174  15   0]\n",
            " [  0   0   1  38 174   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [182][   10/   31]    Overall Loss 0.000061    Objective Loss 0.000061                                        LR 0.000125    Time 0.174666    \n",
            "Epoch: [182][   20/   31]    Overall Loss 0.000060    Objective Loss 0.000060                                        LR 0.000125    Time 0.134194    \n",
            "Epoch: [182][   30/   31]    Overall Loss 0.000058    Objective Loss 0.000058    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.109887    \n",
            "Epoch: [182][   31/   31]    Overall Loss 0.000058    Objective Loss 0.000058    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.107730    \n",
            "--- validate (epoch=182)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [182][    4/    4]    Loss 1.689753    Top1 75.145180    Top5 100.000000    \n",
            "==> Top1: 75.145    Top5: 100.000    Loss: 1.690\n",
            "\n",
            "==> Confusion:\n",
            "[[117  42  15   0   0   0]\n",
            " [ 43  56   7   0   0   0]\n",
            " [ 15  10 125  15   0   0]\n",
            " [  0   0  13 176  14   0]\n",
            " [  0   0   1  39 173   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [183][   10/   31]    Overall Loss 0.000056    Objective Loss 0.000056                                        LR 0.000125    Time 0.179209    \n",
            "Epoch: [183][   20/   31]    Overall Loss 0.000059    Objective Loss 0.000059                                        LR 0.000125    Time 0.130495    \n",
            "Epoch: [183][   30/   31]    Overall Loss 0.000059    Objective Loss 0.000059    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.100654    \n",
            "Epoch: [183][   31/   31]    Overall Loss 0.000059    Objective Loss 0.000059    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.098370    \n",
            "--- validate (epoch=183)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [183][    4/    4]    Loss 1.791678    Top1 75.029036    Top5 100.000000    \n",
            "==> Top1: 75.029    Top5: 100.000    Loss: 1.792\n",
            "\n",
            "==> Confusion:\n",
            "[[117  42  15   0   0   0]\n",
            " [ 43  57   6   0   0   0]\n",
            " [ 15  10 124  16   0   0]\n",
            " [  0   0  14 173  16   0]\n",
            " [  0   0   1  37 175   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [184][   10/   31]    Overall Loss 0.000058    Objective Loss 0.000058                                        LR 0.000125    Time 0.118424    \n",
            "Epoch: [184][   20/   31]    Overall Loss 0.000060    Objective Loss 0.000060                                        LR 0.000125    Time 0.088822    \n",
            "Epoch: [184][   30/   31]    Overall Loss 0.000059    Objective Loss 0.000059    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.072793    \n",
            "Epoch: [184][   31/   31]    Overall Loss 0.000059    Objective Loss 0.000059    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.071454    \n",
            "--- validate (epoch=184)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [184][    4/    4]    Loss 1.763968    Top1 75.725900    Top5 100.000000    \n",
            "==> Top1: 75.726    Top5: 100.000    Loss: 1.764\n",
            "\n",
            "==> Confusion:\n",
            "[[119  40  15   0   0   0]\n",
            " [ 43  57   6   0   0   0]\n",
            " [ 15  10 124  16   0   0]\n",
            " [  1   0  12 177  13   0]\n",
            " [  0   0   2  36 175   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [185][   10/   31]    Overall Loss 0.000060    Objective Loss 0.000060                                        LR 0.000125    Time 0.115164    \n",
            "Epoch: [185][   20/   31]    Overall Loss 0.000058    Objective Loss 0.000058                                        LR 0.000125    Time 0.086511    \n",
            "Epoch: [185][   30/   31]    Overall Loss 0.000059    Objective Loss 0.000059    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.070669    \n",
            "Epoch: [185][   31/   31]    Overall Loss 0.000059    Objective Loss 0.000059    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.069356    \n",
            "--- validate (epoch=185)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [185][    4/    4]    Loss 1.617718    Top1 75.725900    Top5 100.000000    \n",
            "==> Top1: 75.726    Top5: 100.000    Loss: 1.618\n",
            "\n",
            "==> Confusion:\n",
            "[[120  39  15   0   0   0]\n",
            " [ 42  59   5   0   0   0]\n",
            " [ 15  10 125  15   0   0]\n",
            " [  0   1  13 176  13   0]\n",
            " [  0   0   2  39 172   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [186][   10/   31]    Overall Loss 0.000059    Objective Loss 0.000059                                        LR 0.000125    Time 0.114304    \n",
            "Epoch: [186][   20/   31]    Overall Loss 0.000058    Objective Loss 0.000058                                        LR 0.000125    Time 0.086361    \n",
            "Epoch: [186][   30/   31]    Overall Loss 0.000060    Objective Loss 0.000060    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.070678    \n",
            "Epoch: [186][   31/   31]    Overall Loss 0.000059    Objective Loss 0.000059    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.069343    \n",
            "--- validate (epoch=186)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [186][    4/    4]    Loss 1.633378    Top1 74.912892    Top5 100.000000    \n",
            "==> Top1: 74.913    Top5: 100.000    Loss: 1.633\n",
            "\n",
            "==> Confusion:\n",
            "[[118  41  15   0   0   0]\n",
            " [ 44  57   5   0   0   0]\n",
            " [ 15  10 124  16   0   0]\n",
            " [  0   0  14 173  16   0]\n",
            " [  0   0   1  39 173   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [187][   10/   31]    Overall Loss 0.000057    Objective Loss 0.000057                                        LR 0.000125    Time 0.185842    \n",
            "Epoch: [187][   20/   31]    Overall Loss 0.000058    Objective Loss 0.000058                                        LR 0.000125    Time 0.139868    \n",
            "Epoch: [187][   30/   31]    Overall Loss 0.000058    Objective Loss 0.000058    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.113060    \n",
            "Epoch: [187][   31/   31]    Overall Loss 0.000058    Objective Loss 0.000058    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.110682    \n",
            "--- validate (epoch=187)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [187][    4/    4]    Loss 1.731671    Top1 75.377468    Top5 100.000000    \n",
            "==> Top1: 75.377    Top5: 100.000    Loss: 1.732\n",
            "\n",
            "==> Confusion:\n",
            "[[116  43  15   0   0   0]\n",
            " [ 41  58   7   0   0   0]\n",
            " [ 15  10 124  16   0   0]\n",
            " [  0   0  13 175  15   0]\n",
            " [  0   0   1  36 176   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [188][   10/   31]    Overall Loss 0.000056    Objective Loss 0.000056                                        LR 0.000125    Time 0.176743    \n",
            "Epoch: [188][   20/   31]    Overall Loss 0.000056    Objective Loss 0.000056                                        LR 0.000125    Time 0.133040    \n",
            "Epoch: [188][   30/   31]    Overall Loss 0.000056    Objective Loss 0.000056    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.109527    \n",
            "Epoch: [188][   31/   31]    Overall Loss 0.000056    Objective Loss 0.000056    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.107290    \n",
            "--- validate (epoch=188)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [188][    4/    4]    Loss 1.774546    Top1 75.145180    Top5 100.000000    \n",
            "==> Top1: 75.145    Top5: 100.000    Loss: 1.775\n",
            "\n",
            "==> Confusion:\n",
            "[[115  43  16   0   0   0]\n",
            " [ 40  61   5   0   0   0]\n",
            " [ 15  10 124  16   0   0]\n",
            " [  0   1  13 172  17   0]\n",
            " [  0   0   0  38 175   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [189][   10/   31]    Overall Loss 0.000060    Objective Loss 0.000060                                        LR 0.000125    Time 0.180432    \n",
            "Epoch: [189][   20/   31]    Overall Loss 0.000058    Objective Loss 0.000058                                        LR 0.000125    Time 0.134923    \n",
            "Epoch: [189][   30/   31]    Overall Loss 0.000057    Objective Loss 0.000057    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.108616    \n",
            "Epoch: [189][   31/   31]    Overall Loss 0.000057    Objective Loss 0.000057    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.106415    \n",
            "--- validate (epoch=189)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [189][    4/    4]    Loss 1.778890    Top1 75.145180    Top5 100.000000    \n",
            "==> Top1: 75.145    Top5: 100.000    Loss: 1.779\n",
            "\n",
            "==> Confusion:\n",
            "[[114  45  15   0   0   0]\n",
            " [ 40  60   6   0   0   0]\n",
            " [ 14  10 124  17   0   0]\n",
            " [  1   1  11 176  14   0]\n",
            " [  0   0   2  38 173   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [190][   10/   31]    Overall Loss 0.000057    Objective Loss 0.000057                                        LR 0.000063    Time 0.187210    \n",
            "Epoch: [190][   20/   31]    Overall Loss 0.000057    Objective Loss 0.000057                                        LR 0.000063    Time 0.139703    \n",
            "Epoch: [190][   30/   31]    Overall Loss 0.000055    Objective Loss 0.000055    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.113213    \n",
            "Epoch: [190][   31/   31]    Overall Loss 0.000055    Objective Loss 0.000055    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.110832    \n",
            "--- validate (epoch=190)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [190][    4/    4]    Loss 1.734684    Top1 75.725900    Top5 100.000000    \n",
            "==> Top1: 75.726    Top5: 100.000    Loss: 1.735\n",
            "\n",
            "==> Confusion:\n",
            "[[116  44  14   0   0   0]\n",
            " [ 41  61   4   0   0   0]\n",
            " [ 15  10 124  16   0   0]\n",
            " [  0   1  13 173  16   0]\n",
            " [  0   0   1  34 178   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [191][   10/   31]    Overall Loss 0.000054    Objective Loss 0.000054                                        LR 0.000063    Time 0.180346    \n",
            "Epoch: [191][   20/   31]    Overall Loss 0.000056    Objective Loss 0.000056                                        LR 0.000063    Time 0.136652    \n",
            "Epoch: [191][   30/   31]    Overall Loss 0.000057    Objective Loss 0.000057    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.110388    \n",
            "Epoch: [191][   31/   31]    Overall Loss 0.000056    Objective Loss 0.000056    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.108137    \n",
            "--- validate (epoch=191)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [191][    4/    4]    Loss 1.773854    Top1 75.958188    Top5 100.000000    \n",
            "==> Top1: 75.958    Top5: 100.000    Loss: 1.774\n",
            "\n",
            "==> Confusion:\n",
            "[[120  39  15   0   0   0]\n",
            " [ 43  58   5   0   0   0]\n",
            " [ 15   9 126  15   0   0]\n",
            " [  0   0  13 176  14   0]\n",
            " [  0   0   2  37 174   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [192][   10/   31]    Overall Loss 0.000056    Objective Loss 0.000056                                        LR 0.000063    Time 0.200899    \n",
            "Epoch: [192][   20/   31]    Overall Loss 0.000056    Objective Loss 0.000056                                        LR 0.000063    Time 0.155502    \n",
            "Epoch: [192][   30/   31]    Overall Loss 0.000056    Objective Loss 0.000056    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.128121    \n",
            "Epoch: [192][   31/   31]    Overall Loss 0.000056    Objective Loss 0.000056    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.125662    \n",
            "--- validate (epoch=192)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [192][    4/    4]    Loss 1.764658    Top1 76.074332    Top5 100.000000    \n",
            "==> Top1: 76.074    Top5: 100.000    Loss: 1.765\n",
            "\n",
            "==> Confusion:\n",
            "[[118  41  15   0   0   0]\n",
            " [ 42  58   6   0   0   0]\n",
            " [ 15   9 127  14   0   0]\n",
            " [  0   0  13 177  13   0]\n",
            " [  0   0   1  37 175   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [193][   10/   31]    Overall Loss 0.000055    Objective Loss 0.000055                                        LR 0.000063    Time 0.187009    \n",
            "Epoch: [193][   20/   31]    Overall Loss 0.000057    Objective Loss 0.000057                                        LR 0.000063    Time 0.137389    \n",
            "Epoch: [193][   30/   31]    Overall Loss 0.000055    Objective Loss 0.000055    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.110679    \n",
            "Epoch: [193][   31/   31]    Overall Loss 0.000055    Objective Loss 0.000055    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.108356    \n",
            "--- validate (epoch=193)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [193][    4/    4]    Loss 1.716812    Top1 75.493612    Top5 100.000000    \n",
            "==> Top1: 75.494    Top5: 100.000    Loss: 1.717\n",
            "\n",
            "==> Confusion:\n",
            "[[117  41  16   0   0   0]\n",
            " [ 42  59   5   0   0   0]\n",
            " [ 16  10 125  14   0   0]\n",
            " [  0   0  14 174  15   0]\n",
            " [  0   0   2  36 175   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [194][   10/   31]    Overall Loss 0.000054    Objective Loss 0.000054                                        LR 0.000063    Time 0.206006    \n",
            "Epoch: [194][   20/   31]    Overall Loss 0.000054    Objective Loss 0.000054                                        LR 0.000063    Time 0.149246    \n",
            "Epoch: [194][   30/   31]    Overall Loss 0.000056    Objective Loss 0.000056    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.118484    \n",
            "Epoch: [194][   31/   31]    Overall Loss 0.000055    Objective Loss 0.000055    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.116001    \n",
            "--- validate (epoch=194)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [194][    4/    4]    Loss 1.757823    Top1 75.029036    Top5 100.000000    \n",
            "==> Top1: 75.029    Top5: 100.000    Loss: 1.758\n",
            "\n",
            "==> Confusion:\n",
            "[[115  46  13   0   0   0]\n",
            " [ 44  57   5   0   0   0]\n",
            " [ 15  10 124  16   0   0]\n",
            " [  0   0  13 175  15   0]\n",
            " [  0   0   2  36 175   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [195][   10/   31]    Overall Loss 0.000053    Objective Loss 0.000053                                        LR 0.000031    Time 0.139042    \n",
            "Epoch: [195][   20/   31]    Overall Loss 0.000055    Objective Loss 0.000055                                        LR 0.000031    Time 0.100660    \n",
            "Epoch: [195][   30/   31]    Overall Loss 0.000055    Objective Loss 0.000055    Top1 100.000000    Top5 100.000000    LR 0.000031    Time 0.080669    \n",
            "Epoch: [195][   31/   31]    Overall Loss 0.000054    Objective Loss 0.000054    Top1 100.000000    Top5 100.000000    LR 0.000031    Time 0.079057    \n",
            "--- validate (epoch=195)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [195][    4/    4]    Loss 1.851378    Top1 75.377468    Top5 100.000000    \n",
            "==> Top1: 75.377    Top5: 100.000    Loss: 1.851\n",
            "\n",
            "==> Confusion:\n",
            "[[118  42  14   0   0   0]\n",
            " [ 43  58   5   0   0   0]\n",
            " [ 15  10 124  16   0   0]\n",
            " [  0   1  12 175  15   0]\n",
            " [  0   0   0  39 174   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [196][   10/   31]    Overall Loss 0.000055    Objective Loss 0.000055                                        LR 0.000031    Time 0.113740    \n",
            "Epoch: [196][   20/   31]    Overall Loss 0.000053    Objective Loss 0.000053                                        LR 0.000031    Time 0.087202    \n",
            "Epoch: [196][   30/   31]    Overall Loss 0.000055    Objective Loss 0.000055    Top1 100.000000    Top5 100.000000    LR 0.000031    Time 0.071272    \n",
            "Epoch: [196][   31/   31]    Overall Loss 0.000054    Objective Loss 0.000054    Top1 100.000000    Top5 100.000000    LR 0.000031    Time 0.069992    \n",
            "--- validate (epoch=196)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [196][    4/    4]    Loss 1.693799    Top1 74.912892    Top5 100.000000    \n",
            "==> Top1: 74.913    Top5: 100.000    Loss: 1.694\n",
            "\n",
            "==> Confusion:\n",
            "[[116  44  14   0   0   0]\n",
            " [ 43  57   6   0   0   0]\n",
            " [ 15  10 123  17   0   0]\n",
            " [  0   1  13 173  16   0]\n",
            " [  0   0   1  36 176   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [197][   10/   31]    Overall Loss 0.000052    Objective Loss 0.000052                                        LR 0.000031    Time 0.112537    \n",
            "Epoch: [197][   20/   31]    Overall Loss 0.000053    Objective Loss 0.000053                                        LR 0.000031    Time 0.084574    \n",
            "Epoch: [197][   30/   31]    Overall Loss 0.000053    Objective Loss 0.000053    Top1 100.000000    Top5 100.000000    LR 0.000031    Time 0.069521    \n",
            "Epoch: [197][   31/   31]    Overall Loss 0.000053    Objective Loss 0.000053    Top1 100.000000    Top5 100.000000    LR 0.000031    Time 0.068214    \n",
            "--- validate (epoch=197)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [197][    4/    4]    Loss 1.700458    Top1 75.842044    Top5 100.000000    \n",
            "==> Top1: 75.842    Top5: 100.000    Loss: 1.700\n",
            "\n",
            "==> Confusion:\n",
            "[[119  40  15   0   0   0]\n",
            " [ 42  59   5   0   0   0]\n",
            " [ 13  10 127  15   0   0]\n",
            " [  1   1  12 174  15   0]\n",
            " [  0   0   2  37 174   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [198][   10/   31]    Overall Loss 0.000058    Objective Loss 0.000058                                        LR 0.000031    Time 0.115058    \n",
            "Epoch: [198][   20/   31]    Overall Loss 0.000057    Objective Loss 0.000057                                        LR 0.000031    Time 0.088180    \n",
            "Epoch: [198][   30/   31]    Overall Loss 0.000056    Objective Loss 0.000056    Top1 100.000000    Top5 100.000000    LR 0.000031    Time 0.076273    \n",
            "Epoch: [198][   31/   31]    Overall Loss 0.000056    Objective Loss 0.000056    Top1 100.000000    Top5 100.000000    LR 0.000031    Time 0.074968    \n",
            "--- validate (epoch=198)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [198][    4/    4]    Loss 1.838514    Top1 75.377468    Top5 100.000000    \n",
            "==> Top1: 75.377    Top5: 100.000    Loss: 1.839\n",
            "\n",
            "==> Confusion:\n",
            "[[116  45  13   0   0   0]\n",
            " [ 44  58   4   0   0   0]\n",
            " [ 15  10 124  16   0   0]\n",
            " [  0   1  13 176  13   0]\n",
            " [  0   0   1  37 175   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [199][   10/   31]    Overall Loss 0.000052    Objective Loss 0.000052                                        LR 0.000031    Time 0.175604    \n",
            "Epoch: [199][   20/   31]    Overall Loss 0.000054    Objective Loss 0.000054                                        LR 0.000031    Time 0.133485    \n",
            "Epoch: [199][   30/   31]    Overall Loss 0.000054    Objective Loss 0.000054    Top1 100.000000    Top5 100.000000    LR 0.000031    Time 0.109589    \n",
            "Epoch: [199][   31/   31]    Overall Loss 0.000054    Objective Loss 0.000054    Top1 100.000000    Top5 100.000000    LR 0.000031    Time 0.107352    \n",
            "--- validate (epoch=199)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [199][    4/    4]    Loss 1.713290    Top1 75.377468    Top5 100.000000    \n",
            "==> Top1: 75.377    Top5: 100.000    Loss: 1.713\n",
            "\n",
            "==> Confusion:\n",
            "[[118  42  14   0   0   0]\n",
            " [ 44  57   5   0   0   0]\n",
            " [ 15   9 126  15   0   0]\n",
            " [  0   1  13 174  15   0]\n",
            " [  0   0   0  39 174   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 76.307   Top5: 100.000   Sparsity:0.00   Params: 113050 on epoch: 80]\n",
            "Saving checkpoint to: logs/2023.08.18-022226/qat_checkpoint.pth.tar\n",
            "--- test ---------------------\n",
            "966 samples (256 per mini-batch)\n",
            "Test: [    4/    4]    Loss 1.334595    Top1 79.710145    Top5 100.000000    \n",
            "==> Top1: 79.710    Top5: 100.000    Loss: 1.335\n",
            "\n",
            "==> Confusion:\n",
            "[[124  47   8   1   0   0]\n",
            " [ 43  49   4   0   0   0]\n",
            " [  6   3 169  19   1   0]\n",
            " [  0   1  15 207  20   0]\n",
            " [  0   0   3  25 221   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "\n",
            "Log file for this run: /content/ai8x-training/logs/2023.08.18-022226/2023.08.18-022226.log\n",
            "\u001b[?2004h(ai8x-training) \u001b[01;34m/content/ai8x-training\u001b[00m# scripts/train_smart_echo_net.sh\n",
            "train.py:73: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
            "  from pkg_resources import parse_version\n",
            "Configuring device: MAX78000, simulate=False.\n",
            "Log file for this run: /content/ai8x-training/logs/2023.08.18-024925/2023.08.18-024925.log\n",
            "{'start_epoch': 10, 'weight_bits': 8}\n",
            "Optimizer Type: <class 'torch.optim.adam.Adam'>\n",
            "Optimizer Args: {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0, 'amsgrad': False}\n",
            "Jession : data\n",
            "No key `strech` in input augmentation dictionary! Using defaults: [Min: 0.8, Max: 1.3]\n",
            "\n",
            "Processing train...\n",
            "Class FULL_LEAK (# 0): 1680 elements\n",
            "Class MEDIUM_LEAK (# 1): 1020 elements\n",
            "Class NORMAL (# 2): 1662 elements\n",
            "Class SHUTTLE_ABN (# 3): 2082 elements\n",
            "Class SHUTTLE_NORM (# 4): 2169 elements\n",
            "Class UNKNOWN (# 5): 0 elements\n",
            "Class UNKNOWN: 0 elements\n",
            "\n",
            "Processing test...\n",
            "Class FULL_LEAK (# 0): 180 elements\n",
            "Class MEDIUM_LEAK (# 1): 96 elements\n",
            "Class NORMAL (# 2): 198 elements\n",
            "Class SHUTTLE_ABN (# 3): 243 elements\n",
            "Class SHUTTLE_NORM (# 4): 249 elements\n",
            "Class UNKNOWN (# 5): 0 elements\n",
            "Class UNKNOWN: 0 elements\n",
            "This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\n",
            "Dataset sizes:\n",
            "\ttraining=7752\n",
            "\tvalidation=861\n",
            "\ttest=966\n",
            "Reading compression schedule from: policies/schedule_kws20.yaml\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [0][   10/   31]    Overall Loss 1.764517    Objective Loss 1.764517                                        LR 0.001000    Time 0.194160    \n",
            "Epoch: [0][   20/   31]    Overall Loss 1.706141    Objective Loss 1.706141                                        LR 0.001000    Time 0.123818    \n",
            "Epoch: [0][   30/   31]    Overall Loss 1.674853    Objective Loss 1.674853    Top1 24.218750    Top5 100.000000    LR 0.001000    Time 0.094904    \n",
            "Epoch: [0][   31/   31]    Overall Loss 1.672195    Objective Loss 1.672195    Top1 22.865854    Top5 100.000000    LR 0.001000    Time 0.092768    \n",
            "--- validate (epoch=0)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [0][    4/    4]    Loss 1.612832    Top1 19.279907    Top5 100.000000    \n",
            "==> Top1: 19.280    Top5: 100.000    Loss: 1.613\n",
            "\n",
            "==> Confusion:\n",
            "[[174   0   0   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [165   0   0   0   0   0]\n",
            " [202   0   0   1   0   0]\n",
            " [213   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 19.280   Top5: 100.000   Sparsity:0.00   Params: 80076 on epoch: 0]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [1][   10/   31]    Overall Loss 1.610580    Objective Loss 1.610580                                        LR 0.001000    Time 0.112001    \n",
            "Epoch: [1][   20/   31]    Overall Loss 1.597131    Objective Loss 1.597131                                        LR 0.001000    Time 0.083011    \n",
            "Epoch: [1][   30/   31]    Overall Loss 1.587530    Objective Loss 1.587530    Top1 27.343750    Top5 100.000000    LR 0.001000    Time 0.070137    \n",
            "Epoch: [1][   31/   31]    Overall Loss 1.587991    Objective Loss 1.587991    Top1 28.353659    Top5 100.000000    LR 0.001000    Time 0.068755    \n",
            "--- validate (epoch=1)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [1][    4/    4]    Loss 1.570698    Top1 35.191638    Top5 100.000000    \n",
            "==> Top1: 35.192    Top5: 100.000    Loss: 1.571\n",
            "\n",
            "==> Confusion:\n",
            "[[137   0  37   0   0   0]\n",
            " [ 83   0  23   0   0   0]\n",
            " [ 35   0 126   4   0   0]\n",
            " [  2   0  48 153   0   0]\n",
            " [  1   0  70 142   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 35.192   Top5: 100.000   Sparsity:0.00   Params: 80076 on epoch: 1]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [2][   10/   31]    Overall Loss 1.564276    Objective Loss 1.564276                                        LR 0.001000    Time 0.110428    \n",
            "Epoch: [2][   20/   31]    Overall Loss 1.555677    Objective Loss 1.555677                                        LR 0.001000    Time 0.083091    \n",
            "Epoch: [2][   30/   31]    Overall Loss 1.544506    Objective Loss 1.544506    Top1 37.890625    Top5 100.000000    LR 0.001000    Time 0.067643    \n",
            "Epoch: [2][   31/   31]    Overall Loss 1.544330    Objective Loss 1.544330    Top1 35.365854    Top5 100.000000    LR 0.001000    Time 0.066334    \n",
            "--- validate (epoch=2)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [2][    4/    4]    Loss 1.523745    Top1 41.695703    Top5 100.000000    \n",
            "==> Top1: 41.696    Top5: 100.000    Loss: 1.524\n",
            "\n",
            "==> Confusion:\n",
            "[[156   0  18   0   0   0]\n",
            " [ 94   0  12   0   0   0]\n",
            " [ 53   0 104   8   0   0]\n",
            " [  2   0  15 186   0   0]\n",
            " [  0   0  11 145  57   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 41.696   Top5: 100.000   Sparsity:0.00   Params: 80076 on epoch: 2]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [3][   10/   31]    Overall Loss 1.499810    Objective Loss 1.499810                                        LR 0.001000    Time 0.109134    \n",
            "Epoch: [3][   20/   31]    Overall Loss 1.488148    Objective Loss 1.488148                                        LR 0.001000    Time 0.082051    \n",
            "Epoch: [3][   30/   31]    Overall Loss 1.467287    Objective Loss 1.467287    Top1 49.609375    Top5 100.000000    LR 0.001000    Time 0.066735    \n",
            "Epoch: [3][   31/   31]    Overall Loss 1.467318    Objective Loss 1.467318    Top1 43.902439    Top5 100.000000    LR 0.001000    Time 0.065489    \n",
            "--- validate (epoch=3)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [3][    4/    4]    Loss 1.316754    Top1 47.851336    Top5 100.000000    \n",
            "==> Top1: 47.851    Top5: 100.000    Loss: 1.317\n",
            "\n",
            "==> Confusion:\n",
            "[[174   0   0   0   0   0]\n",
            " [105   0   1   0   0   0]\n",
            " [113   0  38  14   0   0]\n",
            " [  4   0   4 189   6   0]\n",
            " [  0   0   1 212   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 47.851   Top5: 100.000   Sparsity:0.00   Params: 80076 on epoch: 3]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [4][   10/   31]    Overall Loss 1.343408    Objective Loss 1.343408                                        LR 0.001000    Time 0.174244    \n",
            "Epoch: [4][   20/   31]    Overall Loss 1.331049    Objective Loss 1.331049                                        LR 0.001000    Time 0.130428    \n",
            "Epoch: [4][   30/   31]    Overall Loss 1.315595    Objective Loss 1.315595    Top1 47.656250    Top5 100.000000    LR 0.001000    Time 0.104855    \n",
            "Epoch: [4][   31/   31]    Overall Loss 1.313141    Objective Loss 1.313141    Top1 48.170732    Top5 100.000000    LR 0.001000    Time 0.102708    \n",
            "--- validate (epoch=4)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [4][    4/    4]    Loss 1.348855    Top1 42.508711    Top5 99.651568    \n",
            "==> Top1: 42.509    Top5: 99.652    Loss: 1.349\n",
            "\n",
            "==> Confusion:\n",
            "[[119   0  51   4   0   0]\n",
            " [ 71   1  32   2   0   0]\n",
            " [ 28   0  73  64   0   0]\n",
            " [  1   0   3 199   0   0]\n",
            " [  0   0   0 213   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 47.851   Top5: 100.000   Sparsity:0.00   Params: 80076 on epoch: 3]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [5][   10/   31]    Overall Loss 1.291473    Objective Loss 1.291473                                        LR 0.001000    Time 0.172996    \n",
            "Epoch: [5][   20/   31]    Overall Loss 1.275075    Objective Loss 1.275075                                        LR 0.001000    Time 0.132925    \n",
            "Epoch: [5][   30/   31]    Overall Loss 1.271812    Objective Loss 1.271812    Top1 44.921875    Top5 100.000000    LR 0.001000    Time 0.106504    \n",
            "Epoch: [5][   31/   31]    Overall Loss 1.272671    Objective Loss 1.272671    Top1 46.951220    Top5 100.000000    LR 0.001000    Time 0.104355    \n",
            "--- validate (epoch=5)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [5][    4/    4]    Loss 1.279110    Top1 45.993031    Top5 100.000000    \n",
            "==> Top1: 45.993    Top5: 100.000    Loss: 1.279\n",
            "\n",
            "==> Confusion:\n",
            "[[159   0  15   0   0   0]\n",
            " [ 98   0   8   0   0   0]\n",
            " [ 45   2 106  12   0   0]\n",
            " [  2   0  10 191   0   0]\n",
            " [  0   0   1 212   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 47.851   Top5: 100.000   Sparsity:0.00   Params: 80076 on epoch: 3]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [6][   10/   31]    Overall Loss 1.245008    Objective Loss 1.245008                                        LR 0.001000    Time 0.212891    \n",
            "Epoch: [6][   20/   31]    Overall Loss 1.249954    Objective Loss 1.249954                                        LR 0.001000    Time 0.158935    \n",
            "Epoch: [6][   30/   31]    Overall Loss 1.246903    Objective Loss 1.246903    Top1 53.906250    Top5 100.000000    LR 0.001000    Time 0.126602    \n",
            "Epoch: [6][   31/   31]    Overall Loss 1.245129    Objective Loss 1.245129    Top1 53.048780    Top5 100.000000    LR 0.001000    Time 0.123818    \n",
            "--- validate (epoch=6)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [6][    4/    4]    Loss 1.273790    Top1 47.386760    Top5 100.000000    \n",
            "==> Top1: 47.387    Top5: 100.000    Loss: 1.274\n",
            "\n",
            "==> Confusion:\n",
            "[[174   0   0   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 72   0  92   1   0   0]\n",
            " [  5   0  21 177   0   0]\n",
            " [  0   0  15 198   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 47.851   Top5: 100.000   Sparsity:0.00   Params: 80076 on epoch: 3]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [7][   10/   31]    Overall Loss 1.263610    Objective Loss 1.263610                                        LR 0.001000    Time 0.166471    \n",
            "Epoch: [7][   20/   31]    Overall Loss 1.260451    Objective Loss 1.260451                                        LR 0.001000    Time 0.123814    \n",
            "Epoch: [7][   30/   31]    Overall Loss 1.257158    Objective Loss 1.257158    Top1 51.171875    Top5 100.000000    LR 0.001000    Time 0.101421    \n",
            "Epoch: [7][   31/   31]    Overall Loss 1.256058    Objective Loss 1.256058    Top1 52.439024    Top5 100.000000    LR 0.001000    Time 0.099506    \n",
            "--- validate (epoch=7)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [7][    4/    4]    Loss 1.281530    Top1 47.851336    Top5 100.000000    \n",
            "==> Top1: 47.851    Top5: 100.000    Loss: 1.282\n",
            "\n",
            "==> Confusion:\n",
            "[[174   0   0   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 67   0  96   2   0   0]\n",
            " [  4   0  21 178   0   0]\n",
            " [  0   0  15 198   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 47.851   Top5: 100.000   Sparsity:0.00   Params: 80076 on epoch: 7]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [8][   10/   31]    Overall Loss 1.258934    Objective Loss 1.258934                                        LR 0.001000    Time 0.169733    \n",
            "Epoch: [8][   20/   31]    Overall Loss 1.258001    Objective Loss 1.258001                                        LR 0.001000    Time 0.132778    \n",
            "Epoch: [8][   30/   31]    Overall Loss 1.255446    Objective Loss 1.255446    Top1 52.734375    Top5 100.000000    LR 0.001000    Time 0.107808    \n",
            "Epoch: [8][   31/   31]    Overall Loss 1.254340    Objective Loss 1.254340    Top1 51.829268    Top5 100.000000    LR 0.001000    Time 0.105633    \n",
            "--- validate (epoch=8)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [8][    4/    4]    Loss 1.259821    Top1 51.103368    Top5 100.000000    \n",
            "==> Top1: 51.103    Top5: 100.000    Loss: 1.260\n",
            "\n",
            "==> Confusion:\n",
            "[[173   0   1   0   0   0]\n",
            " [105   0   1   0   0   0]\n",
            " [ 48   0 116   1   0   0]\n",
            " [  4   0  16 183   0   0]\n",
            " [  0   0   9 204   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 51.103   Top5: 100.000   Sparsity:0.00   Params: 80076 on epoch: 8]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [9][   10/   31]    Overall Loss 1.241674    Objective Loss 1.241674                                        LR 0.001000    Time 0.207162    \n",
            "Epoch: [9][   20/   31]    Overall Loss 1.231241    Objective Loss 1.231241                                        LR 0.001000    Time 0.154788    \n",
            "Epoch: [9][   30/   31]    Overall Loss 1.230205    Objective Loss 1.230205    Top1 54.296875    Top5 100.000000    LR 0.001000    Time 0.123081    \n",
            "Epoch: [9][   31/   31]    Overall Loss 1.229942    Objective Loss 1.229942    Top1 53.963415    Top5 100.000000    LR 0.001000    Time 0.120464    \n",
            "--- validate (epoch=9)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [9][    4/    4]    Loss 1.270462    Top1 50.871080    Top5 99.767712    \n",
            "==> Top1: 50.871    Top5: 99.768    Loss: 1.270\n",
            "\n",
            "==> Confusion:\n",
            "[[163   0  11   0   0   0]\n",
            " [ 99   0   7   0   0   0]\n",
            " [ 24   0 129  12   0   0]\n",
            " [  3   0  10 190   0   0]\n",
            " [  0   0   1 212   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 51.103   Top5: 100.000   Sparsity:0.00   Params: 80076 on epoch: 8]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Initiating quantization aware training (QAT)...\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [10][   10/   31]    Overall Loss 1.222831    Objective Loss 1.222831                                        LR 0.001000    Time 0.219162    \n",
            "Epoch: [10][   20/   31]    Overall Loss 1.225326    Objective Loss 1.225326                                        LR 0.001000    Time 0.166113    \n",
            "Epoch: [10][   30/   31]    Overall Loss 1.227160    Objective Loss 1.227160    Top1 51.171875    Top5 100.000000    LR 0.001000    Time 0.136710    \n",
            "Epoch: [10][   31/   31]    Overall Loss 1.226216    Objective Loss 1.226216    Top1 51.829268    Top5 100.000000    LR 0.001000    Time 0.134141    \n",
            "--- validate (epoch=10)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [10][    4/    4]    Loss 1.267792    Top1 51.335656    Top5 99.883856    \n",
            "==> Top1: 51.336    Top5: 99.884    Loss: 1.268\n",
            "\n",
            "==> Confusion:\n",
            "[[170   0   4   0   0   0]\n",
            " [103   0   3   0   0   0]\n",
            " [ 35   0 123   7   0   0]\n",
            " [  4   0  11 188   0   0]\n",
            " [  0   0   4 209   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 51.336   Top5: 99.884   Sparsity:0.00   Params: 80076 on epoch: 10]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [11][   10/   31]    Overall Loss 1.224125    Objective Loss 1.224125                                        LR 0.001000    Time 0.215419    \n",
            "Epoch: [11][   20/   31]    Overall Loss 1.224421    Objective Loss 1.224421                                        LR 0.001000    Time 0.165942    \n",
            "Epoch: [11][   30/   31]    Overall Loss 1.223689    Objective Loss 1.223689    Top1 51.562500    Top5 100.000000    LR 0.001000    Time 0.133626    \n",
            "Epoch: [11][   31/   31]    Overall Loss 1.223048    Objective Loss 1.223048    Top1 52.439024    Top5 100.000000    LR 0.001000    Time 0.130992    \n",
            "--- validate (epoch=11)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [11][    4/    4]    Loss 1.253863    Top1 51.567944    Top5 100.000000    \n",
            "==> Top1: 51.568    Top5: 100.000    Loss: 1.254\n",
            "\n",
            "==> Confusion:\n",
            "[[170   0   4   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 41   0 119   5   0   0]\n",
            " [  4   0  13 186   0   0]\n",
            " [  0   0   7 206   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 51.568   Top5: 100.000   Sparsity:0.00   Params: 80076 on epoch: 11]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [12][   10/   31]    Overall Loss 1.230522    Objective Loss 1.230522                                        LR 0.001000    Time 0.120646    \n",
            "Epoch: [12][   20/   31]    Overall Loss 1.225204    Objective Loss 1.225204                                        LR 0.001000    Time 0.092042    \n",
            "Epoch: [12][   30/   31]    Overall Loss 1.223931    Objective Loss 1.223931    Top1 51.171875    Top5 100.000000    LR 0.001000    Time 0.076266    \n",
            "Epoch: [12][   31/   31]    Overall Loss 1.224599    Objective Loss 1.224599    Top1 51.829268    Top5 100.000000    LR 0.001000    Time 0.074983    \n",
            "--- validate (epoch=12)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [12][    4/    4]    Loss 1.275169    Top1 50.522648    Top5 99.535424    \n",
            "==> Top1: 50.523    Top5: 99.535    Loss: 1.275\n",
            "\n",
            "==> Confusion:\n",
            "[[157   0  17   0   0   0]\n",
            " [ 97   0   9   0   0   0]\n",
            " [ 17   0 137  11   0   0]\n",
            " [  3   0  10 190   0   0]\n",
            " [  0   0   1 212   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 51.568   Top5: 100.000   Sparsity:0.00   Params: 80076 on epoch: 11]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [13][   10/   31]    Overall Loss 1.221765    Objective Loss 1.221765                                        LR 0.001000    Time 0.120001    \n",
            "Epoch: [13][   20/   31]    Overall Loss 1.216228    Objective Loss 1.216228                                        LR 0.001000    Time 0.091706    \n",
            "Epoch: [13][   30/   31]    Overall Loss 1.218092    Objective Loss 1.218092    Top1 51.562500    Top5 100.000000    LR 0.001000    Time 0.075628    \n",
            "Epoch: [13][   31/   31]    Overall Loss 1.217494    Objective Loss 1.217494    Top1 50.304878    Top5 100.000000    LR 0.001000    Time 0.074303    \n",
            "--- validate (epoch=13)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [13][    4/    4]    Loss 1.269205    Top1 50.754936    Top5 99.651568    \n",
            "==> Top1: 50.755    Top5: 99.652    Loss: 1.269\n",
            "\n",
            "==> Confusion:\n",
            "[[163   0  11   0   0   0]\n",
            " [101   0   5   0   0   0]\n",
            " [ 26   0 131   8   0   0]\n",
            " [  3   0  11 189   0   0]\n",
            " [  0   0   4 209   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 51.568   Top5: 100.000   Sparsity:0.00   Params: 80076 on epoch: 11]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [14][   10/   31]    Overall Loss 1.216759    Objective Loss 1.216759                                        LR 0.001000    Time 0.141674    \n",
            "Epoch: [14][   20/   31]    Overall Loss 1.216720    Objective Loss 1.216720                                        LR 0.001000    Time 0.103140    \n",
            "Epoch: [14][   30/   31]    Overall Loss 1.215678    Objective Loss 1.215678    Top1 57.031250    Top5 100.000000    LR 0.001000    Time 0.083947    \n",
            "Epoch: [14][   31/   31]    Overall Loss 1.215712    Objective Loss 1.215712    Top1 54.878049    Top5 100.000000    LR 0.001000    Time 0.082395    \n",
            "--- validate (epoch=14)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [14][    4/    4]    Loss 1.274569    Top1 51.219512    Top5 99.767712    \n",
            "==> Top1: 51.220    Top5: 99.768    Loss: 1.275\n",
            "\n",
            "==> Confusion:\n",
            "[[168   0   6   0   0   0]\n",
            " [104   0   2   0   0   0]\n",
            " [ 28   0 128   9   0   0]\n",
            " [  3   0  11 189   0   0]\n",
            " [  0   0   3 210   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 51.568   Top5: 100.000   Sparsity:0.00   Params: 80076 on epoch: 11]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [15][   10/   31]    Overall Loss 1.216801    Objective Loss 1.216801                                        LR 0.001000    Time 0.175214    \n",
            "Epoch: [15][   20/   31]    Overall Loss 1.217652    Objective Loss 1.217652                                        LR 0.001000    Time 0.141750    \n",
            "Epoch: [15][   30/   31]    Overall Loss 1.217418    Objective Loss 1.217418    Top1 55.468750    Top5 100.000000    LR 0.001000    Time 0.116086    \n",
            "Epoch: [15][   31/   31]    Overall Loss 1.218161    Objective Loss 1.218161    Top1 56.402439    Top5 100.000000    LR 0.001000    Time 0.113822    \n",
            "--- validate (epoch=15)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [15][    4/    4]    Loss 1.281258    Top1 50.290360    Top5 99.303136    \n",
            "==> Top1: 50.290    Top5: 99.303    Loss: 1.281\n",
            "\n",
            "==> Confusion:\n",
            "[[157   0  17   0   0   0]\n",
            " [ 99   0   7   0   0   0]\n",
            " [ 17   0 139   9   0   0]\n",
            " [  3   0  12 188   0   0]\n",
            " [  0   0   3 210   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 51.568   Top5: 100.000   Sparsity:0.00   Params: 80076 on epoch: 11]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [16][   10/   31]    Overall Loss 1.216141    Objective Loss 1.216141                                        LR 0.001000    Time 0.195652    \n",
            "Epoch: [16][   20/   31]    Overall Loss 1.209365    Objective Loss 1.209365                                        LR 0.001000    Time 0.154860    \n",
            "Epoch: [16][   30/   31]    Overall Loss 1.215150    Objective Loss 1.215150    Top1 55.468750    Top5 100.000000    LR 0.001000    Time 0.126378    \n",
            "Epoch: [16][   31/   31]    Overall Loss 1.215259    Objective Loss 1.215259    Top1 57.012195    Top5 100.000000    LR 0.001000    Time 0.123987    \n",
            "--- validate (epoch=16)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [16][    4/    4]    Loss 1.266344    Top1 51.103368    Top5 99.767712    \n",
            "==> Top1: 51.103    Top5: 99.768    Loss: 1.266\n",
            "\n",
            "==> Confusion:\n",
            "[[170   0   4   0   0   0]\n",
            " [105   0   1   0   0   0]\n",
            " [ 33   0 124   8   0   0]\n",
            " [  3   0  11 189   0   0]\n",
            " [  0   0   1 212   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 51.568   Top5: 100.000   Sparsity:0.00   Params: 80076 on epoch: 11]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [17][   10/   31]    Overall Loss 1.221325    Objective Loss 1.221325                                        LR 0.001000    Time 0.188087    \n",
            "Epoch: [17][   20/   31]    Overall Loss 1.214238    Objective Loss 1.214238                                        LR 0.001000    Time 0.144897    \n",
            "Epoch: [17][   30/   31]    Overall Loss 1.218148    Objective Loss 1.218148    Top1 54.687500    Top5 100.000000    LR 0.001000    Time 0.120361    \n",
            "Epoch: [17][   31/   31]    Overall Loss 1.217438    Objective Loss 1.217438    Top1 53.658537    Top5 100.000000    LR 0.001000    Time 0.118109    \n",
            "--- validate (epoch=17)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [17][    4/    4]    Loss 1.290472    Top1 49.593496    Top5 99.070848    \n",
            "==> Top1: 49.593    Top5: 99.071    Loss: 1.290\n",
            "\n",
            "==> Confusion:\n",
            "[[160   0  14   0   0   0]\n",
            " [100   0   6   0   0   0]\n",
            " [ 18   0 129  18   0   0]\n",
            " [  3   0   9 191   0   0]\n",
            " [  0   0   1 212   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 51.568   Top5: 100.000   Sparsity:0.00   Params: 80076 on epoch: 11]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [18][   10/   31]    Overall Loss 1.207725    Objective Loss 1.207725                                        LR 0.001000    Time 0.122046    \n",
            "Epoch: [18][   20/   31]    Overall Loss 1.211526    Objective Loss 1.211526                                        LR 0.001000    Time 0.093581    \n",
            "Epoch: [18][   30/   31]    Overall Loss 1.213513    Objective Loss 1.213513    Top1 57.031250    Top5 100.000000    LR 0.001000    Time 0.077404    \n",
            "Epoch: [18][   31/   31]    Overall Loss 1.212582    Objective Loss 1.212582    Top1 56.097561    Top5 100.000000    LR 0.001000    Time 0.076073    \n",
            "--- validate (epoch=18)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [18][    4/    4]    Loss 1.325969    Top1 48.548200    Top5 97.909408    \n",
            "==> Top1: 48.548    Top5: 97.909    Loss: 1.326\n",
            "\n",
            "==> Confusion:\n",
            "[[145   0  29   0   0   0]\n",
            " [ 94   0  12   0   0   0]\n",
            " [ 11   0 136  18   0   0]\n",
            " [  1   0  11 191   0   0]\n",
            " [  0   0   1 212   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 51.568   Top5: 100.000   Sparsity:0.00   Params: 80076 on epoch: 11]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [19][   10/   31]    Overall Loss 1.211647    Objective Loss 1.211647                                        LR 0.001000    Time 0.121767    \n",
            "Epoch: [19][   20/   31]    Overall Loss 1.215190    Objective Loss 1.215190                                        LR 0.001000    Time 0.093323    \n",
            "Epoch: [19][   30/   31]    Overall Loss 1.214054    Objective Loss 1.214054    Top1 58.984375    Top5 100.000000    LR 0.001000    Time 0.077065    \n",
            "Epoch: [19][   31/   31]    Overall Loss 1.214152    Objective Loss 1.214152    Top1 56.707317    Top5 100.000000    LR 0.001000    Time 0.075736    \n",
            "--- validate (epoch=19)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [19][    4/    4]    Loss 1.255985    Top1 51.451800    Top5 99.883856    \n",
            "==> Top1: 51.452    Top5: 99.884    Loss: 1.256\n",
            "\n",
            "==> Confusion:\n",
            "[[173   0   1   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 40   0 120   5   0   0]\n",
            " [  4   0  10 189   0   0]\n",
            " [  0   0   5 208   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 51.568   Top5: 100.000   Sparsity:0.00   Params: 80076 on epoch: 11]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [20][   10/   31]    Overall Loss 1.216487    Objective Loss 1.216487                                        LR 0.001000    Time 0.124316    \n",
            "Epoch: [20][   20/   31]    Overall Loss 1.212623    Objective Loss 1.212623                                        LR 0.001000    Time 0.095729    \n",
            "Epoch: [20][   30/   31]    Overall Loss 1.209511    Objective Loss 1.209511    Top1 55.468750    Top5 100.000000    LR 0.001000    Time 0.078970    \n",
            "Epoch: [20][   31/   31]    Overall Loss 1.209313    Objective Loss 1.209313    Top1 55.487805    Top5 100.000000    LR 0.001000    Time 0.077582    \n",
            "--- validate (epoch=20)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [20][    4/    4]    Loss 1.266191    Top1 51.451800    Top5 99.651568    \n",
            "==> Top1: 51.452    Top5: 99.652    Loss: 1.266\n",
            "\n",
            "==> Confusion:\n",
            "[[169   0   5   0   0   0]\n",
            " [103   0   3   0   0   0]\n",
            " [ 32   0 126   7   0   0]\n",
            " [  2   0  11 190   0   0]\n",
            " [  0   0   2 211   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 51.568   Top5: 100.000   Sparsity:0.00   Params: 80076 on epoch: 11]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [21][   10/   31]    Overall Loss 1.201116    Objective Loss 1.201116                                        LR 0.001000    Time 0.192734    \n",
            "Epoch: [21][   20/   31]    Overall Loss 1.203963    Objective Loss 1.203963                                        LR 0.001000    Time 0.150083    \n",
            "Epoch: [21][   30/   31]    Overall Loss 1.206723    Objective Loss 1.206723    Top1 55.078125    Top5 100.000000    LR 0.001000    Time 0.123352    \n",
            "Epoch: [21][   31/   31]    Overall Loss 1.207957    Objective Loss 1.207957    Top1 56.707317    Top5 100.000000    LR 0.001000    Time 0.121026    \n",
            "--- validate (epoch=21)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [21][    4/    4]    Loss 1.262656    Top1 50.871080    Top5 99.186992    \n",
            "==> Top1: 50.871    Top5: 99.187    Loss: 1.263\n",
            "\n",
            "==> Confusion:\n",
            "[[169   0   5   0   0   0]\n",
            " [105   0   1   0   0   0]\n",
            " [ 34   0 126   5   0   0]\n",
            " [  3   0  11 189   0   0]\n",
            " [  0   0   5 208   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 51.568   Top5: 100.000   Sparsity:0.00   Params: 80076 on epoch: 11]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [22][   10/   31]    Overall Loss 1.209020    Objective Loss 1.209020                                        LR 0.001000    Time 0.199905    \n",
            "Epoch: [22][   20/   31]    Overall Loss 1.207771    Objective Loss 1.207771                                        LR 0.001000    Time 0.150800    \n",
            "Epoch: [22][   30/   31]    Overall Loss 1.209570    Objective Loss 1.209570    Top1 53.906250    Top5 100.000000    LR 0.001000    Time 0.123856    \n",
            "Epoch: [22][   31/   31]    Overall Loss 1.209178    Objective Loss 1.209178    Top1 53.963415    Top5 100.000000    LR 0.001000    Time 0.121669    \n",
            "--- validate (epoch=22)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [22][    4/    4]    Loss 1.259633    Top1 51.335656    Top5 99.535424    \n",
            "==> Top1: 51.336    Top5: 99.535    Loss: 1.260\n",
            "\n",
            "==> Confusion:\n",
            "[[170   0   4   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 32   0 128   5   0   0]\n",
            " [  2   0  14 187   0   0]\n",
            " [  0   0   5 208   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 51.568   Top5: 100.000   Sparsity:0.00   Params: 80076 on epoch: 11]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [23][   10/   31]    Overall Loss 1.208807    Objective Loss 1.208807                                        LR 0.001000    Time 0.216963    \n",
            "Epoch: [23][   20/   31]    Overall Loss 1.206582    Objective Loss 1.206582                                        LR 0.001000    Time 0.170947    \n",
            "Epoch: [23][   30/   31]    Overall Loss 1.204706    Objective Loss 1.204706    Top1 56.250000    Top5 100.000000    LR 0.001000    Time 0.138440    \n",
            "Epoch: [23][   31/   31]    Overall Loss 1.203573    Objective Loss 1.203573    Top1 56.402439    Top5 100.000000    LR 0.001000    Time 0.135545    \n",
            "--- validate (epoch=23)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [23][    4/    4]    Loss 1.308156    Top1 50.754936    Top5 98.257840    \n",
            "==> Top1: 50.755    Top5: 98.258    Loss: 1.308\n",
            "\n",
            "==> Confusion:\n",
            "[[163   0  11   0   0   0]\n",
            " [100   0   6   0   0   0]\n",
            " [ 22   0 137   6   0   0]\n",
            " [  1   0  12 190   0   0]\n",
            " [  0   0   1 212   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 51.568   Top5: 100.000   Sparsity:0.00   Params: 80076 on epoch: 11]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [24][   10/   31]    Overall Loss 1.202578    Objective Loss 1.202578                                        LR 0.001000    Time 0.145594    \n",
            "Epoch: [24][   20/   31]    Overall Loss 1.196921    Objective Loss 1.196921                                        LR 0.001000    Time 0.104555    \n",
            "Epoch: [24][   30/   31]    Overall Loss 1.202042    Objective Loss 1.202042    Top1 59.375000    Top5 100.000000    LR 0.001000    Time 0.085024    \n",
            "Epoch: [24][   31/   31]    Overall Loss 1.202544    Objective Loss 1.202544    Top1 57.317073    Top5 100.000000    LR 0.001000    Time 0.083424    \n",
            "--- validate (epoch=24)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [24][    4/    4]    Loss 1.287185    Top1 50.406504    Top5 98.490128    \n",
            "==> Top1: 50.407    Top5: 98.490    Loss: 1.287\n",
            "\n",
            "==> Confusion:\n",
            "[[165   0   9   0   0   0]\n",
            " [104   0   2   0   0   0]\n",
            " [ 25   0 134   6   0   0]\n",
            " [  2   0  11 190   0   0]\n",
            " [  0   0   3 210   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 51.568   Top5: 100.000   Sparsity:0.00   Params: 80076 on epoch: 11]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [25][   10/   31]    Overall Loss 1.198751    Objective Loss 1.198751                                        LR 0.001000    Time 0.121225    \n",
            "Epoch: [25][   20/   31]    Overall Loss 1.197366    Objective Loss 1.197366                                        LR 0.001000    Time 0.093314    \n",
            "Epoch: [25][   30/   31]    Overall Loss 1.200815    Objective Loss 1.200815    Top1 51.953125    Top5 100.000000    LR 0.001000    Time 0.077495    \n",
            "Epoch: [25][   31/   31]    Overall Loss 1.201367    Objective Loss 1.201367    Top1 50.000000    Top5 100.000000    LR 0.001000    Time 0.076147    \n",
            "--- validate (epoch=25)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [25][    4/    4]    Loss 1.309989    Top1 49.012776    Top5 97.444832    \n",
            "==> Top1: 49.013    Top5: 97.445    Loss: 1.310\n",
            "\n",
            "==> Confusion:\n",
            "[[155   0  19   0   0   0]\n",
            " [ 98   0   8   0   0   0]\n",
            " [ 15   0 137  13   0   0]\n",
            " [  1   0  10 192   0   0]\n",
            " [  0   0   0 213   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 51.568   Top5: 100.000   Sparsity:0.00   Params: 80076 on epoch: 11]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [26][   10/   31]    Overall Loss 1.194421    Objective Loss 1.194421                                        LR 0.001000    Time 0.124298    \n",
            "Epoch: [26][   20/   31]    Overall Loss 1.204463    Objective Loss 1.204463                                        LR 0.001000    Time 0.100796    \n",
            "Epoch: [26][   30/   31]    Overall Loss 1.201877    Objective Loss 1.201877    Top1 58.203125    Top5 100.000000    LR 0.001000    Time 0.087117    \n",
            "Epoch: [26][   31/   31]    Overall Loss 1.202749    Objective Loss 1.202749    Top1 57.926829    Top5 100.000000    LR 0.001000    Time 0.085798    \n",
            "--- validate (epoch=26)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [26][    4/    4]    Loss 1.281395    Top1 50.174216    Top5 97.677120    \n",
            "==> Top1: 50.174    Top5: 97.677    Loss: 1.281\n",
            "\n",
            "==> Confusion:\n",
            "[[153   0  21   0   0   0]\n",
            " [101   0   5   0   0   0]\n",
            " [ 16   0 141   8   0   0]\n",
            " [  1   0  12 190   0   0]\n",
            " [  0   0   3 210   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 51.568   Top5: 100.000   Sparsity:0.00   Params: 80076 on epoch: 11]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [27][   10/   31]    Overall Loss 1.199842    Objective Loss 1.199842                                        LR 0.001000    Time 0.199567    \n",
            "Epoch: [27][   20/   31]    Overall Loss 1.200788    Objective Loss 1.200788                                        LR 0.001000    Time 0.153718    \n",
            "Epoch: [27][   30/   31]    Overall Loss 1.202257    Objective Loss 1.202257    Top1 58.593750    Top5 100.000000    LR 0.001000    Time 0.124058    \n",
            "Epoch: [27][   31/   31]    Overall Loss 1.201602    Objective Loss 1.201602    Top1 57.317073    Top5 100.000000    LR 0.001000    Time 0.121747    \n",
            "--- validate (epoch=27)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [27][    4/    4]    Loss 1.290045    Top1 50.174216    Top5 98.606272    \n",
            "==> Top1: 50.174    Top5: 98.606    Loss: 1.290\n",
            "\n",
            "==> Confusion:\n",
            "[[168   0   6   0   0   0]\n",
            " [104   0   2   0   0   0]\n",
            " [ 27   0 130   8   0   0]\n",
            " [  1   0  11 191   0   0]\n",
            " [  0   0   1 212   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 51.568   Top5: 100.000   Sparsity:0.00   Params: 80076 on epoch: 11]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [28][   10/   31]    Overall Loss 1.194545    Objective Loss 1.194545                                        LR 0.001000    Time 0.190084    \n",
            "Epoch: [28][   20/   31]    Overall Loss 1.198260    Objective Loss 1.198260                                        LR 0.001000    Time 0.147219    \n",
            "Epoch: [28][   30/   31]    Overall Loss 1.203131    Objective Loss 1.203131    Top1 57.031250    Top5 100.000000    LR 0.001000    Time 0.121831    \n",
            "Epoch: [28][   31/   31]    Overall Loss 1.203516    Objective Loss 1.203516    Top1 55.182927    Top5 100.000000    LR 0.001000    Time 0.119588    \n",
            "--- validate (epoch=28)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [28][    4/    4]    Loss 1.316686    Top1 50.174216    Top5 97.328688    \n",
            "==> Top1: 50.174    Top5: 97.329    Loss: 1.317\n",
            "\n",
            "==> Confusion:\n",
            "[[159   0  15   0   0   0]\n",
            " [101   0   5   0   0   0]\n",
            " [ 12   0 143  10   0   0]\n",
            " [  1   0  10 192   0   0]\n",
            " [  0   0   0 213   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 51.568   Top5: 100.000   Sparsity:0.00   Params: 80076 on epoch: 11]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [29][   10/   31]    Overall Loss 1.206581    Objective Loss 1.206581                                        LR 0.001000    Time 0.177267    \n",
            "Epoch: [29][   20/   31]    Overall Loss 1.232920    Objective Loss 1.232920                                        LR 0.001000    Time 0.119620    \n",
            "Epoch: [29][   30/   31]    Overall Loss 1.237898    Objective Loss 1.237898    Top1 50.781250    Top5 100.000000    LR 0.001000    Time 0.095143    \n",
            "Epoch: [29][   31/   31]    Overall Loss 1.238733    Objective Loss 1.238733    Top1 51.524390    Top5 100.000000    LR 0.001000    Time 0.093183    \n",
            "--- validate (epoch=29)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [29][    4/    4]    Loss 1.272474    Top1 51.684088    Top5 99.767712    \n",
            "==> Top1: 51.684    Top5: 99.768    Loss: 1.272\n",
            "\n",
            "==> Confusion:\n",
            "[[173   0   1   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 50   0 112   3   0   0]\n",
            " [  4   0  10 189   0   0]\n",
            " [  0   0   5 208   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 51.684   Top5: 99.768   Sparsity:0.00   Params: 80076 on epoch: 29]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [30][   10/   31]    Overall Loss 1.203906    Objective Loss 1.203906                                        LR 0.001000    Time 0.123128    \n",
            "Epoch: [30][   20/   31]    Overall Loss 1.204220    Objective Loss 1.204220                                        LR 0.001000    Time 0.093500    \n",
            "Epoch: [30][   30/   31]    Overall Loss 1.204511    Objective Loss 1.204511    Top1 55.859375    Top5 100.000000    LR 0.001000    Time 0.077692    \n",
            "Epoch: [30][   31/   31]    Overall Loss 1.206325    Objective Loss 1.206325    Top1 56.402439    Top5 100.000000    LR 0.001000    Time 0.076345    \n",
            "--- validate (epoch=30)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [30][    4/    4]    Loss 1.262552    Top1 51.916376    Top5 98.838560    \n",
            "==> Top1: 51.916    Top5: 98.839    Loss: 1.263\n",
            "\n",
            "==> Confusion:\n",
            "[[171   0   3   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 40   0 121   4   0   0]\n",
            " [  2   0  11 190   0   0]\n",
            " [  0   0   2 211   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 51.916   Top5: 98.839   Sparsity:0.00   Params: 80076 on epoch: 30]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [31][   10/   31]    Overall Loss 1.200523    Objective Loss 1.200523                                        LR 0.001000    Time 0.123663    \n",
            "Epoch: [31][   20/   31]    Overall Loss 1.200590    Objective Loss 1.200590                                        LR 0.001000    Time 0.096102    \n",
            "Epoch: [31][   30/   31]    Overall Loss 1.205900    Objective Loss 1.205900    Top1 53.125000    Top5 100.000000    LR 0.001000    Time 0.079971    \n",
            "Epoch: [31][   31/   31]    Overall Loss 1.206183    Objective Loss 1.206183    Top1 53.963415    Top5 100.000000    LR 0.001000    Time 0.078605    \n",
            "--- validate (epoch=31)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [31][    4/    4]    Loss 1.313083    Top1 48.083624    Top5 96.747967    \n",
            "==> Top1: 48.084    Top5: 96.748    Loss: 1.313\n",
            "\n",
            "==> Confusion:\n",
            "[[151   0  23   0   0   0]\n",
            " [100   0   6   0   0   0]\n",
            " [ 12   0 129  24   0   0]\n",
            " [  1   0  10 192   0   0]\n",
            " [  0   0   1 212   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 51.916   Top5: 98.839   Sparsity:0.00   Params: 80076 on epoch: 30]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [32][   10/   31]    Overall Loss 1.211738    Objective Loss 1.211738                                        LR 0.001000    Time 0.124136    \n",
            "Epoch: [32][   20/   31]    Overall Loss 1.210323    Objective Loss 1.210323                                        LR 0.001000    Time 0.108780    \n",
            "Epoch: [32][   30/   31]    Overall Loss 1.207822    Objective Loss 1.207822    Top1 57.812500    Top5 100.000000    LR 0.001000    Time 0.093992    \n",
            "Epoch: [32][   31/   31]    Overall Loss 1.207564    Objective Loss 1.207564    Top1 57.926829    Top5 100.000000    LR 0.001000    Time 0.092558    \n",
            "--- validate (epoch=32)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [32][    4/    4]    Loss 1.349270    Top1 46.573751    Top5 96.399535    \n",
            "==> Top1: 46.574    Top5: 96.400    Loss: 1.349\n",
            "\n",
            "==> Confusion:\n",
            "[[145   0  29   0   0   0]\n",
            " [ 93   0  13   0   0   0]\n",
            " [  9   0 123  33   0   0]\n",
            " [  1   0   8 194   0   0]\n",
            " [  0   0   0 213   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 51.916   Top5: 98.839   Sparsity:0.00   Params: 80076 on epoch: 30]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [33][   10/   31]    Overall Loss 1.199623    Objective Loss 1.199623                                        LR 0.001000    Time 0.195603    \n",
            "Epoch: [33][   20/   31]    Overall Loss 1.199793    Objective Loss 1.199793                                        LR 0.001000    Time 0.151727    \n",
            "Epoch: [33][   30/   31]    Overall Loss 1.202410    Objective Loss 1.202410    Top1 54.296875    Top5 100.000000    LR 0.001000    Time 0.124418    \n",
            "Epoch: [33][   31/   31]    Overall Loss 1.201706    Objective Loss 1.201706    Top1 54.573171    Top5 100.000000    LR 0.001000    Time 0.122087    \n",
            "--- validate (epoch=33)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [33][    4/    4]    Loss 1.295384    Top1 49.941928    Top5 98.141696    \n",
            "==> Top1: 49.942    Top5: 98.142    Loss: 1.295\n",
            "\n",
            "==> Confusion:\n",
            "[[162   0  12   0   0   0]\n",
            " [104   0   2   0   0   0]\n",
            " [ 20   0 136   9   0   0]\n",
            " [  1   0  12 190   0   0]\n",
            " [  0   0   1 212   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 51.916   Top5: 98.839   Sparsity:0.00   Params: 80076 on epoch: 30]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [34][   10/   31]    Overall Loss 1.205065    Objective Loss 1.205065                                        LR 0.001000    Time 0.193876    \n",
            "Epoch: [34][   20/   31]    Overall Loss 1.200371    Objective Loss 1.200371                                        LR 0.001000    Time 0.150898    \n",
            "Epoch: [34][   30/   31]    Overall Loss 1.200836    Objective Loss 1.200836    Top1 52.734375    Top5 100.000000    LR 0.001000    Time 0.123332    \n",
            "Epoch: [34][   31/   31]    Overall Loss 1.199949    Objective Loss 1.199949    Top1 52.439024    Top5 100.000000    LR 0.001000    Time 0.120955    \n",
            "--- validate (epoch=34)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [34][    4/    4]    Loss 1.251909    Top1 51.916376    Top5 99.535424    \n",
            "==> Top1: 51.916    Top5: 99.535    Loss: 1.252\n",
            "\n",
            "==> Confusion:\n",
            "[[174   0   0   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 43   0 118   4   0   0]\n",
            " [  3   0  12 188   0   0]\n",
            " [  0   0   4 209   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 51.916   Top5: 99.535   Sparsity:0.00   Params: 80076 on epoch: 34]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [35][   10/   31]    Overall Loss 1.205961    Objective Loss 1.205961                                        LR 0.001000    Time 0.147688    \n",
            "Epoch: [35][   20/   31]    Overall Loss 1.200553    Objective Loss 1.200553                                        LR 0.001000    Time 0.105748    \n",
            "Epoch: [35][   30/   31]    Overall Loss 1.199011    Objective Loss 1.199011    Top1 54.687500    Top5 100.000000    LR 0.001000    Time 0.087453    \n",
            "Epoch: [35][   31/   31]    Overall Loss 1.198199    Objective Loss 1.198199    Top1 55.182927    Top5 100.000000    LR 0.001000    Time 0.085757    \n",
            "--- validate (epoch=35)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [35][    4/    4]    Loss 1.258877    Top1 51.684088    Top5 98.838560    \n",
            "==> Top1: 51.684    Top5: 98.839    Loss: 1.259\n",
            "\n",
            "==> Confusion:\n",
            "[[172   0   2   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 32   0 128   5   0   0]\n",
            " [  1   0  13 189   0   0]\n",
            " [  0   0   3 210   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 51.916   Top5: 99.535   Sparsity:0.00   Params: 80076 on epoch: 34]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [36][   10/   31]    Overall Loss 1.200064    Objective Loss 1.200064                                        LR 0.001000    Time 0.120813    \n",
            "Epoch: [36][   20/   31]    Overall Loss 1.199256    Objective Loss 1.199256                                        LR 0.001000    Time 0.092764    \n",
            "Epoch: [36][   30/   31]    Overall Loss 1.199803    Objective Loss 1.199803    Top1 55.078125    Top5 100.000000    LR 0.001000    Time 0.077517    \n",
            "Epoch: [36][   31/   31]    Overall Loss 1.199102    Objective Loss 1.199102    Top1 56.402439    Top5 100.000000    LR 0.001000    Time 0.076186    \n",
            "--- validate (epoch=36)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [36][    4/    4]    Loss 1.254694    Top1 52.032520    Top5 99.070848    \n",
            "==> Top1: 52.033    Top5: 99.071    Loss: 1.255\n",
            "\n",
            "==> Confusion:\n",
            "[[172   0   2   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 38   0 125   2   0   0]\n",
            " [  1   0  14 188   0   0]\n",
            " [  0   0   5 208   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.033   Top5: 99.071   Sparsity:0.00   Params: 80076 on epoch: 36]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [37][   10/   31]    Overall Loss 1.197653    Objective Loss 1.197653                                        LR 0.001000    Time 0.127827    \n",
            "Epoch: [37][   20/   31]    Overall Loss 1.197036    Objective Loss 1.197036                                        LR 0.001000    Time 0.096637    \n",
            "Epoch: [37][   30/   31]    Overall Loss 1.196712    Objective Loss 1.196712    Top1 51.171875    Top5 100.000000    LR 0.001000    Time 0.078978    \n",
            "Epoch: [37][   31/   31]    Overall Loss 1.195702    Objective Loss 1.195702    Top1 52.134146    Top5 100.000000    LR 0.001000    Time 0.077549    \n",
            "--- validate (epoch=37)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [37][    4/    4]    Loss 1.287694    Top1 50.174216    Top5 97.328688    \n",
            "==> Top1: 50.174    Top5: 97.329    Loss: 1.288\n",
            "\n",
            "==> Confusion:\n",
            "[[170   0   4   0   0   0]\n",
            " [104   0   2   0   0   0]\n",
            " [ 20   0 136   9   0   0]\n",
            " [  1   0  11 191   0   0]\n",
            " [  0   0   1 212   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.033   Top5: 99.071   Sparsity:0.00   Params: 80076 on epoch: 36]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [38][   10/   31]    Overall Loss 1.207543    Objective Loss 1.207543                                        LR 0.001000    Time 0.149171    \n",
            "Epoch: [38][   20/   31]    Overall Loss 1.221367    Objective Loss 1.221367                                        LR 0.001000    Time 0.121350    \n",
            "Epoch: [38][   30/   31]    Overall Loss 1.240416    Objective Loss 1.240416    Top1 60.937500    Top5 100.000000    LR 0.001000    Time 0.104126    \n",
            "Epoch: [38][   31/   31]    Overall Loss 1.239734    Objective Loss 1.239734    Top1 58.536585    Top5 100.000000    LR 0.001000    Time 0.102238    \n",
            "--- validate (epoch=38)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [38][    4/    4]    Loss 1.292856    Top1 47.967480    Top5 100.000000    \n",
            "==> Top1: 47.967    Top5: 100.000    Loss: 1.293\n",
            "\n",
            "==> Confusion:\n",
            "[[174   0   0   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [134   0  31   0   0   0]\n",
            " [ 12   0  25 166   0   0]\n",
            " [  0   0  22 191   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.033   Top5: 99.071   Sparsity:0.00   Params: 80076 on epoch: 36]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [39][   10/   31]    Overall Loss 1.268118    Objective Loss 1.268118                                        LR 0.001000    Time 0.195539    \n",
            "Epoch: [39][   20/   31]    Overall Loss 1.246734    Objective Loss 1.246734                                        LR 0.001000    Time 0.149501    \n",
            "Epoch: [39][   30/   31]    Overall Loss 1.239308    Objective Loss 1.239308    Top1 53.125000    Top5 99.609375    LR 0.001000    Time 0.122650    \n",
            "Epoch: [39][   31/   31]    Overall Loss 1.238176    Objective Loss 1.238176    Top1 54.573171    Top5 99.695122    LR 0.001000    Time 0.120326    \n",
            "--- validate (epoch=39)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [39][    4/    4]    Loss 1.265330    Top1 51.451800    Top5 98.257840    \n",
            "==> Top1: 51.452    Top5: 98.258    Loss: 1.265\n",
            "\n",
            "==> Confusion:\n",
            "[[168   0   6   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 32   0 129   4   0   0]\n",
            " [  3   0  12 188   0   0]\n",
            " [  0   0   4 209   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.033   Top5: 99.071   Sparsity:0.00   Params: 80076 on epoch: 36]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [40][   10/   31]    Overall Loss 1.206413    Objective Loss 1.206413                                        LR 0.001000    Time 0.191792    \n",
            "Epoch: [40][   20/   31]    Overall Loss 1.197830    Objective Loss 1.197830                                        LR 0.001000    Time 0.149459    \n",
            "Epoch: [40][   30/   31]    Overall Loss 1.200520    Objective Loss 1.200520    Top1 57.421875    Top5 99.609375    LR 0.001000    Time 0.123241    \n",
            "Epoch: [40][   31/   31]    Overall Loss 1.201444    Objective Loss 1.201444    Top1 57.012195    Top5 99.695122    LR 0.001000    Time 0.121004    \n",
            "--- validate (epoch=40)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [40][    4/    4]    Loss 1.287074    Top1 49.593496    Top5 97.328688    \n",
            "==> Top1: 49.593    Top5: 97.329    Loss: 1.287\n",
            "\n",
            "==> Confusion:\n",
            "[[163   0  11   0   0   0]\n",
            " [103   0   3   0   0   0]\n",
            " [ 20   0 137   8   0   0]\n",
            " [  1   0  11 191   0   0]\n",
            " [  0   0   1 212   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.033   Top5: 99.071   Sparsity:0.00   Params: 80076 on epoch: 36]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [41][   10/   31]    Overall Loss 1.185739    Objective Loss 1.185739                                        LR 0.001000    Time 0.126338    \n",
            "Epoch: [41][   20/   31]    Overall Loss 1.199523    Objective Loss 1.199523                                        LR 0.001000    Time 0.095398    \n",
            "Epoch: [41][   30/   31]    Overall Loss 1.201137    Objective Loss 1.201137    Top1 58.593750    Top5 100.000000    LR 0.001000    Time 0.078742    \n",
            "Epoch: [41][   31/   31]    Overall Loss 1.202684    Objective Loss 1.202684    Top1 56.707317    Top5 100.000000    LR 0.001000    Time 0.077329    \n",
            "--- validate (epoch=41)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [41][    4/    4]    Loss 1.273360    Top1 51.451800    Top5 98.606272    \n",
            "==> Top1: 51.452    Top5: 98.606    Loss: 1.273\n",
            "\n",
            "==> Confusion:\n",
            "[[170   0   4   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 31   0 129   5   0   0]\n",
            " [  1   0  13 189   0   0]\n",
            " [  0   0   3 210   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.033   Top5: 99.071   Sparsity:0.00   Params: 80076 on epoch: 36]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [42][   10/   31]    Overall Loss 1.192657    Objective Loss 1.192657                                        LR 0.001000    Time 0.125228    \n",
            "Epoch: [42][   20/   31]    Overall Loss 1.196991    Objective Loss 1.196991                                        LR 0.001000    Time 0.094830    \n",
            "Epoch: [42][   30/   31]    Overall Loss 1.197510    Objective Loss 1.197510    Top1 58.593750    Top5 100.000000    LR 0.001000    Time 0.078685    \n",
            "Epoch: [42][   31/   31]    Overall Loss 1.197411    Objective Loss 1.197411    Top1 56.097561    Top5 100.000000    LR 0.001000    Time 0.077357    \n",
            "--- validate (epoch=42)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [42][    4/    4]    Loss 1.260383    Top1 51.219512    Top5 98.373984    \n",
            "==> Top1: 51.220    Top5: 98.374    Loss: 1.260\n",
            "\n",
            "==> Confusion:\n",
            "[[168   0   6   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 25   0 135   5   0   0]\n",
            " [  2   0  11 190   0   0]\n",
            " [  0   0   2 211   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.033   Top5: 99.071   Sparsity:0.00   Params: 80076 on epoch: 36]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [43][   10/   31]    Overall Loss 1.197546    Objective Loss 1.197546                                        LR 0.001000    Time 0.128793    \n",
            "Epoch: [43][   20/   31]    Overall Loss 1.200937    Objective Loss 1.200937                                        LR 0.001000    Time 0.096699    \n",
            "Epoch: [43][   30/   31]    Overall Loss 1.201689    Objective Loss 1.201689    Top1 54.687500    Top5 100.000000    LR 0.001000    Time 0.079887    \n",
            "Epoch: [43][   31/   31]    Overall Loss 1.201702    Objective Loss 1.201702    Top1 54.573171    Top5 100.000000    LR 0.001000    Time 0.078482    \n",
            "--- validate (epoch=43)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [43][    4/    4]    Loss 1.260942    Top1 52.148664    Top5 98.954704    \n",
            "==> Top1: 52.149    Top5: 98.955    Loss: 1.261\n",
            "\n",
            "==> Confusion:\n",
            "[[174   0   0   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 39   0 124   2   0   0]\n",
            " [  3   0  14 186   0   0]\n",
            " [  0   0   5 208   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.149   Top5: 98.955   Sparsity:0.00   Params: 80076 on epoch: 43]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [44][   10/   31]    Overall Loss 1.205390    Objective Loss 1.205390                                        LR 0.001000    Time 0.172040    \n",
            "Epoch: [44][   20/   31]    Overall Loss 1.203840    Objective Loss 1.203840                                        LR 0.001000    Time 0.138794    \n",
            "Epoch: [44][   30/   31]    Overall Loss 1.200358    Objective Loss 1.200358    Top1 51.953125    Top5 100.000000    LR 0.001000    Time 0.113934    \n",
            "Epoch: [44][   31/   31]    Overall Loss 1.198346    Objective Loss 1.198346    Top1 52.134146    Top5 100.000000    LR 0.001000    Time 0.111870    \n",
            "--- validate (epoch=44)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [44][    4/    4]    Loss 1.276909    Top1 50.406504    Top5 98.025552    \n",
            "==> Top1: 50.407    Top5: 98.026    Loss: 1.277\n",
            "\n",
            "==> Confusion:\n",
            "[[167   0   7   0   0   0]\n",
            " [105   0   1   0   0   0]\n",
            " [ 19   0 138   8   0   0]\n",
            " [  1   0  11 191   0   0]\n",
            " [  0   0   2 211   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.149   Top5: 98.955   Sparsity:0.00   Params: 80076 on epoch: 43]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [45][   10/   31]    Overall Loss 1.195916    Objective Loss 1.195916                                        LR 0.001000    Time 0.221813    \n",
            "Epoch: [45][   20/   31]    Overall Loss 1.200197    Objective Loss 1.200197                                        LR 0.001000    Time 0.159125    \n",
            "Epoch: [45][   30/   31]    Overall Loss 1.198233    Objective Loss 1.198233    Top1 56.640625    Top5 100.000000    LR 0.001000    Time 0.129417    \n",
            "Epoch: [45][   31/   31]    Overall Loss 1.198963    Objective Loss 1.198963    Top1 57.926829    Top5 100.000000    LR 0.001000    Time 0.126947    \n",
            "--- validate (epoch=45)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [45][    4/    4]    Loss 1.279815    Top1 50.522648    Top5 97.560976    \n",
            "==> Top1: 50.523    Top5: 97.561    Loss: 1.280\n",
            "\n",
            "==> Confusion:\n",
            "[[164   0  10   0   0   0]\n",
            " [105   0   1   0   0   0]\n",
            " [ 15   0 143   7   0   0]\n",
            " [  1   0  12 190   0   0]\n",
            " [  0   0   3 210   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.149   Top5: 98.955   Sparsity:0.00   Params: 80076 on epoch: 43]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [46][   10/   31]    Overall Loss 1.197878    Objective Loss 1.197878                                        LR 0.001000    Time 0.206352    \n",
            "Epoch: [46][   20/   31]    Overall Loss 1.194864    Objective Loss 1.194864                                        LR 0.001000    Time 0.157155    \n",
            "Epoch: [46][   30/   31]    Overall Loss 1.195711    Objective Loss 1.195711    Top1 53.906250    Top5 100.000000    LR 0.001000    Time 0.129285    \n",
            "Epoch: [46][   31/   31]    Overall Loss 1.193378    Objective Loss 1.193378    Top1 54.573171    Top5 100.000000    LR 0.001000    Time 0.126772    \n",
            "--- validate (epoch=46)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [46][    4/    4]    Loss 1.313660    Top1 49.709640    Top5 97.328688    \n",
            "==> Top1: 49.710    Top5: 97.329    Loss: 1.314\n",
            "\n",
            "==> Confusion:\n",
            "[[163   0  11   0   0   0]\n",
            " [103   0   3   0   0   0]\n",
            " [ 14   0 140  11   0   0]\n",
            " [  1   0  11 191   0   0]\n",
            " [  0   0   1 212   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.149   Top5: 98.955   Sparsity:0.00   Params: 80076 on epoch: 43]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [47][   10/   31]    Overall Loss 1.200214    Objective Loss 1.200214                                        LR 0.001000    Time 0.123984    \n",
            "Epoch: [47][   20/   31]    Overall Loss 1.196637    Objective Loss 1.196637                                        LR 0.001000    Time 0.093854    \n",
            "Epoch: [47][   30/   31]    Overall Loss 1.197508    Objective Loss 1.197508    Top1 55.859375    Top5 100.000000    LR 0.001000    Time 0.077733    \n",
            "Epoch: [47][   31/   31]    Overall Loss 1.196558    Objective Loss 1.196558    Top1 57.012195    Top5 100.000000    LR 0.001000    Time 0.076371    \n",
            "--- validate (epoch=47)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [47][    4/    4]    Loss 1.270773    Top1 51.451800    Top5 98.722416    \n",
            "==> Top1: 51.452    Top5: 98.722    Loss: 1.271\n",
            "\n",
            "==> Confusion:\n",
            "[[171   0   3   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 35   0 127   3   0   0]\n",
            " [  2   0  13 188   0   0]\n",
            " [  0   0   4 209   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.149   Top5: 98.955   Sparsity:0.00   Params: 80076 on epoch: 43]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [48][   10/   31]    Overall Loss 1.196524    Objective Loss 1.196524                                        LR 0.001000    Time 0.120976    \n",
            "Epoch: [48][   20/   31]    Overall Loss 1.198413    Objective Loss 1.198413                                        LR 0.001000    Time 0.091242    \n",
            "Epoch: [48][   30/   31]    Overall Loss 1.194701    Objective Loss 1.194701    Top1 51.562500    Top5 100.000000    LR 0.001000    Time 0.076117    \n",
            "Epoch: [48][   31/   31]    Overall Loss 1.193925    Objective Loss 1.193925    Top1 51.829268    Top5 100.000000    LR 0.001000    Time 0.074851    \n",
            "--- validate (epoch=48)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [48][    4/    4]    Loss 1.259575    Top1 51.684088    Top5 98.141696    \n",
            "==> Top1: 51.684    Top5: 98.142    Loss: 1.260\n",
            "\n",
            "==> Confusion:\n",
            "[[170   0   4   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 33   0 128   4   0   0]\n",
            " [  3   0  11 189   0   0]\n",
            " [  0   0   3 210   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.149   Top5: 98.955   Sparsity:0.00   Params: 80076 on epoch: 43]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [49][   10/   31]    Overall Loss 1.192164    Objective Loss 1.192164                                        LR 0.001000    Time 0.121384    \n",
            "Epoch: [49][   20/   31]    Overall Loss 1.191826    Objective Loss 1.191826                                        LR 0.001000    Time 0.092046    \n",
            "Epoch: [49][   30/   31]    Overall Loss 1.197074    Objective Loss 1.197074    Top1 51.171875    Top5 99.609375    LR 0.001000    Time 0.076922    \n",
            "Epoch: [49][   31/   31]    Overall Loss 1.197750    Objective Loss 1.197750    Top1 51.524390    Top5 99.695122    LR 0.001000    Time 0.075603    \n",
            "--- validate (epoch=49)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [49][    4/    4]    Loss 1.284656    Top1 50.638792    Top5 97.560976    \n",
            "==> Top1: 50.639    Top5: 97.561    Loss: 1.285\n",
            "\n",
            "==> Confusion:\n",
            "[[169   0   5   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 27   0 133   5   0   0]\n",
            " [  2   0  12 189   0   0]\n",
            " [  0   0   4 209   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.149   Top5: 98.955   Sparsity:0.00   Params: 80076 on epoch: 43]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [50][   10/   31]    Overall Loss 1.206687    Objective Loss 1.206687                                        LR 0.001000    Time 0.188856    \n",
            "Epoch: [50][   20/   31]    Overall Loss 1.202313    Objective Loss 1.202313                                        LR 0.001000    Time 0.144956    \n",
            "Epoch: [50][   30/   31]    Overall Loss 1.197485    Objective Loss 1.197485    Top1 59.765625    Top5 100.000000    LR 0.001000    Time 0.118532    \n",
            "Epoch: [50][   31/   31]    Overall Loss 1.197498    Objective Loss 1.197498    Top1 57.012195    Top5 100.000000    LR 0.001000    Time 0.116325    \n",
            "--- validate (epoch=50)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [50][    4/    4]    Loss 1.267430    Top1 51.684088    Top5 98.141696    \n",
            "==> Top1: 51.684    Top5: 98.142    Loss: 1.267\n",
            "\n",
            "==> Confusion:\n",
            "[[174   0   0   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 42   0 120   3   0   0]\n",
            " [  3   0  12 188   0   0]\n",
            " [  0   0   3 210   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.149   Top5: 98.955   Sparsity:0.00   Params: 80076 on epoch: 43]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [51][   10/   31]    Overall Loss 1.208325    Objective Loss 1.208325                                        LR 0.001000    Time 0.180374    \n",
            "Epoch: [51][   20/   31]    Overall Loss 1.205392    Objective Loss 1.205392                                        LR 0.001000    Time 0.141667    \n",
            "Epoch: [51][   30/   31]    Overall Loss 1.209641    Objective Loss 1.209641    Top1 52.343750    Top5 100.000000    LR 0.001000    Time 0.117052    \n",
            "Epoch: [51][   31/   31]    Overall Loss 1.210518    Objective Loss 1.210518    Top1 53.658537    Top5 100.000000    LR 0.001000    Time 0.114881    \n",
            "--- validate (epoch=51)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [51][    4/    4]    Loss 1.263407    Top1 50.406504    Top5 100.000000    \n",
            "==> Top1: 50.407    Top5: 100.000    Loss: 1.263\n",
            "\n",
            "==> Confusion:\n",
            "[[174   0   0   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 75   0  89   1   0   0]\n",
            " [  6   0  18 179   0   0]\n",
            " [  0   0  15 198   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.149   Top5: 98.955   Sparsity:0.00   Params: 80076 on epoch: 43]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [52][   10/   31]    Overall Loss 1.243258    Objective Loss 1.243258                                        LR 0.001000    Time 0.206238    \n",
            "Epoch: [52][   20/   31]    Overall Loss 1.237664    Objective Loss 1.237664                                        LR 0.001000    Time 0.163617    \n",
            "Epoch: [52][   30/   31]    Overall Loss 1.224643    Objective Loss 1.224643    Top1 60.937500    Top5 100.000000    LR 0.001000    Time 0.138368    \n",
            "Epoch: [52][   31/   31]    Overall Loss 1.222535    Objective Loss 1.222535    Top1 59.756098    Top5 100.000000    LR 0.001000    Time 0.136312    \n",
            "--- validate (epoch=52)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [52][    4/    4]    Loss 1.297455    Top1 50.174216    Top5 97.328688    \n",
            "==> Top1: 50.174    Top5: 97.329    Loss: 1.297\n",
            "\n",
            "==> Confusion:\n",
            "[[160   0  14   0   0   0]\n",
            " [100   0   6   0   0   0]\n",
            " [ 12   0 141  12   0   0]\n",
            " [  1   0  12 190   0   0]\n",
            " [  0   0   0 213   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.149   Top5: 98.955   Sparsity:0.00   Params: 80076 on epoch: 43]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [53][   10/   31]    Overall Loss 1.205270    Objective Loss 1.205270                                        LR 0.001000    Time 0.206141    \n",
            "Epoch: [53][   20/   31]    Overall Loss 1.201977    Objective Loss 1.201977                                        LR 0.001000    Time 0.161024    \n",
            "Epoch: [53][   30/   31]    Overall Loss 1.203151    Objective Loss 1.203151    Top1 58.593750    Top5 100.000000    LR 0.001000    Time 0.131920    \n",
            "Epoch: [53][   31/   31]    Overall Loss 1.201609    Objective Loss 1.201609    Top1 57.926829    Top5 100.000000    LR 0.001000    Time 0.129453    \n",
            "--- validate (epoch=53)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [53][    4/    4]    Loss 1.259714    Top1 52.032520    Top5 98.838560    \n",
            "==> Top1: 52.033    Top5: 98.839    Loss: 1.260\n",
            "\n",
            "==> Confusion:\n",
            "[[173   0   1   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 40   0 122   3   0   0]\n",
            " [  3   0  14 186   0   0]\n",
            " [  0   0   6 207   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.149   Top5: 98.955   Sparsity:0.00   Params: 80076 on epoch: 43]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [54][   10/   31]    Overall Loss 1.208550    Objective Loss 1.208550                                        LR 0.001000    Time 0.206454    \n",
            "Epoch: [54][   20/   31]    Overall Loss 1.206847    Objective Loss 1.206847                                        LR 0.001000    Time 0.164234    \n",
            "Epoch: [54][   30/   31]    Overall Loss 1.204402    Objective Loss 1.204402    Top1 53.125000    Top5 100.000000    LR 0.001000    Time 0.142106    \n",
            "Epoch: [54][   31/   31]    Overall Loss 1.204340    Objective Loss 1.204340    Top1 53.658537    Top5 100.000000    LR 0.001000    Time 0.140273    \n",
            "--- validate (epoch=54)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [54][    4/    4]    Loss 1.258455    Top1 52.380952    Top5 98.606272    \n",
            "==> Top1: 52.381    Top5: 98.606    Loss: 1.258\n",
            "\n",
            "==> Confusion:\n",
            "[[170   0   4   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 23   0 138   4   0   0]\n",
            " [  1   0  14 188   0   0]\n",
            " [  0   0   4 209   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.381   Top5: 98.606   Sparsity:0.00   Params: 80076 on epoch: 54]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [55][   10/   31]    Overall Loss 1.198166    Objective Loss 1.198166                                        LR 0.001000    Time 0.229366    \n",
            "Epoch: [55][   20/   31]    Overall Loss 1.194837    Objective Loss 1.194837                                        LR 0.001000    Time 0.162856    \n",
            "Epoch: [55][   30/   31]    Overall Loss 1.196551    Objective Loss 1.196551    Top1 57.812500    Top5 100.000000    LR 0.001000    Time 0.131078    \n",
            "Epoch: [55][   31/   31]    Overall Loss 1.196212    Objective Loss 1.196212    Top1 58.841463    Top5 100.000000    LR 0.001000    Time 0.128603    \n",
            "--- validate (epoch=55)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [55][    4/    4]    Loss 1.255656    Top1 51.916376    Top5 99.303136    \n",
            "==> Top1: 51.916    Top5: 99.303    Loss: 1.256\n",
            "\n",
            "==> Confusion:\n",
            "[[173   0   1   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 37   0 125   3   0   0]\n",
            " [  1   0  16 186   0   0]\n",
            " [  0   0   6 207   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.381   Top5: 98.606   Sparsity:0.00   Params: 80076 on epoch: 54]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [56][   10/   31]    Overall Loss 1.197268    Objective Loss 1.197268                                        LR 0.001000    Time 0.188715    \n",
            "Epoch: [56][   20/   31]    Overall Loss 1.200218    Objective Loss 1.200218                                        LR 0.001000    Time 0.147504    \n",
            "Epoch: [56][   30/   31]    Overall Loss 1.199159    Objective Loss 1.199159    Top1 50.781250    Top5 100.000000    LR 0.001000    Time 0.121919    \n",
            "Epoch: [56][   31/   31]    Overall Loss 1.200830    Objective Loss 1.200830    Top1 51.829268    Top5 100.000000    LR 0.001000    Time 0.119665    \n",
            "--- validate (epoch=56)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [56][    4/    4]    Loss 1.264130    Top1 52.264808    Top5 98.606272    \n",
            "==> Top1: 52.265    Top5: 98.606    Loss: 1.264\n",
            "\n",
            "==> Confusion:\n",
            "[[174   0   0   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 43   0 119   3   0   0]\n",
            " [  2   0  14 187   0   0]\n",
            " [  0   0   3 210   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.381   Top5: 98.606   Sparsity:0.00   Params: 80076 on epoch: 54]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [57][   10/   31]    Overall Loss 1.208513    Objective Loss 1.208513                                        LR 0.001000    Time 0.191286    \n",
            "Epoch: [57][   20/   31]    Overall Loss 1.202738    Objective Loss 1.202738                                        LR 0.001000    Time 0.137628    \n",
            "Epoch: [57][   30/   31]    Overall Loss 1.201226    Objective Loss 1.201226    Top1 59.765625    Top5 100.000000    LR 0.001000    Time 0.106651    \n",
            "Epoch: [57][   31/   31]    Overall Loss 1.201430    Objective Loss 1.201430    Top1 57.926829    Top5 100.000000    LR 0.001000    Time 0.104380    \n",
            "--- validate (epoch=57)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [57][    4/    4]    Loss 1.290264    Top1 50.638792    Top5 97.096400    \n",
            "==> Top1: 50.639    Top5: 97.096    Loss: 1.290\n",
            "\n",
            "==> Confusion:\n",
            "[[160   0  14   0   0   0]\n",
            " [104   0   2   0   0   0]\n",
            " [ 12   0 146   7   0   0]\n",
            " [  1   0  12 190   0   0]\n",
            " [  0   0   2 211   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.381   Top5: 98.606   Sparsity:0.00   Params: 80076 on epoch: 54]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [58][   10/   31]    Overall Loss 1.201194    Objective Loss 1.201194                                        LR 0.001000    Time 0.181456    \n",
            "Epoch: [58][   20/   31]    Overall Loss 1.193096    Objective Loss 1.193096                                        LR 0.001000    Time 0.140158    \n",
            "Epoch: [58][   30/   31]    Overall Loss 1.194079    Objective Loss 1.194079    Top1 50.390625    Top5 100.000000    LR 0.001000    Time 0.114992    \n",
            "Epoch: [58][   31/   31]    Overall Loss 1.195001    Objective Loss 1.195001    Top1 49.695122    Top5 100.000000    LR 0.001000    Time 0.112759    \n",
            "--- validate (epoch=58)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [58][    4/    4]    Loss 1.281516    Top1 51.684088    Top5 97.677120    \n",
            "==> Top1: 51.684    Top5: 97.677    Loss: 1.282\n",
            "\n",
            "==> Confusion:\n",
            "[[172   0   2   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 27   0 135   3   0   0]\n",
            " [  1   0  13 189   0   0]\n",
            " [  0   0   4 209   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.381   Top5: 98.606   Sparsity:0.00   Params: 80076 on epoch: 54]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [59][   10/   31]    Overall Loss 1.189293    Objective Loss 1.189293                                        LR 0.001000    Time 0.122592    \n",
            "Epoch: [59][   20/   31]    Overall Loss 1.196220    Objective Loss 1.196220                                        LR 0.001000    Time 0.093375    \n",
            "Epoch: [59][   30/   31]    Overall Loss 1.193015    Objective Loss 1.193015    Top1 55.078125    Top5 100.000000    LR 0.001000    Time 0.077740    \n",
            "Epoch: [59][   31/   31]    Overall Loss 1.193868    Objective Loss 1.193868    Top1 51.524390    Top5 100.000000    LR 0.001000    Time 0.076286    \n",
            "--- validate (epoch=59)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [59][    4/    4]    Loss 1.291259    Top1 51.451800    Top5 97.328688    \n",
            "==> Top1: 51.452    Top5: 97.329    Loss: 1.291\n",
            "\n",
            "==> Confusion:\n",
            "[[163   0  11   0   0   0]\n",
            " [104   0   2   0   0   0]\n",
            " [ 19   0 139   7   0   0]\n",
            " [  1   0  13 189   0   0]\n",
            " [  0   0   1 212   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.381   Top5: 98.606   Sparsity:0.00   Params: 80076 on epoch: 54]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [60][   10/   31]    Overall Loss 1.194666    Objective Loss 1.194666                                        LR 0.001000    Time 0.145574    \n",
            "Epoch: [60][   20/   31]    Overall Loss 1.192913    Objective Loss 1.192913                                        LR 0.001000    Time 0.123471    \n",
            "Epoch: [60][   30/   31]    Overall Loss 1.191616    Objective Loss 1.191616    Top1 53.906250    Top5 100.000000    LR 0.001000    Time 0.104777    \n",
            "Epoch: [60][   31/   31]    Overall Loss 1.193101    Objective Loss 1.193101    Top1 55.792683    Top5 100.000000    LR 0.001000    Time 0.102871    \n",
            "--- validate (epoch=60)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [60][    4/    4]    Loss 1.267025    Top1 52.380952    Top5 98.025552    \n",
            "==> Top1: 52.381    Top5: 98.026    Loss: 1.267\n",
            "\n",
            "==> Confusion:\n",
            "[[168   0   6   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 23   0 137   5   0   0]\n",
            " [  1   0  13 189   0   0]\n",
            " [  0   0   1 212   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.381   Top5: 98.606   Sparsity:0.00   Params: 80076 on epoch: 54]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [61][   10/   31]    Overall Loss 1.191690    Objective Loss 1.191690                                        LR 0.001000    Time 0.193600    \n",
            "Epoch: [61][   20/   31]    Overall Loss 1.189555    Objective Loss 1.189555                                        LR 0.001000    Time 0.148418    \n",
            "Epoch: [61][   30/   31]    Overall Loss 1.192091    Objective Loss 1.192091    Top1 54.296875    Top5 100.000000    LR 0.001000    Time 0.121462    \n",
            "Epoch: [61][   31/   31]    Overall Loss 1.191951    Objective Loss 1.191951    Top1 56.097561    Top5 100.000000    LR 0.001000    Time 0.119301    \n",
            "--- validate (epoch=61)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [61][    4/    4]    Loss 1.263755    Top1 51.451800    Top5 97.909408    \n",
            "==> Top1: 51.452    Top5: 97.909    Loss: 1.264\n",
            "\n",
            "==> Confusion:\n",
            "[[168   0   6   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 19   0 136  10   0   0]\n",
            " [  1   0  11 191   0   0]\n",
            " [  0   0   0 213   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.381   Top5: 98.606   Sparsity:0.00   Params: 80076 on epoch: 54]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [62][   10/   31]    Overall Loss 1.185722    Objective Loss 1.185722                                        LR 0.001000    Time 0.193396    \n",
            "Epoch: [62][   20/   31]    Overall Loss 1.188250    Objective Loss 1.188250                                        LR 0.001000    Time 0.148239    \n",
            "Epoch: [62][   30/   31]    Overall Loss 1.191392    Objective Loss 1.191392    Top1 54.687500    Top5 99.609375    LR 0.001000    Time 0.120785    \n",
            "Epoch: [62][   31/   31]    Overall Loss 1.192712    Objective Loss 1.192712    Top1 53.658537    Top5 99.695122    LR 0.001000    Time 0.118554    \n",
            "--- validate (epoch=62)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [62][    4/    4]    Loss 1.299192    Top1 50.871080    Top5 96.980256    \n",
            "==> Top1: 50.871    Top5: 96.980    Loss: 1.299\n",
            "\n",
            "==> Confusion:\n",
            "[[163   0  11   0   0   0]\n",
            " [103   0   3   0   0   0]\n",
            " [ 14   0 143   8   0   0]\n",
            " [  1   0  10 192   0   0]\n",
            " [  0   0   0 213   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.381   Top5: 98.606   Sparsity:0.00   Params: 80076 on epoch: 54]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [63][   10/   31]    Overall Loss 1.187428    Objective Loss 1.187428                                        LR 0.001000    Time 0.125131    \n",
            "Epoch: [63][   20/   31]    Overall Loss 1.190526    Objective Loss 1.190526                                        LR 0.001000    Time 0.096896    \n",
            "Epoch: [63][   30/   31]    Overall Loss 1.192207    Objective Loss 1.192207    Top1 56.250000    Top5 100.000000    LR 0.001000    Time 0.079922    \n",
            "Epoch: [63][   31/   31]    Overall Loss 1.194737    Objective Loss 1.194737    Top1 57.317073    Top5 100.000000    LR 0.001000    Time 0.078513    \n",
            "--- validate (epoch=63)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [63][    4/    4]    Loss 1.269573    Top1 52.032520    Top5 98.025552    \n",
            "==> Top1: 52.033    Top5: 98.026    Loss: 1.270\n",
            "\n",
            "==> Confusion:\n",
            "[[172   0   2   0   0   0]\n",
            " [104   0   2   0   0   0]\n",
            " [ 27   0 134   4   0   0]\n",
            " [  1   0  14 188   0   0]\n",
            " [  0   0   3 210   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.381   Top5: 98.606   Sparsity:0.00   Params: 80076 on epoch: 54]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [64][   10/   31]    Overall Loss 1.187353    Objective Loss 1.187353                                        LR 0.001000    Time 0.122367    \n",
            "Epoch: [64][   20/   31]    Overall Loss 1.192201    Objective Loss 1.192201                                        LR 0.001000    Time 0.093191    \n",
            "Epoch: [64][   30/   31]    Overall Loss 1.198408    Objective Loss 1.198408    Top1 53.906250    Top5 100.000000    LR 0.001000    Time 0.077004    \n",
            "Epoch: [64][   31/   31]    Overall Loss 1.199358    Objective Loss 1.199358    Top1 53.353659    Top5 100.000000    LR 0.001000    Time 0.075650    \n",
            "--- validate (epoch=64)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [64][    4/    4]    Loss 1.256341    Top1 51.916376    Top5 98.722416    \n",
            "==> Top1: 51.916    Top5: 98.722    Loss: 1.256\n",
            "\n",
            "==> Confusion:\n",
            "[[174   0   0   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 38   0 124   3   0   0]\n",
            " [  2   0  15 186   0   0]\n",
            " [  0   0   7 206   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.381   Top5: 98.606   Sparsity:0.00   Params: 80076 on epoch: 54]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [65][   10/   31]    Overall Loss 1.193040    Objective Loss 1.193040                                        LR 0.001000    Time 0.126163    \n",
            "Epoch: [65][   20/   31]    Overall Loss 1.198048    Objective Loss 1.198048                                        LR 0.001000    Time 0.097673    \n",
            "Epoch: [65][   30/   31]    Overall Loss 1.198356    Objective Loss 1.198356    Top1 55.468750    Top5 100.000000    LR 0.001000    Time 0.080870    \n",
            "Epoch: [65][   31/   31]    Overall Loss 1.198759    Objective Loss 1.198759    Top1 54.573171    Top5 100.000000    LR 0.001000    Time 0.079418    \n",
            "--- validate (epoch=65)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [65][    4/    4]    Loss 1.295397    Top1 50.290360    Top5 97.096400    \n",
            "==> Top1: 50.290    Top5: 97.096    Loss: 1.295\n",
            "\n",
            "==> Confusion:\n",
            "[[169   0   5   0   0   0]\n",
            " [104   0   2   0   0   0]\n",
            " [ 24   0 133   8   0   0]\n",
            " [  1   0  12 190   0   0]\n",
            " [  0   0   1 212   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.381   Top5: 98.606   Sparsity:0.00   Params: 80076 on epoch: 54]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [66][   10/   31]    Overall Loss 1.210306    Objective Loss 1.210306                                        LR 0.001000    Time 0.171646    \n",
            "Epoch: [66][   20/   31]    Overall Loss 1.210491    Objective Loss 1.210491                                        LR 0.001000    Time 0.138828    \n",
            "Epoch: [66][   30/   31]    Overall Loss 1.200365    Objective Loss 1.200365    Top1 56.640625    Top5 100.000000    LR 0.001000    Time 0.115144    \n",
            "Epoch: [66][   31/   31]    Overall Loss 1.202300    Objective Loss 1.202300    Top1 56.097561    Top5 100.000000    LR 0.001000    Time 0.113186    \n",
            "--- validate (epoch=66)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [66][    4/    4]    Loss 1.263429    Top1 52.148664    Top5 98.838560    \n",
            "==> Top1: 52.149    Top5: 98.839    Loss: 1.263\n",
            "\n",
            "==> Confusion:\n",
            "[[172   0   2   0   0   0]\n",
            " [105   0   1   0   0   0]\n",
            " [ 28   0 133   4   0   0]\n",
            " [  1   0  14 188   0   0]\n",
            " [  0   0   2 211   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.381   Top5: 98.606   Sparsity:0.00   Params: 80076 on epoch: 54]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [67][   10/   31]    Overall Loss 1.194935    Objective Loss 1.194935                                        LR 0.001000    Time 0.206532    \n",
            "Epoch: [67][   20/   31]    Overall Loss 1.190709    Objective Loss 1.190709                                        LR 0.001000    Time 0.156862    \n",
            "Epoch: [67][   30/   31]    Overall Loss 1.193047    Objective Loss 1.193047    Top1 54.296875    Top5 100.000000    LR 0.001000    Time 0.129148    \n",
            "Epoch: [67][   31/   31]    Overall Loss 1.191856    Objective Loss 1.191856    Top1 55.487805    Top5 100.000000    LR 0.001000    Time 0.126708    \n",
            "--- validate (epoch=67)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [67][    4/    4]    Loss 1.263470    Top1 52.613240    Top5 98.954704    \n",
            "==> Top1: 52.613    Top5: 98.955    Loss: 1.263\n",
            "\n",
            "==> Confusion:\n",
            "[[172   0   2   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 40   0 121   4   0   0]\n",
            " [  2   0  13 188   0   0]\n",
            " [  0   0   4 209   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.613   Top5: 98.955   Sparsity:0.00   Params: 80076 on epoch: 67]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [68][   10/   31]    Overall Loss 1.190529    Objective Loss 1.190529                                        LR 0.001000    Time 0.193975    \n",
            "Epoch: [68][   20/   31]    Overall Loss 1.190711    Objective Loss 1.190711                                        LR 0.001000    Time 0.154434    \n",
            "Epoch: [68][   30/   31]    Overall Loss 1.191800    Objective Loss 1.191800    Top1 53.906250    Top5 100.000000    LR 0.001000    Time 0.123194    \n",
            "Epoch: [68][   31/   31]    Overall Loss 1.192748    Objective Loss 1.192748    Top1 53.353659    Top5 100.000000    LR 0.001000    Time 0.120428    \n",
            "--- validate (epoch=68)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [68][    4/    4]    Loss 1.256281    Top1 52.264808    Top5 98.606272    \n",
            "==> Top1: 52.265    Top5: 98.606    Loss: 1.256\n",
            "\n",
            "==> Confusion:\n",
            "[[170   0   4   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 26   0 134   5   0   0]\n",
            " [  2   0  12 189   0   0]\n",
            " [  0   0   3 210   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.613   Top5: 98.955   Sparsity:0.00   Params: 80076 on epoch: 67]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [69][   10/   31]    Overall Loss 1.194263    Objective Loss 1.194263                                        LR 0.001000    Time 0.124327    \n",
            "Epoch: [69][   20/   31]    Overall Loss 1.195709    Objective Loss 1.195709                                        LR 0.001000    Time 0.094386    \n",
            "Epoch: [69][   30/   31]    Overall Loss 1.194138    Objective Loss 1.194138    Top1 62.109375    Top5 100.000000    LR 0.001000    Time 0.078051    \n",
            "Epoch: [69][   31/   31]    Overall Loss 1.193176    Objective Loss 1.193176    Top1 60.975610    Top5 100.000000    LR 0.001000    Time 0.076666    \n",
            "--- validate (epoch=69)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [69][    4/    4]    Loss 1.272635    Top1 50.290360    Top5 97.793264    \n",
            "==> Top1: 50.290    Top5: 97.793    Loss: 1.273\n",
            "\n",
            "==> Confusion:\n",
            "[[166   0   8   0   0   0]\n",
            " [105   0   1   0   0   0]\n",
            " [ 16   0 136  13   0   0]\n",
            " [  2   0   8 193   0   0]\n",
            " [  0   0   1 212   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.613   Top5: 98.955   Sparsity:0.00   Params: 80076 on epoch: 67]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [70][   10/   31]    Overall Loss 1.185654    Objective Loss 1.185654                                        LR 0.001000    Time 0.124961    \n",
            "Epoch: [70][   20/   31]    Overall Loss 1.200842    Objective Loss 1.200842                                        LR 0.001000    Time 0.095727    \n",
            "Epoch: [70][   30/   31]    Overall Loss 1.222338    Objective Loss 1.222338    Top1 50.781250    Top5 100.000000    LR 0.001000    Time 0.078494    \n",
            "Epoch: [70][   31/   31]    Overall Loss 1.221975    Objective Loss 1.221975    Top1 51.219512    Top5 100.000000    LR 0.001000    Time 0.077122    \n",
            "--- validate (epoch=70)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [70][    4/    4]    Loss 1.253211    Top1 52.032520    Top5 99.767712    \n",
            "==> Top1: 52.033    Top5: 99.768    Loss: 1.253\n",
            "\n",
            "==> Confusion:\n",
            "[[174   0   0   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 53   0 110   2   0   0]\n",
            " [  5   0  17 181   0   0]\n",
            " [  0   0   8 205   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.613   Top5: 98.955   Sparsity:0.00   Params: 80076 on epoch: 67]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [71][   10/   31]    Overall Loss 1.198820    Objective Loss 1.198820                                        LR 0.001000    Time 0.124434    \n",
            "Epoch: [71][   20/   31]    Overall Loss 1.196565    Objective Loss 1.196565                                        LR 0.001000    Time 0.094553    \n",
            "Epoch: [71][   30/   31]    Overall Loss 1.195837    Objective Loss 1.195837    Top1 54.687500    Top5 100.000000    LR 0.001000    Time 0.078139    \n",
            "Epoch: [71][   31/   31]    Overall Loss 1.195116    Objective Loss 1.195116    Top1 52.439024    Top5 100.000000    LR 0.001000    Time 0.076770    \n",
            "--- validate (epoch=71)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [71][    4/    4]    Loss 1.293414    Top1 50.058072    Top5 97.212544    \n",
            "==> Top1: 50.058    Top5: 97.213    Loss: 1.293\n",
            "\n",
            "==> Confusion:\n",
            "[[167   0   7   0   0   0]\n",
            " [105   0   1   0   0   0]\n",
            " [ 26   0 128  11   0   0]\n",
            " [  1   0   9 193   0   0]\n",
            " [  0   0   2 211   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.613   Top5: 98.955   Sparsity:0.00   Params: 80076 on epoch: 67]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [72][   10/   31]    Overall Loss 1.183992    Objective Loss 1.183992                                        LR 0.001000    Time 0.200913    \n",
            "Epoch: [72][   20/   31]    Overall Loss 1.193131    Objective Loss 1.193131                                        LR 0.001000    Time 0.155034    \n",
            "Epoch: [72][   30/   31]    Overall Loss 1.193940    Objective Loss 1.193940    Top1 57.812500    Top5 100.000000    LR 0.001000    Time 0.126441    \n",
            "Epoch: [72][   31/   31]    Overall Loss 1.194175    Objective Loss 1.194175    Top1 57.012195    Top5 100.000000    LR 0.001000    Time 0.124071    \n",
            "--- validate (epoch=72)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [72][    4/    4]    Loss 1.258082    Top1 52.032520    Top5 99.070848    \n",
            "==> Top1: 52.033    Top5: 99.071    Loss: 1.258\n",
            "\n",
            "==> Confusion:\n",
            "[[171   0   3   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 32   0 129   4   0   0]\n",
            " [  3   0  12 188   0   0]\n",
            " [  0   0   4 209   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.613   Top5: 98.955   Sparsity:0.00   Params: 80076 on epoch: 67]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [73][   10/   31]    Overall Loss 1.193546    Objective Loss 1.193546                                        LR 0.001000    Time 0.193120    \n",
            "Epoch: [73][   20/   31]    Overall Loss 1.197536    Objective Loss 1.197536                                        LR 0.001000    Time 0.150330    \n",
            "Epoch: [73][   30/   31]    Overall Loss 1.196039    Objective Loss 1.196039    Top1 53.125000    Top5 100.000000    LR 0.001000    Time 0.123723    \n",
            "Epoch: [73][   31/   31]    Overall Loss 1.196932    Objective Loss 1.196932    Top1 53.353659    Top5 100.000000    LR 0.001000    Time 0.121412    \n",
            "--- validate (epoch=73)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [73][    4/    4]    Loss 1.304041    Top1 50.987224    Top5 97.677120    \n",
            "==> Top1: 50.987    Top5: 97.677    Loss: 1.304\n",
            "\n",
            "==> Confusion:\n",
            "[[160   0  14   0   0   0]\n",
            " [103   0   3   0   0   0]\n",
            " [ 11   0 148   6   0   0]\n",
            " [  1   0  11 191   0   0]\n",
            " [  0   0   3 210   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.613   Top5: 98.955   Sparsity:0.00   Params: 80076 on epoch: 67]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [74][   10/   31]    Overall Loss 1.194989    Objective Loss 1.194989                                        LR 0.001000    Time 0.165973    \n",
            "Epoch: [74][   20/   31]    Overall Loss 1.201871    Objective Loss 1.201871                                        LR 0.001000    Time 0.115695    \n",
            "Epoch: [74][   30/   31]    Overall Loss 1.206650    Objective Loss 1.206650    Top1 50.781250    Top5 100.000000    LR 0.001000    Time 0.093673    \n",
            "Epoch: [74][   31/   31]    Overall Loss 1.208378    Objective Loss 1.208378    Top1 48.170732    Top5 100.000000    LR 0.001000    Time 0.091825    \n",
            "--- validate (epoch=74)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [74][    4/    4]    Loss 1.288753    Top1 49.245064    Top5 100.000000    \n",
            "==> Top1: 49.245    Top5: 100.000    Loss: 1.289\n",
            "\n",
            "==> Confusion:\n",
            "[[174   0   0   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [136   0  29   0   0   0]\n",
            " [  6   0  32 165   0   0]\n",
            " [  1   0  21 191   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.613   Top5: 98.955   Sparsity:0.00   Params: 80076 on epoch: 67]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [75][   10/   31]    Overall Loss 1.301119    Objective Loss 1.301119                                        LR 0.001000    Time 0.122537    \n",
            "Epoch: [75][   20/   31]    Overall Loss 1.298471    Objective Loss 1.298471                                        LR 0.001000    Time 0.093062    \n",
            "Epoch: [75][   30/   31]    Overall Loss 1.280905    Objective Loss 1.280905    Top1 50.781250    Top5 100.000000    LR 0.001000    Time 0.076880    \n",
            "Epoch: [75][   31/   31]    Overall Loss 1.280433    Objective Loss 1.280433    Top1 52.439024    Top5 100.000000    LR 0.001000    Time 0.075565    \n",
            "--- validate (epoch=75)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [75][    4/    4]    Loss 1.287447    Top1 48.664344    Top5 99.883856    \n",
            "==> Top1: 48.664    Top5: 99.884    Loss: 1.287\n",
            "\n",
            "==> Confusion:\n",
            "[[174   0   0   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 99   0  66   0   0   0]\n",
            " [  7   0  31 165   0   0]\n",
            " [  0   0  21 192   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.613   Top5: 98.955   Sparsity:0.00   Params: 80076 on epoch: 67]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [76][   10/   31]    Overall Loss 1.225549    Objective Loss 1.225549                                        LR 0.001000    Time 0.123386    \n",
            "Epoch: [76][   20/   31]    Overall Loss 1.224090    Objective Loss 1.224090                                        LR 0.001000    Time 0.096097    \n",
            "Epoch: [76][   30/   31]    Overall Loss 1.218375    Objective Loss 1.218375    Top1 58.593750    Top5 100.000000    LR 0.001000    Time 0.079013    \n",
            "Epoch: [76][   31/   31]    Overall Loss 1.217890    Objective Loss 1.217890    Top1 57.012195    Top5 100.000000    LR 0.001000    Time 0.077609    \n",
            "--- validate (epoch=76)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [76][    4/    4]    Loss 1.266962    Top1 51.800232    Top5 98.257840    \n",
            "==> Top1: 51.800    Top5: 98.258    Loss: 1.267\n",
            "\n",
            "==> Confusion:\n",
            "[[170   0   4   0   0   0]\n",
            " [104   0   2   0   0   0]\n",
            " [ 22   0 138   5   0   0]\n",
            " [  4   0  11 188   0   0]\n",
            " [  0   0   4 209   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.613   Top5: 98.955   Sparsity:0.00   Params: 80076 on epoch: 67]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [77][   10/   31]    Overall Loss 1.211823    Objective Loss 1.211823                                        LR 0.001000    Time 0.130390    \n",
            "Epoch: [77][   20/   31]    Overall Loss 1.203653    Objective Loss 1.203653                                        LR 0.001000    Time 0.119415    \n",
            "Epoch: [77][   30/   31]    Overall Loss 1.203306    Objective Loss 1.203306    Top1 56.250000    Top5 99.609375    LR 0.001000    Time 0.099958    \n",
            "Epoch: [77][   31/   31]    Overall Loss 1.205420    Objective Loss 1.205420    Top1 55.792683    Top5 99.695122    LR 0.001000    Time 0.098289    \n",
            "--- validate (epoch=77)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [77][    4/    4]    Loss 1.249395    Top1 52.613240    Top5 98.838560    \n",
            "==> Top1: 52.613    Top5: 98.839    Loss: 1.249\n",
            "\n",
            "==> Confusion:\n",
            "[[172   0   2   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 18   0 143   4   0   0]\n",
            " [  3   0   9 191   0   0]\n",
            " [  0   0   6 207   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.613   Top5: 98.955   Sparsity:0.00   Params: 80076 on epoch: 67]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [78][   10/   31]    Overall Loss 1.204921    Objective Loss 1.204921                                        LR 0.001000    Time 0.190945    \n",
            "Epoch: [78][   20/   31]    Overall Loss 1.199966    Objective Loss 1.199966                                        LR 0.001000    Time 0.150461    \n",
            "Epoch: [78][   30/   31]    Overall Loss 1.199378    Objective Loss 1.199378    Top1 50.781250    Top5 100.000000    LR 0.001000    Time 0.123297    \n",
            "Epoch: [78][   31/   31]    Overall Loss 1.199669    Objective Loss 1.199669    Top1 50.914634    Top5 100.000000    LR 0.001000    Time 0.120932    \n",
            "--- validate (epoch=78)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [78][    4/    4]    Loss 1.278457    Top1 51.335656    Top5 98.257840    \n",
            "==> Top1: 51.336    Top5: 98.258    Loss: 1.278\n",
            "\n",
            "==> Confusion:\n",
            "[[170   0   4   0   0   0]\n",
            " [104   0   2   0   0   0]\n",
            " [ 12   0 147   6   0   0]\n",
            " [  3   0  11 189   0   0]\n",
            " [  0   0   4 209   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.613   Top5: 98.955   Sparsity:0.00   Params: 80076 on epoch: 67]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [79][   10/   31]    Overall Loss 1.195577    Objective Loss 1.195577                                        LR 0.001000    Time 0.193349    \n",
            "Epoch: [79][   20/   31]    Overall Loss 1.194800    Objective Loss 1.194800                                        LR 0.001000    Time 0.152313    \n",
            "Epoch: [79][   30/   31]    Overall Loss 1.199733    Objective Loss 1.199733    Top1 56.640625    Top5 100.000000    LR 0.001000    Time 0.125590    \n",
            "Epoch: [79][   31/   31]    Overall Loss 1.200426    Objective Loss 1.200426    Top1 55.792683    Top5 99.695122    LR 0.001000    Time 0.123206    \n",
            "--- validate (epoch=79)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [79][    4/    4]    Loss 1.241720    Top1 52.729384    Top5 99.186992    \n",
            "==> Top1: 52.729    Top5: 99.187    Loss: 1.242\n",
            "\n",
            "==> Confusion:\n",
            "[[174   0   0   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 27   0 134   4   0   0]\n",
            " [  5   0  12 186   0   0]\n",
            " [  0   0   6 207   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.729   Top5: 99.187   Sparsity:0.00   Params: 80076 on epoch: 79]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [80][   10/   31]    Overall Loss 1.219681    Objective Loss 1.219681                                        LR 0.001000    Time 0.121575    \n",
            "Epoch: [80][   20/   31]    Overall Loss 1.208965    Objective Loss 1.208965                                        LR 0.001000    Time 0.092255    \n",
            "Epoch: [80][   30/   31]    Overall Loss 1.207896    Objective Loss 1.207896    Top1 53.515625    Top5 99.609375    LR 0.001000    Time 0.076405    \n",
            "Epoch: [80][   31/   31]    Overall Loss 1.206508    Objective Loss 1.206508    Top1 52.743902    Top5 99.695122    LR 0.001000    Time 0.075064    \n",
            "--- validate (epoch=80)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [80][    4/    4]    Loss 1.271614    Top1 51.335656    Top5 97.909408    \n",
            "==> Top1: 51.336    Top5: 97.909    Loss: 1.272\n",
            "\n",
            "==> Confusion:\n",
            "[[173   0   1   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 23   0 133   9   0   0]\n",
            " [  4   0   9 190   0   0]\n",
            " [  0   0   3 210   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.729   Top5: 99.187   Sparsity:0.00   Params: 80076 on epoch: 79]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [81][   10/   31]    Overall Loss 1.195176    Objective Loss 1.195176                                        LR 0.001000    Time 0.123296    \n",
            "Epoch: [81][   20/   31]    Overall Loss 1.197737    Objective Loss 1.197737                                        LR 0.001000    Time 0.094808    \n",
            "Epoch: [81][   30/   31]    Overall Loss 1.199097    Objective Loss 1.199097    Top1 56.250000    Top5 99.609375    LR 0.001000    Time 0.077891    \n",
            "Epoch: [81][   31/   31]    Overall Loss 1.199659    Objective Loss 1.199659    Top1 54.573171    Top5 99.695122    LR 0.001000    Time 0.076650    \n",
            "--- validate (epoch=81)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [81][    4/    4]    Loss 1.259146    Top1 51.684088    Top5 97.909408    \n",
            "==> Top1: 51.684    Top5: 97.909    Loss: 1.259\n",
            "\n",
            "==> Confusion:\n",
            "[[172   0   2   0   0   0]\n",
            " [104   0   2   0   0   0]\n",
            " [ 20   0 138   7   0   0]\n",
            " [  3   0   9 191   0   0]\n",
            " [  0   0   2 211   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.729   Top5: 99.187   Sparsity:0.00   Params: 80076 on epoch: 79]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [82][   10/   31]    Overall Loss 1.198367    Objective Loss 1.198367                                        LR 0.001000    Time 0.133045    \n",
            "Epoch: [82][   20/   31]    Overall Loss 1.198910    Objective Loss 1.198910                                        LR 0.001000    Time 0.099465    \n",
            "Epoch: [82][   30/   31]    Overall Loss 1.201320    Objective Loss 1.201320    Top1 55.078125    Top5 100.000000    LR 0.001000    Time 0.082095    \n",
            "Epoch: [82][   31/   31]    Overall Loss 1.200381    Objective Loss 1.200381    Top1 55.487805    Top5 100.000000    LR 0.001000    Time 0.080604    \n",
            "--- validate (epoch=82)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [82][    4/    4]    Loss 1.247169    Top1 52.613240    Top5 99.535424    \n",
            "==> Top1: 52.613    Top5: 99.535    Loss: 1.247\n",
            "\n",
            "==> Confusion:\n",
            "[[174   0   0   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 44   0 117   4   0   0]\n",
            " [  5   0  13 185   0   0]\n",
            " [  0   0   7 206   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.729   Top5: 99.187   Sparsity:0.00   Params: 80076 on epoch: 79]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [83][   10/   31]    Overall Loss 1.198707    Objective Loss 1.198707                                        LR 0.001000    Time 0.186337    \n",
            "Epoch: [83][   20/   31]    Overall Loss 1.200530    Objective Loss 1.200530                                        LR 0.001000    Time 0.143246    \n",
            "Epoch: [83][   30/   31]    Overall Loss 1.196944    Objective Loss 1.196944    Top1 60.937500    Top5 100.000000    LR 0.001000    Time 0.116376    \n",
            "Epoch: [83][   31/   31]    Overall Loss 1.197228    Objective Loss 1.197228    Top1 60.975610    Top5 100.000000    LR 0.001000    Time 0.114279    \n",
            "--- validate (epoch=83)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [83][    4/    4]    Loss 1.257024    Top1 52.845528    Top5 99.070848    \n",
            "==> Top1: 52.846    Top5: 99.071    Loss: 1.257\n",
            "\n",
            "==> Confusion:\n",
            "[[174   0   0   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 35   0 127   3   0   0]\n",
            " [  4   0  14 185   0   0]\n",
            " [  0   0   7 206   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.846   Top5: 99.071   Sparsity:0.00   Params: 80076 on epoch: 83]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [84][   10/   31]    Overall Loss 1.197252    Objective Loss 1.197252                                        LR 0.001000    Time 0.186922    \n",
            "Epoch: [84][   20/   31]    Overall Loss 1.199390    Objective Loss 1.199390                                        LR 0.001000    Time 0.143235    \n",
            "Epoch: [84][   30/   31]    Overall Loss 1.197921    Objective Loss 1.197921    Top1 62.500000    Top5 100.000000    LR 0.001000    Time 0.118649    \n",
            "Epoch: [84][   31/   31]    Overall Loss 1.197589    Objective Loss 1.197589    Top1 61.585366    Top5 99.695122    LR 0.001000    Time 0.116433    \n",
            "--- validate (epoch=84)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [84][    4/    4]    Loss 1.237068    Top1 52.497096    Top5 98.954704    \n",
            "==> Top1: 52.497    Top5: 98.955    Loss: 1.237\n",
            "\n",
            "==> Confusion:\n",
            "[[173   0   1   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 28   0 134   3   0   0]\n",
            " [  3   0  13 187   0   0]\n",
            " [  0   0   6 207   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.846   Top5: 99.071   Sparsity:0.00   Params: 80076 on epoch: 83]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [85][   10/   31]    Overall Loss 1.202107    Objective Loss 1.202107                                        LR 0.001000    Time 0.223482    \n",
            "Epoch: [85][   20/   31]    Overall Loss 1.202376    Objective Loss 1.202376                                        LR 0.001000    Time 0.156070    \n",
            "Epoch: [85][   30/   31]    Overall Loss 1.198328    Objective Loss 1.198328    Top1 58.203125    Top5 100.000000    LR 0.001000    Time 0.119742    \n",
            "Epoch: [85][   31/   31]    Overall Loss 1.197931    Objective Loss 1.197931    Top1 56.707317    Top5 100.000000    LR 0.001000    Time 0.117104    \n",
            "--- validate (epoch=85)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [85][    4/    4]    Loss 1.251997    Top1 52.613240    Top5 99.186992    \n",
            "==> Top1: 52.613    Top5: 99.187    Loss: 1.252\n",
            "\n",
            "==> Confusion:\n",
            "[[173   0   1   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 28   0 133   4   0   0]\n",
            " [  4   0  13 186   0   0]\n",
            " [  0   0   4 209   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.846   Top5: 99.071   Sparsity:0.00   Params: 80076 on epoch: 83]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [86][   10/   31]    Overall Loss 1.199132    Objective Loss 1.199132                                        LR 0.001000    Time 0.124646    \n",
            "Epoch: [86][   20/   31]    Overall Loss 1.194718    Objective Loss 1.194718                                        LR 0.001000    Time 0.094279    \n",
            "Epoch: [86][   30/   31]    Overall Loss 1.198580    Objective Loss 1.198580    Top1 51.171875    Top5 99.609375    LR 0.001000    Time 0.078692    \n",
            "Epoch: [86][   31/   31]    Overall Loss 1.200043    Objective Loss 1.200043    Top1 51.524390    Top5 99.695122    LR 0.001000    Time 0.077318    \n",
            "--- validate (epoch=86)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [86][    4/    4]    Loss 1.242022    Top1 52.845528    Top5 99.419280    \n",
            "==> Top1: 52.846    Top5: 99.419    Loss: 1.242\n",
            "\n",
            "==> Confusion:\n",
            "[[174   0   0   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 40   0 123   2   0   0]\n",
            " [  4   0  16 183   0   0]\n",
            " [  0   0   8 205   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.846   Top5: 99.419   Sparsity:0.00   Params: 80076 on epoch: 86]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [87][   10/   31]    Overall Loss 1.201795    Objective Loss 1.201795                                        LR 0.001000    Time 0.127142    \n",
            "Epoch: [87][   20/   31]    Overall Loss 1.197827    Objective Loss 1.197827                                        LR 0.001000    Time 0.096371    \n",
            "Epoch: [87][   30/   31]    Overall Loss 1.199344    Objective Loss 1.199344    Top1 58.203125    Top5 100.000000    LR 0.001000    Time 0.079472    \n",
            "Epoch: [87][   31/   31]    Overall Loss 1.199762    Objective Loss 1.199762    Top1 57.621951    Top5 100.000000    LR 0.001000    Time 0.078254    \n",
            "--- validate (epoch=87)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [87][    4/    4]    Loss 1.248877    Top1 52.148664    Top5 98.954704    \n",
            "==> Top1: 52.149    Top5: 98.955    Loss: 1.249\n",
            "\n",
            "==> Confusion:\n",
            "[[172   0   2   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 33   0 129   3   0   0]\n",
            " [  4   0  17 182   0   0]\n",
            " [  0   0   9 204   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.846   Top5: 99.419   Sparsity:0.00   Params: 80076 on epoch: 86]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [88][   10/   31]    Overall Loss 1.182662    Objective Loss 1.182662                                        LR 0.001000    Time 0.122802    \n",
            "Epoch: [88][   20/   31]    Overall Loss 1.193934    Objective Loss 1.193934                                        LR 0.001000    Time 0.095267    \n",
            "Epoch: [88][   30/   31]    Overall Loss 1.198867    Objective Loss 1.198867    Top1 53.515625    Top5 100.000000    LR 0.001000    Time 0.084504    \n",
            "Epoch: [88][   31/   31]    Overall Loss 1.197154    Objective Loss 1.197154    Top1 55.487805    Top5 100.000000    LR 0.001000    Time 0.083320    \n",
            "--- validate (epoch=88)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [88][    4/    4]    Loss 1.256799    Top1 51.916376    Top5 98.606272    \n",
            "==> Top1: 51.916    Top5: 98.606    Loss: 1.257\n",
            "\n",
            "==> Confusion:\n",
            "[[172   0   2   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 25   0 134   6   0   0]\n",
            " [  4   0  10 189   0   0]\n",
            " [  0   0   4 209   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.846   Top5: 99.419   Sparsity:0.00   Params: 80076 on epoch: 86]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [89][   10/   31]    Overall Loss 1.196469    Objective Loss 1.196469                                        LR 0.001000    Time 0.190291    \n",
            "Epoch: [89][   20/   31]    Overall Loss 1.195683    Objective Loss 1.195683                                        LR 0.001000    Time 0.150053    \n",
            "Epoch: [89][   30/   31]    Overall Loss 1.195483    Objective Loss 1.195483    Top1 57.031250    Top5 100.000000    LR 0.001000    Time 0.121816    \n",
            "Epoch: [89][   31/   31]    Overall Loss 1.196664    Objective Loss 1.196664    Top1 55.487805    Top5 100.000000    LR 0.001000    Time 0.119490    \n",
            "--- validate (epoch=89)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [89][    4/    4]    Loss 1.265656    Top1 52.613240    Top5 98.257840    \n",
            "==> Top1: 52.613    Top5: 98.258    Loss: 1.266\n",
            "\n",
            "==> Confusion:\n",
            "[[171   0   3   0   0   0]\n",
            " [106   0   0   0   0   0]\n",
            " [ 28   0 134   3   0   0]\n",
            " [  4   0  13 186   0   0]\n",
            " [  0   0   6 207   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.846   Top5: 99.419   Sparsity:0.00   Params: 80076 on epoch: 86]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [90][   10/   31]    Overall Loss 1.206356    Objective Loss 1.206356                                        LR 0.001000    Time 0.197249    \n",
            "Epoch: [90][   20/   31]    Overall Loss 1.201492    Objective Loss 1.201492                                        LR 0.001000    Time 0.150887    \n",
            "Epoch: [90][   30/   31]    Overall Loss 1.198292    Objective Loss 1.198292    Top1 57.031250    Top5 100.000000    LR 0.001000    Time 0.123147    \n",
            "Epoch: [90][   31/   31]    Overall Loss 1.198573    Objective Loss 1.198573    Top1 58.231707    Top5 100.000000    LR 0.001000    Time 0.120846    \n",
            "--- validate (epoch=90)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [90][    4/    4]    Loss 1.272093    Top1 51.684088    Top5 98.141696    \n",
            "==> Top1: 51.684    Top5: 98.142    Loss: 1.272\n",
            "\n",
            "==> Confusion:\n",
            "[[163   0  11   0   0   0]\n",
            " [104   0   2   0   0   0]\n",
            " [ 14   0 147   4   0   0]\n",
            " [  1   0  15 187   0   0]\n",
            " [  0   0   4 209   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.846   Top5: 99.419   Sparsity:0.00   Params: 80076 on epoch: 86]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [91][   10/   31]    Overall Loss 1.199052    Objective Loss 1.199052                                        LR 0.001000    Time 0.144647    \n",
            "Epoch: [91][   20/   31]    Overall Loss 1.193512    Objective Loss 1.193512                                        LR 0.001000    Time 0.105271    \n",
            "Epoch: [91][   30/   31]    Overall Loss 1.192480    Objective Loss 1.192480    Top1 55.078125    Top5 100.000000    LR 0.001000    Time 0.085044    \n",
            "Epoch: [91][   31/   31]    Overall Loss 1.191484    Objective Loss 1.191484    Top1 53.658537    Top5 100.000000    LR 0.001000    Time 0.083476    \n",
            "--- validate (epoch=91)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [91][    4/    4]    Loss 1.276540    Top1 51.567944    Top5 97.560976    \n",
            "==> Top1: 51.568    Top5: 97.561    Loss: 1.277\n",
            "\n",
            "==> Confusion:\n",
            "[[165   0   9   0   0   0]\n",
            " [104   0   2   0   0   0]\n",
            " [ 12   0 147   6   0   0]\n",
            " [  2   0  10 191   0   0]\n",
            " [  0   0   2 211   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.846   Top5: 99.419   Sparsity:0.00   Params: 80076 on epoch: 86]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [92][   10/   31]    Overall Loss 1.194188    Objective Loss 1.194188                                        LR 0.001000    Time 0.145650    \n",
            "Epoch: [92][   20/   31]    Overall Loss 1.189770    Objective Loss 1.189770                                        LR 0.001000    Time 0.124724    \n",
            "Epoch: [92][   30/   31]    Overall Loss 1.199980    Objective Loss 1.199980    Top1 50.781250    Top5 100.000000    LR 0.001000    Time 0.104548    \n",
            "Epoch: [92][   31/   31]    Overall Loss 1.201181    Objective Loss 1.201181    Top1 50.609756    Top5 100.000000    LR 0.001000    Time 0.103020    \n",
            "--- validate (epoch=92)-----------\n",
            "861 samples (256 per mini-batch)\n",
            "Epoch: [92][    4/    4]    Loss 1.294656    Top1 49.593496    Top5 97.096400    \n",
            "==> Top1: 49.593    Top5: 97.096    Loss: 1.295\n",
            "\n",
            "==> Confusion:\n",
            "[[168   0   6   0   0   0]\n",
            " [105   0   1   0   0   0]\n",
            " [ 22   0 126  17   0   0]\n",
            " [  2   0   8 193   0   0]\n",
            " [  0   0   0 213   0   0]\n",
            " [  0   0   0   0   0   0]]\n",
            "\n",
            "==> Best [Top1: 52.846   Top5: 99.419   Sparsity:0.00   Params: 80076 on epoch: 86]\n",
            "Saving checkpoint to: logs/2023.08.18-024925/qat_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "Training epoch: 7752 samples (256 per mini-batch)\n",
            "Epoch: [93][   10/   31]    Overall Loss 1.269564    Objective Loss 1.269564                                        LR 0.001000    Time 0.192958    \n",
            "Epoch: [93][   20/   31]    Overall Loss 1.243623    Objective Loss 1.243623                                        LR 0.001000    Time 0.150389    \n",
            "Epoch: [93][   30/   31]    Overall Loss 1.232230    Objective Loss 1.232230    Top1 53.906250    Top5 100.000000    LR 0.001000    Time 0.129043    \n",
            "Epoch: [93][   31/   31]    Overall Loss 1.232822    Objective Loss 1.232822    Top1 52.439024    Top5 100.000000    LR 0.001000    Time 0.127616    \n",
            "--- validate (epoch=93)-----------\n",
            "861 samples (256 per mini-batch)\n"
          ]
        }
      ],
      "source": [
        "!exec $SHELL"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step by step process on SHELL above\n",
        "1. pyenv install 3.8.11\n",
        "2. pyenv local 3.8.11\n",
        "3. python -m venv venv --prompt ai8x-training\n",
        "4. source venv/bin/activate\n",
        "5. pip3 install -U pip wheel setuptools\n",
        "6. pip3 install -r requirements-cu11.txt\n",
        "7. pip3 install -r requirements.txt\n",
        "8. chmod +x /content/ai8x-training/scripts/train_smart_echo_net.sh\n",
        "9. scripts/train_smart_echo_net.sh"
      ],
      "metadata": {
        "id": "VvJC2DlXQhii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Path to the directory you want to zip\n",
        "directory_path = \"/content/don/ai8x-synthesis/tensorflow/tf-maxstutnet\"\n",
        "\n",
        "# Destination zip file path\n",
        "zip_file_path = \"/content/don/ai8x-synthesis/tensorflow/tf-maxstutnet.zip\"\n",
        "\n",
        "# Create the zip file\n",
        "shutil.make_archive(zip_file_path, 'zip', directory_path, directory_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BsnKPyNnQmVL",
        "outputId": "a449c9f6-addb-49eb-ed2a-8f5ed5c864ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/don/ai8x-synthesis/tensorflow/tf-maxstutnet.zip.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}